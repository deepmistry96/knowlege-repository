
Skip to Content
Search 50,000+ courses, events, titles, and more
1
Differential Game Theory and Applications to Missile Guidance
Nomenclature

k:

    is the epoch (in a discrete time game).
P:

    is the set of players in a game.
U:

    is the set of strategies available to all the players.
Ui:

    is the set of strategies available to player i.

    is the objective function for players i and j.
Xk:

    is the set of current state of a game at epoch k.
Uk:

    is the set of strategies available to a player at epoch k.

    is the strategy vector (input vector) available to player i against player j atepoch k.
Ck:

    is the set of constraints at epoch k.
Gk:

    is the set of elements of a discrete-time game.
t:

    is the time in a continuous time (differential) game.
Xt:

    is the set of states of a game at time t.
Ut:

    is the set of strategies at time t.

    is the strategy vector (input vector) available to player i against player j attime t.
Ct:

    is the set of constraints at time t.
Gt:

    is the set of elements of a continuous time (differential) game.

    is the relative state vector of player i w.r.t. player j at time t.

    is the strategy vector (input vector) of player i.
F:

    is the state coefficient matrix.
G:

    is the input coefficient matrix.
Q:

    is the PI weightings matrix on the current relative states.
S:

    is the PI weightings matrix on the final relative states.

    are PI weightings matrices on inputs.

Abbreviations

APN:

    augmented PN
CF:

    cost function
LQPI:

    linear system quadratic performance index
OF:

    objective function
PI:

    performance index
PN:

    proportional navigation
UF:

    utility function
4-DOF:

    four degrees of freedom
w.r.t.:

    with respect to

1.1 Introduction

Over the last few decades a great deal of material has been published covering some of the major aspects of game theory. The well-known publications in this field include “Games and Economic Behaviour” by John von Neumann and Oskar Morgenstern.[1] Since then there has been a significant growth in publication on both the theoretical results and applications. A total of eight Nobel Prizes were given in Economic Sciences for work primarily in game theory, including the one given in 1994 to John Harsanyi, John Nash, and Reinhard Selten for their pioneering work in the analysis of non-cooperative games. In 2005, the Nobel Prizes in game theory went to Robert Aumann and Thomas Schelling for their work on conflict and cooperation through game-theory analysis. In 2007, Leonid Hurwicz, Eric Maskin, and Roger Myerson were awarded the Nobel Prize for having laid the foundations of mechanism design theory. These and other notable works on game theory are given in the references.[2–7]

Cooperative game theory application to autonomous systems with applications to surveillance and reconnaissance of potential threats, and persistent area denial have been studied by a number of authors; useful references on this and allied topics are given at the end of this chapter.[8–15] Usually, the (potential) targets and threats in a battlefield are intelligent and mobile, and they employ counter-strategies to avoid being detected, tracked, or destroyed. These action and counteraction behaviors can be formulated in a game setting, or more specifically, by pursuit/evasion differential games (with multiple players). It is noteworthy that application of differential games to combat systems can be considered to have been started by Rufus P. Isaacs when he investigated pursuit/evasion games.[8] However, most of the theoretical results focus on two-player games with a single pursuer and a single evader, which has since been extended to a multi-player scenarios.
1.1.1 Need for Missile Guidance—Past, Present, and Future

Guided missiles with the requirement to intercept a target (usually an aircraft) at a long range from the missile launch point have been in use since WWII. Guidance systems for missiles are needed in order to correct for initial aiming errors and to maintain intercept flight trajectory in the presence of atmospheric disturbances that may cause the missile to go off course. Traditionally, the use of the so-called proportional navigation (PN) guidance (law) provided the means to enable an attacking missile to maintain its intercept trajectory to its target. As aircraft became more agile and capable of high-g maneuvers, which they could use for evading an incoming threat, the PN guidance law was upgraded to the augmented PN (APN) guidance law that compensated for target maneuvers. Zarchan[24] gives a comprehensive explanation of PN and APN guidance implementation and performance. With advances in missile hardware and computer processing (on-board target tracking sensor and processors), most modern missiles now use the APN guidance. Rapid advances in autonomous system technologies have opened up the possibility that next generation aircraft will be pilotless and capable of performing “intelligent” high-g evasive maneuvers. This potential development has prompted missile guidance designers to look at techniques, such as game theory-based guidance and “intelligent” guidance to outwit potential adversaries.

Earlier reported research[16–27] on the application of game theory to the missile guidance problem has concentrated on engagement scenarios that involve two parties, comprising an attacking missile (pursuer) aimed against another missile or aircraft referred to as a target or an evader. In this book, the above approach is extended to a three-party engagement scenario that includes the situation where an attacking missile may have dual objectives—that is, to evade a defending missile and then continue its mission to engage its primary designated high-value target. The role of the defending missile is only to intercept the attacking missile; the attacking missile, on the other hand, must perform the dual role, that of evading the defending missile, as well as subsequently intercepting its primary target—the aircraft. Since participants in this type of engagement are three players (the aircraft target, the attacking missile, and the defending missile), involved in competition, we shall refer to this type of engagement scenario as a three-party game.

Game theory-based linear state feedback guidance laws are derived for the parties through the use of the well-known linear system quadratic performance index (LQPI) approach. Guidance commands generated are lateral accelerations that parties can implement in order either to intercept a target, or to evade an attacker. A missile/target engagement model has been developed, and feedback gain values are obtained by solving the matrix Riccati differential equation. Preliminary simulation results to demonstrate the characteristics of intercept and evasion strategies are included in Chapter 6. Simple (rule-based) intelligent strategies are also considered for enhancing evasion by a target or for improving the chances of intercept for an attacker.
1.2 Game Theoretic Concepts and Definitions

Game theory is concerned with studying and characterizing the dynamics of interactions between players involved in a collective and competitive activity or contest, where each player is required to make decisions regarding his/her strategy, and implement this strategy in order to gain an advantage. These decision makers will be referred to as players or parties. Each player's choice of the strategy, and the advantage gained by implementing this strategy, is defined through an objective function (OF), which that player tries to maximize. The OF in this case is also referred to as a utility function (UF), or pay-off. If a player sets out to minimize the objective function, it is referred to as a cost function (CF) or a loss function. The objective function of a player depends on the strategies (control or input variable) that a player implements in order to optimize the objective function. This involves action of at least one or more players involved in a game. The strategy that each party implements determines the strategies that the other players involved in a game are required to implement in order to achieve optimization of the objective function. This is particularly true of a competitive or non-cooperative game. In the case of a cooperative game, some or all of the parties may enter into a cooperative agreement so that the strategies selected provide collective advantage to parties in the coalition. A non-cooperative game is a non-zero-sum game if the sum of the player's objective function remains non-zero. If, however, the objective function can be made zero then the non-cooperative game will be called a zero-sum game. As far as the nature of the optimum solution is concerned it is a requirement that this solution be such that if all the players except one, and only one, execute optimum strategies, the pay-off for the player that deviates from the optimum would result in a disadvantage to this player. The optimum solution where none of the players can improve their pay-off by a unilateral move will be referred to as a non-cooperative equilibrium also known as the Nash equilibrium.[3]

A game can be either finite or infinite depending on the number of choices (moves) for the strategies available for the players. A finite game provides for a finite number of choices or alternatives in the strategy set for each player; however, if the choices in the strategy set are infinite then the game is an infinite game. For an infinite game, if the players' objective functions are continuous with respect to (w.r.t.) the action variables (strategies) of all players, then it is known as a continuous-time game. The evolution (transition or progression) of a game can be defined by the state variable (or the state of the game), which represents changes in the game environment as the players involved in the game implement their strategies. The state is a function of the prior state and the actions implemented that causes a change in the game environment. This functional relationship will be referred to as the game dynamics or the game dynamical model. We shall refer to a game as deterministic if the nature of the game dynamics model, the strategies (control variables), and the objective functions are such as to uniquely determine the outcome (the optimum solution). However, if the dynamics model, control variable, or the objective function associated with at least one of the players is defined via a probability function then the game will be referred to as a stochastic game. Stochastic games are not considered in this book. A dynamic game is said to be a differential dynamic game if the evolution of the states and of the decision process is defined through a continuous-time process, involving a set of differential equations. Where the evolution of the states and the decision occurs over discrete time intervals then the game is called a discrete-time game.
1.3 Game Theory Problem Examples

In order to develop a formal structure for the game theory problem and enable its subsequent solution in a manner that allows many of the control systems techniques to be used, we consider the following examples that have played a major role in the development of the game theory.
1.3.1 Prisoner's Dilemma

The prisoner's dilemma is a good example of a simple game that can be analyzed using the game theory principles. It was originally framed by Flood and Dresher in 1950[29] and later formalized by Tucker,[28] who named it the “prisoner's dilemma.” We consider a situation where two prisoners A and B, are being interrogated, separately, about their role in a particular crime. Each prisoner is in solitary confinement with no means of communicating with the other. The interrogator, in order to induce A and B to betray each other and confess to their role in the crime, offers the following incentive to the prisoners:

    If A and B each betray the other, each of them serves two years in prison,
    If A betrays B but B remains silent, A will be set free and B will serve three years in prison (and vice versa),
    If A and B both remain silent then both of them will only serve one year in prison (on a lesser charge).

Using the above scenario, we can construct a strategy/pay-off table for each prisoner as shown in Table 1.3.1 below, with the pay-off shown as (A's pay-off, B's pay-off):

Table 1.3.1 Strategy Versus Pay-Off.
Strategies 	A betrays B 	A keeps silent
B betrays A 	(2, 2) 	(3, 0)
B keeps silent 	(0, 3) 	(1, 1)

Assuming that both the prisoners play an optimum strategy that minimizes each prisoner's pay-off then it follows that the “best strategy” from each player's perspective is to betray the other. Any other strategy would not necessarily lead to the minimum pay-off solution. For example, if B keeps silent hoping that A will also keep silent then this may not necessarily turn out to be the case, because A (motivated by self-interest) may decide to betray B and achieve a reprieve from imprisonment.
1.3.1.1 Observations and Generalization From the Above Example

We can make the following observations arising out of the above example regarding the elements of the game theory as follows.

    A game must have players (in the particular case of the above example: A and B)—in general, however, there could be more than two players; we shall therefore define the set of players in a game as the set:
    (1.3.1)numbered Display Equation

    where
        pi; i = 1, 2, …, n: are players involved in a game.

    A game must have strategies (in the particular case of the example above, there were two strategies available to each player: keep silent or betray the other player). In general for more than two players involved in a game, there could be a number of different strategies; we shall define the strategy set as:
    (1.3.2)numbered Display Equation

    where
        i = 1, 2, …, n is the set of strategies available to player i against player j.

    Note that each strategy subset includes strategies of player i that he/she is able to exercise against another player j. In fact, player i can exercise multiple strategies against player j.

    As we shall see later, when we consider the topic of missile guidance can be either a scalar or a vector.

    A game has a cost function or a pay-off that the players either minimize or maximize in order to achieve their objectives. For this example the objective function (OF) may be written as:
    (1.3.3)numbered Display Equation

    That is, the OF is a function of players' strategies. We shall further qualify the nature of an OF later in this chapter, since in general the OF is also a function of the states of the game.

    The game considered in this example has only one move and will be referred to as a game with single epoch. In the next example we shall consider a game with multiple epochs.

    For the particular example of the prisoner's dilemma it is seen that:

    ; , here the superscripts (1,2) indicate the two components of a vector, representing two strategies.

    Also ; .

1.3.2 The Game of Tic-Tac-Toe

We now turn our attention to the well-known game of “Tic-tac-toe” (T3), which will enable us to introduce other aspects of the game theory. A generalization of this T3 game will give us a framework for formulating the game theory problem as a control systems problem, which will allow us to exploit the well-developed techniques of the optimal control. Tic-tac-toe (also known as Noughts and Crosses or O's and X's) is designed for two players, A and B, who take turns marking the spaces in a 3×3 grid. The player who succeeds in placing three of their marks in a horizontal, vertical, or diagonal row (combinations) wins the game. Let us designate player A's move with a O and B's move with an X; and the move (i.e., the position on the 3×3 grid) that a player selects to make is designated by (see Figure 1.3.1). We shall assume that A moves first. We will also refer to a move position on the grid as the “state” of the game. The author of this book has encapsulated a possible strategy (algorithm) for the play (moves) as a game theory problem where each player makes a move so as to maximize the objective function defined by the following expression:
(1.3.4)numbered Display Equation

where

    is the total number of a player's own potential winning combinations with single entries, as a result of the move k.
    is the total number of opponent's potential winning combinations with single entries that are blocked by the move k.
    is the total number of player's own potential winning combinations with double entries, as a result of the move k.
    is the total number of opponent's potential winning combinations with double entries that are blocked by the move k.
    are objective function values for players A and B respectively at epoch k.
    k: is the move number or epoch.

Diagram shows Tic-Tac-Toe (T3) game moves with X and O within box having three rows and columns and stages like state of game, move: A; k equals 1; J equals 4, move: B; k equals 1; J equals 6, et cetera.

Figure 1.3.1 Moves for the Tic-Tac-Toe (T3) Game.

It follows from (1.3.4) that maximizing the above OF for each move (epoch) is equivalent to maximizing the sum of the OF over all of the moves, that is the OF can also be written as:
(1.3.5)numbered Display Equation

1.3.2.1 Observations and Generalization From the Tic-Tac-Toe Example

A set of moves that occur through the maximization of the objective function (1.3.4) is shown in Figure 1.3.1; the values obtained from the OF are also given there. We make the following observations gleaned from the T3 game considered here:

    A T3 game may be regarded as a discrete (and a finite) game since each move is made at each epoch, which is not continuous.

    The value of the elements of the OF ni; i = 1, 2, 3, 4 depend on the strategy (move) that a player utilizes. This, in turn, depends on the current state of the game and the current strategy; thus, we may regard the OF to be a function of the strategy and the current state of the game. That is, in general we may write:
    (1.3.6)numbered Display Equation

    where

    X(k):

        is the set of states of a game at epoch k.
    U(k):

        is the set of strategies available to players at epoch k.

    Obviously a player cannot make a move to a state (position on the grid) that is already occupied by its own previous moves or those of the opponent's moves. We will regard this as state constraints.

1.4 Game Theory Concepts Generalized

From observations made in the previous section we can now define the class of game theory problems that we shall consider in this book. The main theme in this book will be the continuous-time (differential) game theory and its application to missile guidance. We shall also give a formal definition of the discrete-time games for the sake of completeness.
1.4.1 Discrete-Time Game

    A discrete game has a set of states Xk defined as the set:
    (1.4.1)numbered Display Equation

    where

        is the state vector of a game that depends on epoch k.
    k = 1, 2, …, N:

        are game epochs.

    Note that in cases where we talk about relative states we adopt the notation: .
    A discrete game has a set of players P given by:
    (1.4.2)numbered Display Equation

    A discrete game has a set of strategies Uk given by:
    (1.4.3)numbered Display Equation

    where
        is the strategy vector (input vector) available to player i against player j in a game.
    A discrete game has an objective function J(⋅⋅⋅) given by:
    (1.4.4)numbered Display Equation

    A discrete game can have rules or constraints Ck given by:
    (1.4.5)numbered Display Equation

Based on definitions (1.4.1) through (1.4.5), we may define a discrete-time game Gk as the set:
(1.4.6)numbered Display Equation

A typical example of an OF and constraints for a discrete game may be written as follows:
(1.4.7)numbered Display Equation

Where

    [⋅⋅⋅]; φ[⋅⋅⋅]: are scalar cost functions.

The dynamic constraint is given by
(1.4.8)numbered Display Equation

1.4.2 Continuous-Time Differential Game

A differential game is analogous to the discrete game with the exception that the game evolves in continuous time t and will be defined as follows:

    A differential game is assumed to have a set of states Xt defined as a set:
    (1.4.9)numbered Display Equation

    where
        is the state vector of a game, which is a function of time t; with start time t0 and end (final) time tf, with t0 ⩽ t ⩽ tf.
    A differential game has a set of players P given by:
    (1.4.10)numbered Display Equation

    A differential game has a set of strategies Ut given by:
    (1.4.11)numbered Display Equation

    where
        is the strategy vector (input vector) available to player i against player j in a game.
    A differential game has an objective function J(⋅⋅⋅) given by:
    (1.4.12)numbered Display Equation
    A differential game can have rules or constraints C given by:
    (1.4.13)numbered Display Equation

Based on definitions (1.4.9) through (1.4.13), we may define a differential game Gt as the set:
(1.4.14)numbered Display Equation

A typical example of an OF and constraints for a differential game may be written as follows:
(1.4.15)numbered Display Equation

with the dynamic constraint given by:
(1.4.16)numbered Display Equation

1.5 Differential Game Theory Application to Missile Guidance

The application of the differential game theory to the missile guidance problem requires describing the trajectory of a missile or missile dynamics as a set of differential equations of the type given in (1.4.16). The guidance objectives that a designer aims to meet can be expressed as an objective function of the type (1.4.15), which has to be optimized in order to determine guidance strategies (inputs) for missiles/aircraft involved in a given combat situation. Chapters 3, 4, and 6 are dedicated to developing the differential equations (also referred to as the system dynamics model) and the objective functions (also referred to as a performance index). In this book we shall confine ourselves to a linear system dynamical model and a performance index, which is a scalar quadratic function of system states and inputs and can be written, in a general form, respectively as:
(1.5.1)numbered Display Equation

and
(1.5.2)numbered Display Equation

where

    is the relative state of player i w.r.t. player j.
    is the input of player i.
    is the input of player j.
    F: is the state coefficient matrix.
    G: is the input coefficient matrix.
    Q: is the PI weightings matrix on the current relative states.
    S: is the PI weightings matrix on the final relative states.
    {Ri, Rj}: are PI weightings matrices on inputs.

The structure of the dynamical model (1.5.1) and that of the objective function (1.5.2) will be applicable to the game theory guidance problems considered in this book.
1.6 Two-Party and Three-Party Pursuit-Evasion Game

Consider a situation where a number of different parties are involved in a pursuit-evasion game, where each party endeavors, through the application of the game theory-based strategy to maximize its advantage as reflected in some pre-specified metric or pay-off. A typical example of a pursuer-evader game involves two parties , where the objective of the pursuer p1 is to catch up and intercept p2, whereas the evader p2 has the objective of avoiding the intercept. Clearly, one obvious objective function that both parties can use is the relative separation (projected miss-distance) between them. Let us further assume that both parties are moving w.r.t. each other in a given reference frame (e.g., the inertial frame). It can be assumed that both parties have the capability to change directions of their respective motions (maneuver capability), which they can exercise in order to achieve their objectives—p1 tries to minimize the projected miss-distance, whereas p2 tries to maximize it. This objective can be taken to be some (positive) function of the relative distance between the parties and the maneuver (input) capability, which each party can employ. One also needs to consider the extent of the manueverability of each party and the motion dynamics involved.

The above problem may be extended to a scenario where there are three or more parties involved in a pursuit-evasions game. Let us consider a situation involving three parties and specify these as . An example of this type of game is the following (it is considered in some detail in later chapters of this book):

    to represent the engagement where p3 is the pursuer and p1is the evader,
    to represent the engagement where p2 is the pursuer and p3 is the evader,
    to represent the engagement where p1 and p2 are coalition partners (i.e., neither party is a pursuer or an evader w.r.t. each other).

The particular ordering of the indices is immaterial, as long as there is no confusion as to which party is the pursuer and which one is the evader. In general, we may envisage a scenario in which the pair implies and where each party can be considered to be employing dual strategies of pursuit as well as evasion. Problems of this type can be considered under the framework of the LQPI problem.
1.7 Book Chapter Summaries

In Chapter 2, the subject of optimum control is dealt with in some detail, and results that are important in many problems of practical interest are derived. Derivations considered in this chapter rely heavily on the calculus of variation and necessary and sufficient conditions for optimality are developed for a generalized scalar cost function subject to equality constraints defined by a non-linear dynamical system model. A simple scalar cost function involving system states and control input variables is used to introduce the reader to the steady-state (single-stage decision) optimization problem utilizing the Euler-Lagrange multiplier and the Hamiltonian. The dynamic optimum control problem is then considered, where the cost function is in the form of an integral over time, of a scalar function of system states and control (input) vectors plus a scalar function of the final system states. The optimum control problem involving a linear dynamical system model, where the cost function is a time integral of a scalar quadratic function of state and control vectors is also considered in this chapter. It is shown that the solution of this problem leads to the well-known matrix Riccati differential equation, which has to be solved backward in time. The application of the optimum control results to two-party and three-party game theory problems is considered, and conditions for optimality and convergence of the Riccati equation are given. The nature of the equilibrium point is investigated and conditions for the existence of a minimum, a maximum or a saddle point are derived. Extension of the differential game theory to multi-party (n-party) games is also described.

Chapter 3 considers the application of the differential game theory to the missile guidance problem. The scenario considered involves engagement between an attacker (interceptor/pursuer) and a target (evader), where the objective of the former is to execute a strategy (or maneuvers) so as to achieve intercept with the target, whereas the objective of the latter is to execute a strategy (maneuver) so as to evade the attacker and avoid or at least delay the intercept. Differential game approach enables guidance strategies to be derived for both the attacker and the target so that objectives of the parties are satisfied. Interceptor/target relative kinematics model for a 3-D engagement scenario is derived in state space form, suitable for implementing feedback guidance laws through minimization/maximization of the performance index (PI) incorporating the game theory based objectives. This PI is a generalization of those utilized by previous researchers in the field and includes, in addition to the miss-distance term, other terms involving interceptor/target relative velocity terms in the PI. This latter inclusion allows the designer to influence the engagement trajectories so as to aid both the intercept and evasion strategies. Closed-form expressions are derived for the matrix Riccati differential equations and the feedback gains that allow the guidance strategies of the interceptor and the target to be implemented. Links between the differential game theory based guidance, the optimal guidance, the proportional navigation (PN) and the augmented PN guidance are established. The game theory-based guidance technique proposed in this chapter provides a useful tool to study vulnerabilities of existing missile systems against current and future threats that may incorporate “intelligent” guidance. The technique can also be used for enhancing capabilities of future missile systems.

In Chapter 4 we consider a three-party differential game scenario involving a target, an attacking missile, and a defending missile. We assume that this scenario involves an aircraft target that on becoming aware that it is being engaged by an attacking missile, fires a defending missile against this attacker, and itself performs a maneuver to escape the attacking missile. In order to engage the aircraft, the attacking missile performs both an evasive maneuver to defeat (evade) the defending missile and a pursuit maneuver to engage the aircraft target. A three-party game theoretic approach is considered for this scenario that uses a linear quadratic performance index optimization technique to obtain guidance strategies for the parties involved. The resulting guidance laws are then used in four degrees of freedom (4-DOF) engagement kinematics model simulation, to study the characteristics of the resulting intercept and evasion strategies. Simple (rule-based) AI techniques are also proposed in order to implement additional maneuvers to enable the parties to enhance their evasion/survival, or, in the case of the attacker, to evade the defender and subsequently achieve intercept with the target.

Chapter 5 is concerned with the development of the dynamics simulation model for performance analysis of guidance laws for missiles. This model uses a fixed-axis system convention under the assumption that the missile trajectory during an engagement can vary significantly from the collision course geometry. These models take into account autopilot lags and lateral acceleration limits, and while the guidance commands are computed in fixed axis, these are subsequently converted to body axis. This latter fact is particularly relevant in cases of engagements where the target implements evasive maneuvers, resulting in large variations of the engagement trajectory from that of a collision course. A linearized model is convenient for deriving the guidance laws (in analytical form); however, the study of their performance characteristics still requires a non-linear model that incorporates changes in body attitudes, and implements guidance commands in body axis rather than the fixed axis. In this chapter, a 4-DOF mathematical model for multi-party engagement kinematics is derived, suitable for developing, implementing, and testing modern missile guidance systems. The model developed here is suitable for both conventional and more advanced optimal intelligent guidance, particularly those based on the game theory guidance techniques. These models accommodate changes in vehicle body attitude and other non-linear effects (such as limits on lateral acceleration) and may be extended to include other aerodynamic affects.

Chapter 6 considers a simulation study of game theory-based missile guidance developed in Chapters 3, 4, and 5. The scenario considered involves an aircraft target, which is being engaged by a ground-launched missile and fires a defending missile against this attacker and itself performs a maneuver to escape the attacking missile. In order to engage the aircraft, the attacking missile first performs an evasive maneuver to defeat (evade) the defending missile and then an intercept maneuver to engage the aircraft target. Differential game approach is proposed that utilizes a linear quadratic performance index optimization technique to obtain guidance strategies for the parties; guidance strategies obtained are used in a 4-DOF simulation, to study the characteristics of the resulting intercept and evasion strategies. A simple (rule-based) AI technique is proposed for implementing additional maneuvers to enable the parties to enhance their evasion/survival or in the case of the attacker to achieve intercept.

The addendum of this chapter includes the MATLAB listing of the simulation program and a CD containing the *.m files: faruqi_dgt_DEMO.m and kinematics3.m.
1.7.1 A Note on the Terminology Used In the Book

In this book a missile has been referred to as an attacker or a defender, depending on role that it plays in an engagement; the generic term vehicle is also used for a missile or an aircraft. The term target is used to specify an aircraft target in a three-party game scenario considered; a missile can be a target if it plays this particular role. Also, while the book mostly talks about missiles, all the synthesis techniques considered in this text apply equally to “autonomous systems.” The term performance index (PI) is used to signify an objective function (OF). Terms such as a utility function (UF) and a cost function (CF) are also used, provided it is clear whether maximization or minimization of this function is considered. Terms such as kinematics model, dynamic model, or system model are used interchangeably. Terms such as input, control, or control inputs, guidance inputs/commands are used to mean the same; the term strategy is a generic term for these.
References

    Von Neumann, J., and Morgenstern, O., Theory of Games and Economic Behaviour, 3rd edition. Princeton University Press, 1980.
    Owen, G., Game Theory, 3rd edition, Academic Press, 1995.
    Basar, T., and Olsder, G. J., Dynamic Non-cooperative Game Theory, 2nd edition, SIAM Classics, 1999 (original: Academic Press, 1982).
    Vorobev, N. H., Game Theory, Springer Verlag, 1977.
    Fudenberg, J., and Tirole, J., Game Theory, MIT Press, 1991.
    Myerson, R. B., Game Theory: Analysis of Conflict, Harvard, 1991.
    Gibbons, R., Game Theory for Applied Economists, Princeton University Press, 1992.
    Isaacs R., Differential Games: A Mathematical Theory with Applications to Warfare and Pursuit, Wiley, 1965.
    Antoniades, A., Kim, H., and Sastry, S., “Pursuit–evasion strategies for teams of multiple agents with incomplete information”, Proceedings of the 42nd IEEE Conference on Decision and Control, Maui, HI, 2003; 756–761.
    Vidal, R., Shakernia, O., Kim, H., Shim, D., and Sastry S., “Probabilistic Pursuit–evasion games: theory, implementation, and experimental evaluation”, IEEE Transactions on Robotics and Automation 2002; 18(5):662–669.
    Kanchanavally, S., Ordonez, R., and Layne, J., “Mobile target tracking by networked uninhabited autonomous vehicles via hospitability maps”, Proceedings of the American Control Conference, Boston, MA, 2004; 5570–5575.
    Liu Y., Cruz Jr J. B., and Sparks A., “Coordinating networked uninhabited air vehicles for persistent area denial”, Proceedings of the 43rd IEEE Conference on Decision and Control, Paradise Island, Bahamas, 2004; 3351–3356.
    Hespanha, J., Kim, H., and Sastry, S., “Multiple-agent probabilistic pursuit–evasion games”, Proceedings of the 38th IEEE Conference on Decision and Control, Phoenix, AZ, 1999; 2432–2437.
    Li, D., Cruz Jr, J. B., Chen, G., Kwan, C., and Chang, M., “A hierarchical approach to multi-player pursuit–evasion differential games”, Proceedings of the 44th Joint Conference of CDC-ECC05, Seville, Spain, 2005; 5674–5679.
    Li, D., and Cruz Jr, J. B., “Better cooperative control with limited look-ahead”, Proceedings of American Control Conference, Minneapolis, MN, 2006; 4914–4919.
    Ben-Asher, J. Z., and Isaac, Y., Advances in Missile Guidance Theory, Vol. 180 of Progress in Astronautics and Aeronautics, AIAA, 1998.
    Isaacs, R., Differential Games, Dover Publications, 1965.
    Robb, M. C., Tsourdos, A., and White, B. A., “Earliest Intercept Line Guidance Using a Game Theory Approach”, AIAA Guidance, Navigation, and Control Conference, No. AIAA-2006-6216, 2006.
    Sage, A. P., Optimum Systems Control, Prentice Hall, 1968.
    Shinar, J., Siegel, A., and Gold, Y., “On the analysis of a complex differential game using artificial intelligence”, Proceedings of the 27th IEEE Conference on Decision and Control, 1988; 1436–1441.
    Shinar, J., Guelman, M., Silberman, G., and Green, A., “On optimal missile avoidance – a comparison between optimal control and differential game solutions”, IEEE International Conference on Control and Applications, 1989; 453–459.
    Shinar, J., and Shima, T., “A game theoretical interceptor guidance law for ballistic missile defence”, Proceedings of the35th IEEE Conference on Decision and Control, 1996; 2780–2785.
    Shinar, J., “On the feasibility of ‘hit to kill’ in the interception of a manoeuvring target”, American Control Conference, 2001; 3358–3363.
    Zarchan, P., Tactical and Strategic Missile Guidance, Vol. 199 of Progress in Astronautics and Aeronautics, AIAA, 2nd edition, 2002.
    Faruqi, F. A., “Intelligent 3-Party Game Theoretic Approach to Missile Guidance”, Proc. AAIA (Conference GNC/AFM/MST/ASC), paper 152-GNC-69 on Guidance, Navigation & Control, Aug. 2012.
    Rusnak, I., “Game based Guidance in Anti-Missile Defence for High Order Participants”, IEEE Conf. MELECON 2010, p812.
    Rusnak, I., “The target, the Missile and the Defender – A Two Team Dynamic Game”, The 16th IFAC World Congress, Prague, July 2005.
    Barbara Tucker, et al., “A.W. Tucker: Some reminiscences", Notices of the American Mathematical Society, 1995; 42 (10): 1143–1147.
    Dresher, M., The Mathematics of Games of Strategy: Theory and Applications, Prentice-Hall, 2003.

About the Companion Website
1: Differential Game Theory and Applications to Missile Guidance
Differential Game Theory with Applications to Missiles and Autonomous Systems Guidance
2: Optimum Control and Differential Game Theory




Skip to Content
Search 50,000+ courses, events, titles, and more
2
Optimum Control and Differential Game Theory
Nomenclature

    is the system state vector.
    is the input vector.
    is the vector function of state and input vectors.
    is the Euler–Lagrange multiplier vector.
    is the system coefficient matrix.
    is the input coefficient matrix.
    is the symmetric positive semi-definite matrix for PI weightings on current states.
    is the symmetric positive semi-definite matrix for PI weightings on final states.
    is the symmetric positive definite matrix for PI weightings on inputs.
    is the scalar quadratic function and defines a weighted norm of a vector .
    is the relative state vector for .
    is the input vector for .
    is the state coefficient matrix for .
    is the input coefficient matrix for .
    is the termination (final) time for an engagement.
    is the symmetric positive semi-definite matrix for PI weightings on current states.
    is the symmetric positive semi-definite matrix for PI weightings on final states.
    is the symmetric positive definite matrix for PI weightings on inputs.
    are subscript pairs for the set corresponding to the three players involved in a three-party game.

Abbreviations

EL:
    Euler–Lagrange
LHS:
    left-hand side
LQPI:
    linear system quadratic performance index
MRDE:
    matrix Riccati differential equations
PMP:
    Pontryagin's Minimum Principle
RHS:
    right-hand side
VRDE:
    vector Riccati differential equations

2.1 Introduction

This chapter is dedicated to the development of the optimum control theory, which forms the basis of control systems analysis and design for a large number of problems and those that occur in differential game theory. Theoretical developments presented here are aimed at optimization of a general, non-linear cost function (performance index) where the evolution of the states is defined by a set of non-linear differential equations. The problems that we will be most interested in are those that admit cost functions that are scalar quadratic functions of system states and control variables and where the dynamical system is linear. The generalized optimum theory developed is then applied to the linear dynamical system case. The application of the optimum control technique for a scalar quadratic cost function and linear dynamical system is utilized to develop a differential game theory solution for two-party (pursuer-evader) and three-party game scenarios. Formulation of a multi-party non-cooperative game is also given. A brief discussion of the principles of the differential game theory was included in Chapter 1; in this chapter those principles are invoked in order to develop optimum control techniques for two-, three- and multi-party games. The development of the optimal control theory relies heavily on the calculus of variation. A review of vector/matrix algebra and the associated differential calculus is given in the appendix. Material presented in this chapter will also prove useful to practitioners in fields other than engineering (e.g., economics and business applications).

In Section 2.2 we introduce the use of the Euler–Lagrange (EL) multiplier for incorporating equality constraints, and the construction of the Hamiltonian for deriving optimum control strategies for parties involved in a game. The reader is referred to the references[1–4] for further reading on the material presented in this section.

In Section 2.3, we consider the dynamic optimization problem utilizing the Bolza formulation and use variational calculus to derive necessary and sufficient conditions for optimality. Dynamic optimization implies that the cost function (also referred to as a functional) is optimized over a time interval and the evolution of system states is governed by a dynamical systems model. The Pontryagin's Minimum Principle (PMP) is explained, which is useful in solving a certain class of optimum problems with state and/or control constraints. The Hamilton-Jacobi canonic equations are derived, which lead to the necessary and sufficient conditions for optimality. Dynamic optimization problems with different initial and final conditions (the so-called transversality conditions) are considered. Much of the material presented in this section is now well established, and the references[5–10] provide useful insights into the techniques used in this section.

In Section 2.4, optimum control principles are applied to the optimization of a scalar quadratic cost function for a linear dynamical system model. This type of optimization problem is often referred to as the linear system with quadratic performance index (LQPI) problem. The solution of this problem leads to the well-known matrix Riccati differential equation (MRDE), which requires solving backward in time. For further readings on this topic the reader is directed to the references.[11–16]

In Section 2.5, we consider the application of the LQPI problem to two-party and three-party differential game guidance problems. These will be recognized as the pursuer-evader games. Solutions of these types of problems also lead to state feedback guidance laws. Necessary and sufficient conditions for the existence of the solution are also derived. Stability and convergence of the solution is considered and the nature of the equilibrium is also discussed. For further reading, the references may be useful.[17–23]
2.2 Calculus of Optima (Minimum or Maximum) for a Function

Function optimization problems that commonly occur in control systems and consequently in game theory can be solved using the “calculus of optima,” which leads to a procedure for obtaining the optimal values of a given cost function and parameter values on which this cost function depends. In this section, calculus of optima is developed for a scalar valued cost function of several variables or a vector, and necessary and sufficient conditions are derived. This approach will in turn allow us to set up a framework that will enable us to consider more complex cases. The method of Lagrange multipliers is introduced and used to solve constrained optimum control problems for a single-stage decision process.
2.2.1 On the Existence of the Necessary and Sufficient Conditions for an Optima

Here we set up, in a formal way, the objectives of the optimal problem. Material presented provides a quick overview of the basics and sets up an environment for developing a framework that will be used for solving more complex optimization problems. The general optimization problem may be stated as follows.

Given a real valued scalar cost function defined for variables , then it has a relative minimum (or maximum) at , if and only if there exists a positive number , such that:
(2.2.1)numbered Display Equation

(In the case of a maximum ); for all , provided that exists in the region . Furthermore, if exists and is continuous at , then can be an interior minimum (or maximum) if:
(2.2.2)numbered Display Equation

(2.2.3)numbered Display Equation

then the nature of the optimal value of the cost function (i.e., whether it is a minimum or a maximum or a saddle-point) can be determined (see Figure 2.2.1). In fact it can be shown that if:
(2.2.4)numbered Display Equation

Graph shows plotting of maximum as X1, minimum as X2, and saddle point as X3 and dotted line indicates X1 plus delta X1, X2 plus delta X2, and X3 plus delta X3 for nature of optimum values.

Figure 2.2.1 Nature of function optimum values.
2.2.2 Steady-State Optimum Control Problem with Equality Constraints Utilizing Lagrange Multipliers

The approach to optimizing a cost function, with equality constraints, is to make adjustments to independent variables (e.g., the states) by using an adjustable parameter, referred to as the Euler–Lagrange (EL) multiplier. This allows us to form a new cost function by adjoining the constraints of the original function through EL multiplier and optimizing the new modified cost function using the method developed in Section 2.2.1. For the optimum control problem, where both state and control variables are present in the cost function, the object of the optimization problem is to find the values of control variables (or inputs) as a function of states that minimize the given cost function. In order to demonstrate the use of the EL multiplier and to develop the necessary and sufficient conditions for optimality, we consider the problem that occurs in steady-state control (single-stage decision) as shown below. Here, we consider the optimization (minimization or maximization) of a scalar cost function given by:
(2.2.5)numbered Display Equation

Subject to equality constraints:
(2.2.6)numbered Display Equation

where

    is the system state vector.
    is the input vector.
    is the vector function of state and input vectors.

In the sequel, the terminology “state variable” and “state vector” or simply “state” will be used synonymously; similarly, “control (input) variable” and “control (input) vector” or simply “control (input)” will be taken to mean the same. Scalar state and control variable will imply a single variable/element instead of a vector. The terminology “vector function” or simply “function” are used in the sequel to mean the same algebraic structure. As a general rule vector quantities are characterized by an underscore in the variable name, for example, , whereas a scalar does not have an underscore, for example, .

We now adjoin the equality constraint (2.2.6) to the cost function (2.2.5) through vector, the EL multiplier , in order to form a scalar quantity referred to as the Hamiltonian:
(2.2.7)numbered Display Equation

where

    is the EL multiplier vector.

Necessary conditions for optimality are obtained by setting the first order variation , of due to variations in and , to zero. Writing (replacing and by) and , and expanding the terms on the RHS of (2.2.7) using Taylor series and including only first order terms, we get:
(2.2.8)numbered Display Equation

For optimality: ; which gives us the necessary conditions (for optimum solution) as:
(2.2.9)numbered Display Equation

(2.2.10)numbered Display Equation

where (see Appendix A1.3):
numbered Display Equation

In order to determine whether equations (2.2.9) and (2.2.10) yield a minimum or a maximum value (sufficient condition for optimality), we examine the second order variation , of . From equation (2.2.8), it follows:
(2.2.11)numbered Display Equation

If we now define the composite vector , then equation (2.2.11) can be written as:
(2.2.12)numbered Display Equation

where
numbered Display Equation

The condition for a minimum value for the cost function may be written as:
(2.2.13)numbered Display Equation

Similarly, for a maximum value for the cost function may be written as:
(2.2.14)numbered Display Equation

Equations (2.2.9), (2.2.10) along with (2.2.13), (2.2.14) give the necessary and sufficient conditions for optimality.
2.2.3 Steady-State Optimum Control Problem for a Linear System with Quadratic Cost Function

Given a linear system:
(2.2.15)numbered Display Equation

We wish to find the control vector so as to minimize the cost function:
(2.2.16)numbered Display Equation

where

    is the system state vector.
    is the input (control) vector.
    is the fixed disturbance vector.
    are respectively and state and input coefficient matrices.
    are respectively and PI weightings matrices, that are at least positive semi-definite.
    is an abbreviation for a scalar quadratic function .

The Hamiltonian in this case can be written as:
(2.2.17)numbered Display Equation

Necessary conditions for minimization are given by:
(2.2.18)numbered Display Equation

where is determined such that the equality constraint:
(2.2.19)numbered Display Equation

From (2.2.18) it follows that:
(2.2.20)numbered Display Equation

(2.2.21)numbered Display Equation

Note that for equation (2.2.21) to hold, matrix has to be positive definite. It is also possible to express as a function of as follows. Combining equations (2.2.18) and (2.2.20), we get:
(2.2.22)numbered Display Equation

Substituting for from equation (2.2.19), that is, , we may write equation (2.2.22) as:
(2.2.23)numbered Display Equation

After some straightforward algebraic manipulation of equation (2.2.23) it can be shown that:
(2.2.24)numbered Display Equation

Equation (2.2.24) gives the optimum value for vector; however it requires that exists. In order to verify that the solution in fact gives a minimum, we construct the matrix defined in equation (2.2.13). For our present problem:
numbered Display Equation

This is positive semi-definite if is positive semi-definite and is positive definite, which is what was assumed for the problem. Thus the solution to the optimum problem in this case results in a minimum value for the cost function.

Example 2.2.1

Let us assume the following parameters for the above problem with the cost function and system equation given by: ; ; then: ; ; . Figure 2.2.2 illustrates the solution.
Graph shows circle plotted on u versus x which has points like J equals 1/2, dotted lines indicating X equals ½, and u equals -1/2 and straight line outside circle indicates x - u equals 1.

Figure 2.2.2 Example 2.2.1.
2.3 Dynamic Optimum Control Problem
2.3.1 Optimal Control with Initial and Terminal Conditions Specified

A dynamic optimization control (Bolza) problem is characterized by a cost function (functional), which is of the form:
(2.3.1)numbered Display Equation

where the state and input variables (vectors) and satisfy the non-linear vector differential equation, also referred to as the control system dynamic model, given by:
(2.3.2)numbered Display Equation

where

    is the system state vector with an initial condition: and the final condition .
    is the input (control) vector.
    is the vector function of state and input vectors.

More general boundary conditions may be specified as and ; here: is an vector and is a vector, ; and are respectively and matrices.

The object here is to determine the control vector so as to optimize the cost function (2.3.1) subject to the constraint defined by the differential equation (2.3.2). In order to include this equality constraint in the cost function we utilize the EL multiplier, mentioned earlier. This gives us a modified cost function, which is given by:
(2.3.3)numbered Display Equation

We now define a scalar function, the Hamiltonian as:
(2.3.4)numbered Display Equation

Using equation (2.3.4), we can write the cost function (2.3.3) as:
(2.3.5)numbered Display Equation

Integrating the last term in the integrand of (2.3.5), we get:
(2.3.6)numbered Display Equation

Considering the variations and about the optimal trajectory , we get for first order variation of the cost function (2.3.6) the following:
(2.3.7)numbered Display Equation

Note that for convenience the notation of explicit dependence on time is dropped. The necessary condition for optimality can be obtained by setting for arbitrary and ; which gives us:
(2.3.8)numbered Display Equation

(2.3.9)numbered Display Equation

(2.3.10)numbered Display Equation

(2.3.11)numbered Display Equation

2.3.2 Boundary (Transversality) Conditions

    For problems where the terminal state is not defined and where the initial state is specified, the boundary (transversality) condition may be written as:
    (2.3.12)numbered Display Equation

    Since is fixed, therefore, , and is arbitrary. This situation is depicted in Figure 2.3.1(a).
    In problems where both and are fixed, that is, , we get a two point boundary value problem. This situation is depicted in Figure 2.3.1(b).
    In problems where , and both , are arbitrary, that is, then equation (2.3.8) gives us: as boundary conditions. This situation is depicted in Figure 2.3.1(c).
    If the initial condition is fixed, that is, , while the terminal condition is specified by, say, , then it follows from this equality and equation (2.3.8) that the boundary conditions are given by:
    (2.3.13)numbered Display Equation

Graphs show plotting a, b, and c on x(t) versus t and curves X1, X2, and X3 begin at point t0 on x(t) in graphs a and b and curves end at point tf on t in graph b, whereas c does not start nor end at t0 and tf.

Figure 2.3.1 Boundary (transversality) conditions.
Graph shows plotting on x (t) versus t, with curves x plus delta x which start from t0 and end at tf plus delta tf and tf, respectively, and region between at tf plus delta tf and tf is delta x.

Figure 2.3.2 Unspecified final time.

In many applications the initial and terminal conditions are defined in a more general way, through a manifold specified as follows:
(2.3.14)numbered Display Equation

(2.3.15)numbered Display Equation

where is a vector and is a vector; .

These boundary conditions can be incorporated in the optimum problem by including them in the cost function by means of EL multipliers and as follows:
(2.3.16)numbered Display Equation

The first variation of the cost function, in this case is given by:
(2.3.17)numbered Display Equation

Setting , we obtain conditions for optimality as follows:
(2.3.18)numbered Display Equation

(2.3.19)numbered Display Equation

(2.3.20)numbered Display Equation

The boundary (transversality) conditions are given by:
(2.3.21)numbered Display Equation

(2.3.22)numbered Display Equation

along with the boundary conditions (2.3.14) and (2.3.15).

Equation (2.3.18) will be referred to as the adjoint equation. Equation (2.3.19) provides the coupling between the original system dynamics (2.3.2) and the adjoint operator . Note that for equation (2.3.20) to be valid, must be completely arbitrary. For the case where is not completely arbitrary (e.g., in the case of control constraints) then equation (2.3.20) will not hold. To solve optimum control problems where is bounded (constrained), Pontryagin's Minimum Principle can be used as discussed later.

Example 2.3.1

Given the following cost function to be minimized and a (scalar) system dynamic model:
(2.3.23)numbered Display Equation

(2.3.24)numbered Display Equation

For convenience, we shall assume that the parameters are constants, and , .

Case 1:

Assume that the boundary conditions are specified by and unspecified:

Then the Hamiltonian is given by:
(2.3.25)numbered Display Equation

And equations (2.3.18) through (2.3.20) give us:
(2.3.26)numbered Display Equation

(2.3.27)numbered Display Equation

(2.3.28)numbered Display Equation

which must satisfy the boundary condition (2.3.8):
(2.3.29)numbered Display Equation

Assuming that is of the form: , then it can be shown that equations (2.3.26) through (2.3.28) may be combined to give us:
(2.3.30)numbered Display Equation

Since (2.3.30) must hold for all , hence, the solution of the optimization problem requires that the following differential equation must be solved:
(2.3.31)numbered Display Equation

This is the Riccati equation, which must be solved backward in time from to . The value of can be substituted in (2.3.28) to construct . This case is further considered in Section 2.4.

Case 2:

Assume that the boundary conditions are specified by and ; and the cost function to be minimized is:
(2.3.32)numbered Display Equation

Then the Hamiltonian is given by:
(2.3.33)numbered Display Equation

And equations (2.3.18) through (2.3.20) give us:
(2.3.34)numbered Display Equation

(2.3.35)numbered Display Equation

(2.3.36)numbered Display Equation

In this case , since both , are fixed, and , are arbitrary. Equations (2.3.35) and (2.3.36) may be combined to give us:
(2.3.37)numbered Display Equation

whose general solution may be written as [see Appendix A1.9]:
(2.3.38)numbered Display Equation

Also, the general solution of (2.3.34) may be written as:
(2.3.39)numbered Display Equation

Equations (2.3.38) and (2.3.39) may be combined to give us:
(2.3.40)numbered Display Equation

Note that for and bounded, then is also bounded; in fact:
(2.3.41)numbered Display Equation

and:
(2.3.42)numbered Display Equation

For the case of a cost function of the type: , the solution to the problem with , , becomes a two-point boundary problem for which there is no closed form solution, and requires an iterative technique such as a dynamic or a differential dynamic technique to obtain a solution (e.g., see references).[3,4]

Example 2.3.2

Given the following cost function to be minimized and the system dynamic model as:
(2.3.43)numbered Display Equation

and:
(2.3.44)numbered Display Equation

The boundary conditions are defined by initial and final manifolds:
(2.3.45)numbered Display Equation

(2.3.46)numbered Display Equation

The Hamiltonian is given by:
(2.3.47)numbered Display Equation

The necessary conditions (2.3.9) through (2.3.11) for optimality are given by:
(2.3.48)numbered Display Equation

(2.3.49)numbered Display Equation

(2.3.50)numbered Display Equation

The boundary conditions (2.3.14) through (2.3.15) and (2.2.21) through (2.2.22) are given by:
(2.3.51)numbered Display Equation

(2.3.52)numbered Display Equation

(2.3.53)numbered Display Equation

(2.3.54)numbered Display Equation

Although the differential equations (2.3.48) through (2.3.50) are linear, however, once we take into account the boundary conditions (2.3.51) through (2.3.54), the solution becomes non-linear and somewhat complicated and requires iterative techniques to solve the problem.
2.3.3 Sufficient Conditions for Optimality

In order to investigate the nature of the optimum solution (i.e., minimum, maximum, or a saddle point) we need to examine the second variation of in equation (2.3.6), given that the first variation of (2.3.2) is zero, that is:
(2.3.55)numbered Display Equation

We consider the second order variation of equation (2.3.6) (see Appendix, Sections A2.3 to A2.5) which gives us:
numbered Display Equation

which may be written, in matrix notation, as:
(2.3.56)numbered Display Equation

or equivalently:
(2.3.57)numbered Display Equation

where
(2.3.58)numbered Display Equation

This implies that both the matrices and the one inside the square bracket in equation (2.3.58) must be positive semi-definite for a minimum value for the cost function (and negative definite for a maximum value), and “mixed” (i.e., has both positive and negative eigenvalues) for a saddle point.
2.3.4 Continuous Optimal Control with Fixed Initial Condition and Unspecified Final Time

In this section we consider the problem where the initial time and states are specified while the terminal time is unspecified, and the terminal state vector is defined via a terminal manifold. The development considered in the previous sections can be extended to this case. Accordingly, we consider the problem of optimizing the cost function:
(2.3.59)numbered Display Equation

for the dynamical system described by the differential equation:
(2.3.60)numbered Display Equation

where is fixed, and the terminal time is unspecified; the final state satisfies the condition given by the vector manifold:
(2.3.61)numbered Display Equation

As in previous sections, we use EL multipliers and in order to adjoin the equality constraints (2.3.60) and (2.3.61) to the cost function as follows:
(2.3.62)numbered Display Equation

If we now define the Hamiltonian as:
(2.3.63)numbered Display Equation

Then (2.3.62) may be written as:
(2.3.64)numbered Display Equation

Integrating by parts the second term inside the integrand, we get:
(2.3.65)numbered Display Equation

Consider first order variations of the above expression by making the following substitutions:
(2.3.66)numbered Display Equation

(2.3.67)numbered Display Equation

(2.3.68)numbered Display Equation

(2.3.69)numbered Display Equation

Substituting (2.3.66) through (2.3.69) in equation (2.3.65) it is seen that:
(2.3.70)numbered Display Equation

Terms that occur in (2.3.70) of the type: may be further simplified as follows:
numbered Display Equation

By considering only the first order terms, this reduces to:
(2.3.71)numbered Display Equation

where

    , (see Figure 3.2.1).

Hence we may write (2.3.70) as:
(2.3.72)numbered Display Equation

It will be easier (for the reader) to follow the subsequent development if we consider one term at a time on the RHS of (2.3.72), thus:

    The first term:
    (2.3.73)numbered Display Equation
    The second term:
    (2.3.74)numbered Display Equation
    The third term:
    (2.3.75)numbered Display Equation
    The fourth term:
    (2.3.76)numbered Display Equation
    And the fifth term:
    (2.3.77)numbered Display Equation

It is now a straightforward matter to verify, by comparing the expression for given in equation (2.3.65) and the expression for given in equation (2.3.70) (utilizing the expansion of the variational terms given in equations (2.3.73) through (2.3.77)), that:
(2.3.78)numbered Display Equation

Making the substitution:
numbered Display Equation

It follows that equation (2.3.78) may be written as:
(2.3.79)numbered Display Equation

Necessary conditions for optimality are derived by setting in equation (2.3.79). Examining the integrand in (2.3.79), we may now write the (necessary) conditions for optimality, which are given by:
(2.3.80)numbered Display Equation

(2.3.81)numbered Display Equation

(2.3.82)numbered Display Equation

(2.3.83)numbered Display Equation

Equations (2.3.81) through (2.3.82) represent differential equations in () as a two-point boundary value problem, with the initial condition:
(2.3.84)numbered Display Equation

and terminal conditions given by [see equation (2.3.79)]:
(2.3.85)numbered Display Equation

(2.3.86)numbered Display Equation

(2.3.87)numbered Display Equation

since is arbitrary.

Equation (2.3.85) defines conditions with EL multipliers to be determined. Equation (2.3.86) provides equations to eliminate the EL multipliers; equation (2.3.87) provides one further equation to determine the final time.

Example 2.3.3

We consider the following cost function and the dynamical system given by:
(2.3.88)numbered Display Equation

and
(2.3.89)numbered Display Equation

The boundary conditions are defined by the initial and final conditions: , and . For this problem [see equations (2.3.59) and (2.3.61)]:
numbered Display Equation

The Hamiltonian is given by:
(2.3.90)numbered Display Equation

Conditions for optimality (canonical equations) are:
(2.3.91)numbered Display Equation

(2.3.92)numbered Display Equation

(2.3.93)numbered Display Equation

The boundary conditions are given by [see equations (2.3.85) through (2.3.87)]:
(2.3.94)numbered Display Equation

(2.3.95)numbered Display Equation

(2.3.96)numbered Display Equation

Examination of equation (2.3.92) gives us: ; , with . Hence ; and . In view of the final condition: , we must select the positive sign for , that is, ; and .

Examination of equation (2.3.91), after appropriate substitutions for known values, gives us: ; , which gives us the value for as .
2.3.5 A Further Property of the Hamiltonian

Here we derive one further property of the Hamiltonian that will prove useful in solving many optimum problems particularly those involving control constraints [see Section 2.3.3].

Differentiating the Hamiltonian of equation (2.3.80) w.r.t. yields:
(2.3.97)numbered Display Equation

Using the relations given in equation (2.3.82) and (2.3.83), and noting that: , equation (2.3.97) may be written as:
(2.3.98)numbered Display Equation

We note that if and are not explicit functions of time , then the Hamiltonian is constant along the optimal trajectory where ; in fact, it can also be shown that Hamiltonian is constant along the optimal trajectory even if we are unable to show that . This will be used in Example 2.3.4.
2.3.6 Continuous Optimal Control with Inequality Control Constraints—the Pontryagin's Minimum (Maximum) Principle

In the previous section we considered the Bolza problem where there were no constraints on control variables in which case first variation of , that is, is unrestricted, and we were justified in setting . However, there is a large class of problems where the control variables are subject to inequality constraints, for example, the case where there may be maximum and minimum limits on the control (g-limits on vehicle acceleration, for example). In such cases, and are restricted and we are no longer justified to set . In order to solve such problems we need to establish the optimality conditions through the use of the Pontryagin's Minimum (Maximum) Principle (PMP). Accordingly, we shall, in this section, consider the following problem.

Here we wish to optimize the cost function:
(2.3.99)numbered Display Equation

for the system described by the vector differential equation:
(2.3.100)numbered Display Equation

where is fixed and where at the unspecified terminal time ; the vector manifold for the final state is given by:
(2.3.101)numbered Display Equation

and where the control variable is restricted to the set which contains functions in that satisfy a condition of the type:
(2.3.102)numbered Display Equation

In a general case is a function of , however, for problems considered here constraints given in equation (2.3.102) are appropriate. In fact, we can afford to be somewhat more specific as in many problems of practical interest, control constraints may be written as: . As in previous sections we define the Hamiltonian as:
(2.3.103)numbered Display Equation

A detailed derivation of PMP is given in the references.13 Here we shall state the PMP as follows: The Hamiltonian (canonical) equations that minimize a cost function and determine the optimum state and control vectors: , and , satisfy the condition that:
(2.3.104)numbered Display Equation

and that:
(2.3.105)numbered Display Equation

(2.3.106)numbered Display Equation

Subject to the boundary conditions:
(2.3.107)numbered Display Equation

(2.3.108)numbered Display Equation

(2.3.109)numbered Display Equation

(2.3.110)numbered Display Equation

The variables and notations used in the above equations are the same as those introduced earlier in this chapter. An example of this type of problem (minimum time problem) is where the boundary conditions are given by:
numbered Display Equation

In this case it is easily verified that: , at ; and we are required to solve the following differential equations for :
(2.3.111)numbered Display Equation

(2.3.112)numbered Display Equation

(2.3.113)numbered Display Equation

Example 2.3.4

(The minimum time problem): We consider the following cost function and the dynamical system given by:
(2.3.114)numbered Display Equation

(2.3.115)numbered Display Equation

where the admissible set implies:
(2.3.116)numbered Display Equation

The Hamiltonian is given by:
(2.3.117)numbered Display Equation

In order to minimize the value of w.r.t. we assume:
(2.3.118)numbered Display Equation

Note that this choice of satisfies the minimum condition for (2.3.117). The canonical equations are:
(2.3.119)numbered Display Equation

The boundary conditions are: , , and is determined by equation (2.3.110), which gives:
(2.3.120)numbered Display Equation

Using equation (2.3.98) it can be shown that , since does not depend explicitly on ; hence:
(2.3.121)numbered Display Equation

This provides the additional condition required to determine .
2.4 Optimal Control for a Linear Dynamical System
2.4.1 The LQPI Problem—Fixed Final Time

In this section we consider the optimum control problem commonly referred to as the linear system quadratic performance index (LQPI); the terms “performance index” and “cost function” will be taken to mean the same. Accordingly, we now consider derivation of the optimal feedback control law for a linear dynamical system model defined by the following vector differential equation:
(2.4.1)numbered Display Equation

where

    is the time with ; is the initial time and is the final time.
    is the state vector.
    is the input (control) vector.
    is the state coefficient matrix.
    is the input coefficient matrix.

We wish to minimize the cost function, which is a quadratic scalar function of states and control given by:
(2.4.2)numbered Display Equation

where

    is the symmetric positive semi-definite current-state PI weightings matrix.
    is the symmetric positive semi-definite final-state PI weightings matrix.
    is the symmetric positive definite control PI weightings matrix.
    is the scalar quadratic function and defines a weighted norm of a vector .

The term is inserted for convenience as will become evident later. Scalar quadratic terms in (2.4.2) imply that minimization of the cost function is equivalent to minimizing deviations of system states and control inputs from a nominal value (zero in this case). The elements of the matrices will be referred to as “weightings” on state and control variables. The requirement that be symmetric is quite general whereas the requirement that be positive semi-definite and be positive definite is necessary in order for a solution to the minimization problem to exist.

We see that equation (2.4.2) has the same form as (2.3.1) used earlier in general derivations with the following substitutions:
(2.4.3)numbered Display Equation

(2.4.4)numbered Display Equation

The Hamiltonian in this case may be written as:
(2.4.5)numbered Display Equation

As shown in Section 2.3, equations (2.3.60) through (2.3.62), necessary conditions for minimization for this case, require that:
(2.4.6)numbered Display Equation

(2.4.7)numbered Display Equation

(2.4.8)numbered Display Equation

With terminal conditions:
(2.4.9)numbered Display Equation

Equation (2.4.7) yields:
(2.4.10)numbered Display Equation

In order to convert this expression for the input into a feedback form, we assume a solution for of the form:
(2.4.11)numbered Display Equation

Substituting this value of in equation (2.4.1) gives us:
(2.4.12)numbered Display Equation

Substituting for into equation (2.4.6) gives us:
(2.4.13)numbered Display Equation

Combining equation (2.4.12) with equation (2.4.13) it is easily verified that:
(2.4.14)numbered Display Equation

Since this equation is true for all , it follows that:
(2.4.15)numbered Display Equation

Equation (2.4.15) is the well-known MRDE with the terminal condition that:
(2.4.16)numbered Display Equation

From examination of the structure of the MRDE it follows that is a symmetric matrix. For a solution of equation (2.4.15) to exist with the terminal condition given by equation (2.4.16) matrix must be positive definite. It can be shown that this solution of the MRDE converges to a steady-state value as . If we compute the second derivative then it can be shown that: ; which is positive semi-definite, since were all taken to be at least positive semi-definite, indicating that the solution of the optimization problem considered in this section gives a minimum value for the cost function . The feedback control law may be written as:
(2.4.17)numbered Display Equation

where

    is referred to as the feedback gain (matrix).

It is shown in the Appendix that the second variation matrix equation (A1.8.4) has a set of eigenvalues which are positive, leading to the conclusion that the optimum solution gives a minimum value for the cost function.
2.5 Optimal Control Applications in Differential Game Theory

In this section we shall consider the application of the optimal control theory developed thus far to game theory-based guidance involving two or more players (parties). Game theory application to a two-party game is quite straightforward and is considered in Section 2.5.1. The approach adopted is similar to the LQPI problem considered in Section 2.4. A good example of this application is the well-known pursuit-evasion game involving an interceptor launched against a target. Here the interceptor tries to minimize the miss-distance in order to achieve an intercept while the target tries to maximize the miss-distance in order to escape and thus avoid intercept. Both parties in this scenario need to generate control (guidance) strategies that are usually the commanded lateral accelerations applied to vehicles such as missiles or aircraft or appropriate maneuvers in order to achieve their objectives.

In the case of a three-party (or multi-party) game the situation is somewhat more complex. In Section 2.5.2, we shall consider a three-party game scenario amongst the players {p1, p2, p3} in engagements involving pairs {p1, p2}, {p2, p3} and {p3, p1}. Later in Chapters 4 and 6 we shall look at a special case of the three-party game where the set {p1, p2} represents a neutral set, that is, neither party is the pursuer or the evader w.r.t. to the other. On the other hand, for the pair {p2, p3}, p2 represents the pursuer and p3 is the evader; and for the pair {p3, p1}, p3 represents the pursuer and p1 is the evader. Such a scenario will be referred to as a cooperative three-party game, since parties {p1, p2} are cooperating with each other.

The case of one party attacking two other parties or two parties attacking one party gives rise to stochastic game theory problem and is outside the scope of the current text. Theoretical developments given in this section are general enough such that the methodology developed here may be applied to fields other than missiles and autonomous systems.
2.5.1 Two-Party Game Theoretic Guidance for Linear Dynamical Systems

In this section we consider derivation of the optimal feedback control (guidance) laws (control strategies) and for the parties {p1, p2} respectively, in a non-cooperative game such that the state evolution of the game can be represented by a linear dynamical system model defined by the following vector differential equation:
(2.5.1)numbered Display Equation

where

    is the state vector, which represents common (relative) state vector of the players (adversaries) in a game.
    is the input vector of player p1 against p2.
    is the input vector of player p2 against p1.
    is the state coefficient matrix.
    is the input coefficient matrix for p1.
    is the input coefficient matrix for p2.

Remarks

    Here, we have selected the relative states to represent the relative positions and velocities of the parties in Cartesian coordinates, along x, y, z directions. The control or the input variables are taken to be the demanded accelerations (lateral accelerations) also directed along x, y, z.
    For the two-party game considered in this section, we shall assume that p1 is the pursuer and p2 is the evader. Thus we minimize the cost function, which represents relative separation between p1 and p2, w.r.t. to the control effort applied by p1, and maximize this same cost function w.r.t. to the control effort applied by p2.

The general non-cooperative two-party game theoretic optimization problem may be stated as follows: Given a cost function of the form:
(2.5.2)numbered Display Equation

where

    is the time with ; , with the final time assumed fixed.

We desire to find control strategies of players {p1, p2} respectively, so as to minimize w.r.t. to and maximize w.r.t. to . That is, given that the state evolution of the game can be defined by (2.5.1), we wish to find such that the following conditions are satisfied:
(2.5.3)numbered Display Equation

As in the previous section, a convenient cost function to use, particularly in conjunction with a linear dynamical system model, is a quadratic scalar function of states and controls. Since we wish to minimize the cost function w.r.t. (the pursuer) and maximize this same function w.r.t. (the evader), we can simplify the problem by treating it as that of minimizing the cost function , where the quadratic term involving has a negative sign as shown below:
(2.5.4)numbered Display Equation

where

    is the symmetric positive semi-definite current-state PI weightings matrix.
    is the symmetric positive semi-definite final-state PI weightings matrix.
    is the symmetric positive definite input PI weightings matrix for p1.
    is the symmetric positive definite input PI weightings matrix for p2.

By including the quadratic term in the cost function, with a negative sign, the optimization problem reduces to that of simply minimizing of equation (2.5.4), that is:
(2.5.5)numbered Display Equation

Let us form the Hamiltonian as:
(2.5.6)numbered Display Equation

As shown in Section 2.4.1 (equations (2.4.4) through (2.4.7)), necessary conditions for minimization require that:
(2.5.7)numbered Display Equation

(2.5.8)numbered Display Equation

(2.5.9)numbered Display Equation

(2.5.10)numbered Display Equation

with the terminal condition:
(2.5.11)numbered Display Equation

Equations (2.5.8) and (2.5.9) yield:
(2.5.12)numbered Display Equation

(2.5.13)numbered Display Equation

In order to convert this control into a state feedback form, we assume a solution for of the form:
(2.5.14)numbered Display Equation

This gives us expressions for and as functions of (the feedback control):
(2.5.15)numbered Display Equation

(2.5.16)numbered Display Equation

Substituting these values of , in equation (2.5.1) gives us:
(2.5.17)numbered Display Equation

Substituting for into equation (2.5.7) gives us:
(2.5.18)numbered Display Equation

Combining equation (2.5.17) with equation (2.5.18) we get:
(2.5.19)numbered Display Equation

Since this equation is true for all , it follows that:
(2.5.20)numbered Display Equation

Equation (2.5.20) is the MRDE with the terminal condition given by:
(2.5.21)numbered Display Equation

As in the previous section, the matrix Riccati equation (2.5.21) has to be solved backward in time, with being symmetric positive definite matrix. The solution converges to a steady-state value as . For a stable solution to exist for the MRDE (2.5.20):
(2.5.22)numbered Display Equation

State feedback controls (guidance laws) for p1 and p2 may be written as feedback, respectively as:
(2.5.23)numbered Display Equation

(2.5.24)numbered Display Equation

where
(2.5.25)numbered Display Equation

(2.5.26)numbered Display Equation

It is shown in the Appendix that the second variation matrix equation (A1.8.18) has a set of eigenvalues which are both negative and positive, leading to the conclusion that the optimum solution gives a saddle point. This is to be expected in the case of the (unbiased) game theoretic optimization problem. A block diagram for the implementation of control laws is given in Figure 2.5.1.
Diagram shows circuit with F12, K12, and K21, where F12 goes to S and K12 and K21 go to G12 and G21 through u12 and u21, respectively, and further goes to S which move to 1/S through u and x12.

Figure 2.5.1 Two-party feedback control block diagram.
2.5.2 Three-Party Game Theoretic Guidance for Linear Dynamical Systems

In this section we consider the derivation of optimal control (guidance) laws for a three-party game between the pairs: {p1, p2}, {p2, p3} and {p3, p1} respectively, associated with the three parties {p1, p2, p3}. The notation used here is that the control variables represent strategies for pi engaged in the play with pj and pk respectively. Note that the total control effort that pi can exercise is: ; thus for every engagement that pi is involved in, both control variables and appear in the associated dynamic model. Similarly, notation for the common relative state is used in conjunction with the engagement involving the pair {pi, pj}.

In view of remarks made above, a three-party game yields three dynamical models, which may be written as:
(2.5.27)numbered Display Equation

(2.5.28)numbered Display Equation

(2.5.29)numbered Display Equation

The initial conditions are given by: .

where

    The subscript pair is an element of the set of subscripts that correspond to parties involved in a particular engagement.
    is the state vector for {pi, pj}.
    is the input vector (control) for {pi, pj}.
    is the state coefficient matrix for system dynamics relating to {pi, pj}.
    is the input coefficient matrix for system dynamics relating to {pi, pj}.

Remarks

    Note that the first kinematics equation (2.5.27) contains control terms , corresponding to {p1, p2}; the second equation (2.5.28) contains control terms , corresponding to {p2, p3}; and the third equation (2.5.29) contains control terms , , corresponding to {p3, p1}. The reader is also referred to Chapter 1 for further discussion on three-party game constructs.
    The situation considered above is a general one where each party is applying control effort against the other two parties. Here, it is assumed that the following simultaneous pursuit and evasion games take place between the three parties:
        p1 is the pursuer against p2 who is trying to evade p1—hence represents the pursuit strategy of p1, and represents the evasion strategy of p2.
        p2 is the pursuer against p3 who is trying to evade p2—hence represents the pursuit strategy of p2, and represents the evasion strategy of p3.
        p3 is the pursuer against p1 who is trying to evade p3—hence represents the pursuit strategy of p3 and represents the evasion strategy of p1.
    As noted in the previous section, we have selected the relative states to represent the relative positions and velocities of the parties in Cartesian coordinates, along x, y, z directions. The control or the input variables are taken to be the demanded accelerations (lateral accelerations) also directed along x, y, z.
    For the three-party game considered in this section, we shall assume that p1 is the pursuer and p2 is the evader. Thus we minimize the cost function, which represents relative separation between p1 and p2, w.r.t. to the control effort applied by p1, and maximize this same cost function w.r.t. to the control effort applied by p2. Similar considerations hold for pairs , and .

The optimization problem to be considered in this section requires three cost functions, one for each engagement (play) that has to be optimized. The relative state and control vectors and the cost function correspond to the parties involved in the play. The three cost functions may be written as:
(2.5.30)numbered Display Equation

(2.5.31)numbered Display Equation

(2.5.32)numbered Display Equation

where

    is the final/termination time for an engagement.
    is the symmetric positive semi-definite current-state PI weightings matrix.
    is the symmetric positive semi-definite final-state PI weightings matrix.
    is the symmetric positive semi-definite input PI weightings matrix.

As noted in the previous section, since the cost functions above have one of the quadratic terms in control variable with a negative sign the min/max problem reduces to a minimization problem. Control variables that occur in both the dynamical model as well as in the related cost function are used to derive the state feedback control (guidance) law, whereas control variables that appear in the dynamical model but not in the related cost function are treated as disturbance inputs. Thus, for example, if we examine the dynamical model (2.5.27) and the related cost function (2.5.30), we notice that control variables appear in the dynamic model but only are present in the cost function; hence these control variables yield the state feedback control portion while , which are regarded as disturbance inputs, have to be computed using the vector Riccati differential equations (VRDE) as shown in this section.

Expression for the three Hamiltonians may be written as follows:
(2.5.33)numbered Display Equation

(2.5.34)numbered Display Equation

(2.5.35)numbered Display Equation

Necessary conditions for minimization of the Hamiltonian require that:
(2.5.36)numbered Display Equation

(2.5.37)numbered Display Equation

(2.5.38)numbered Display Equation

(2.5.39)numbered Display Equation

with the terminal condition:
(2.5.40)numbered Display Equation

Here, we shall regard as the direct inputs and as indirect inputs.

Similarly, for the optimization problem involving we get:
(2.5.41)numbered Display Equation

(2.5.42)numbered Display Equation

(2.5.43)numbered Display Equation

(2.5.44)numbered Display Equation

with the terminal condition:
(2.5.45)numbered Display Equation

Here are the direct inputs and are indirect inputs.

For the optimization problem defined by we get:
(2.5.46)numbered Display Equation

(2.5.47)numbered Display Equation

(2.5.48)numbered Display Equation

(2.5.49)numbered Display Equation

with the terminal condition:
(2.5.50)numbered Display Equation

Here are the direct inputs and are indirect inputs.

Equations (2.5.37) and (2.5.38); (2.5.42) and (2.5.43); and (2.5.47) and (2.5.48) give:
(2.5.51)numbered Display Equation

(2.5.52)numbered Display Equation

(2.5.53)numbered Display Equation

(2.5.54)numbered Display Equation

(2.5.55)numbered Display Equation

(2.5.56)numbered Display Equation

In order to convert the above control expressions to state feedback control, we assume a solution for of the form:
(2.5.57)numbered Display Equation

(2.5.58)numbered Display Equation

(2.5.59)numbered Display Equation

Thus the feedback control expressions using equations (2.5.25) through (2.5.30) may be written as:
(2.5.60)numbered Display Equation

(2.5.61)numbered Display Equation

(2.5.62)numbered Display Equation

(2.5.63)numbered Display Equation

(2.5.64)numbered Display Equation

(2.5.65)numbered Display Equation

Substituting these feedback values for control components into system dynamics equations, we get:
(2.5.66)numbered Display Equation

(2.5.67)numbered Display Equation

(2.5.68)numbered Display Equation

Substituting for , , from equations (2.5.57) through (2.5.59) into (2.5.36), (2.5.42), and (2.5.46), respectively, gives us:
(2.5.69)numbered Display Equation

(2.5.70)numbered Display Equation

(2.5.71)numbered Display Equation

Substituting for , , from (2.5.66) through (2.5.68) into (2.5.69) through (2.5.71), we get:
(2.5.72)numbered Display Equation

(2.5.73)numbered Display Equation

(2.5.74)numbered Display Equation

The above equations must hold for all , , ; thus, one way to satisfy this condition is to require that:
(2.5.75)numbered Display Equation

(2.5.76)numbered Display Equation

(2.5.77)numbered Display Equation

with terminal conditions: , ,

Also
(2.5.78)numbered Display Equation

(2.5.79)numbered Display Equation

(2.5.80)numbered Display Equation

with terminal conditions: .

In Chapter 4, these equations are solved in order to obtain closed form solutions for MRDE and VRDE to enable us to construct state feedback guidance laws for the parties involved in three-party pursuit and evasion.
2.6 Extension of the Differential Game Theory to Multi-Party Engagement

In this section, we lay down the foundations of the optimum game theory for the case where n-players (parties) are involved in a non-cooperative game. As before, we assume that the system dynamical model is linear and the cost function is of quadratic form, and hence for player pairs: {pi, pi + 1}, we may write the dynamic model as:
(2.6.1)numbered Display Equation

where

    .
    are state and input vectors.
    are state and input coefficient matrices.

We can, as indicated in the three-party game, construct the quadratic cost functions and the corresponding Hamiltonian for as follows:
(2.6.2)numbered Display Equation

(2.6.3)numbered Display Equation

Weighting matrices are defined in the same way as before.

The solution for this case will proceed in the same way as for the three-party case, and is left as an exercise for the reader.
2.7 Summary and Conclusions

In this chapter the subject of optimum control has been dealt with in some detail and results that are important in many cases of practical interest have been derived. Calculus of variation was utilized and the necessary and sufficient conditions for optimality derived for a generalized scalar cost function subject to the (equality) constraints. A simple scalar cost function involving system state and control is used to introduce the reader to the steady-state (single-stage decision) optimization problem in Section 2.2. The EL multiplier was used to incorporate equality constraints. The Hamiltonian function was used to generate necessary and sufficient conditions for optimality.

The dynamic optimum control (Bolza) problem was considered in Section 2.3. The cost function used was an integral over time involving a scalar function of system state and control vectors plus a scalar function of the final system states. Boundary conditions were defined via initial and terminal state manifolds and the system model was defined by a vector differential equation. In this development as in the previous, the EL multiplier and the Hamiltonian were used to derive the necessary and sufficient conditions for optimality. The problem where the initial conditions are defined but the final time is unspecified was also considered in Section 2.3. The topic of Pontryagin's Minimum Principle as it applies to the optimum control problem was also considered.

The optimum control problem involving linear dynamical systems where the cost function was a scalar quadratic function was considered in Section 2.4; it was shown that the solution of this problem leads to the well-known matrix Riccati differential equation that has to be solved backward in time. This type of problem constitutes an important class that has application to linear regulator control design and as shown in this chapter provided a template for solving problems in differential game theory.

Section 2.5 of this chapter was dedicated to the application of the optimal control concepts to two-party and three-party game theory. Conditions for optimality and convergence of the MRDE were given and the nature of the equilibrium point was investigated to show that saddle point conditions were satisfied. In Section 2.6, we briefly presented an extension of the differential game theory to a multi-party (n-party) game scenario.

Note: Section 2.2.3, and Examples: 2.2.1, 2.3.1, 2.3.2, 2.3.3 taken from the book: SAGE & WHITE, OPTIMUM SYSTEM CONTROL, 2nd Edition, © 1977; reprinted by permission of Pearson Education, Inc., Upper Saddle River, NJ.
References

    Korn, G. A., and Korn, T. M., Mathematical Handbook for Engineers and Scientists, McGraw-Hill Book Company, New York, 1968.
    Sage, A. P., Optimum Systems Control, 2nd edition, Prentice-Hall, Inc., Englewood Cliffs, New Jersey, 1977.
    Bellman, R., and Dreyfus, S., Applied Dynamic Programming, Princeton University Press, Princeton, New Jersey, 1962.
    Jacobson, D. H and Mayne, D. Q., Differential Dynamic Programming, Elsevier, New York, 1970.
    Ogata, K., State Space Analysis of Control Systems, Prentice-Hall, Inc., Englewood Cliffs, New Jersey, 1967.
    Gantmacher, F. R., Theory of Matrices, Vol. I and II, Chelsea Publishing Co. New York, 1959.
    Kalman, R. E., “Mathematical Description of Linear Dynamical Systems”, J S.I.A.M. Control, Ser. A, Vol. 1, No. 2, pp. 159–192, 1963.
    Berkovitz, L. D., “Variational Methods in Problems of Control and Programming”, Journal Math, Anal. Appl., Vol. 3, pp. 145–169, 1961.
    Gelfand, I. M and Fomin, S. V., Calculus of Variations, Prentice-Hall, Inc., Englewood Cliffs, New Jersey, 1963.
    Kalman, R. E., “The Theory of Optimal Control and Calculus of Variations”, Mathematical Optimization Techniques. University of California Press, Los Angeles, CA, 1963.
    Leitman, G., Optimum Control, McGraw-Hill Book Company, New York, 1966.
    Tou, J., Modern Control Theory, McGraw-Hill Book Company, New York, 1966.
    Pontryagin, L. S., et al., The Mathematical Theory of Optimal Processes, Wiley, New York, 1962.
    Kalman, R. E., “Contribution to the Theory of Optimal Control”, Bol. Soc. Mat. Mex., Vol. 5, pp. 102–119, 1960.
    Merriam, C. W. III., Optimization Theory and the Design of Feedback Control Systems, McGraw-Hill Book Company, New York, 1964.
    Athanassiades, M., “Optimum Control for Linear Time Invariant Plants with Time-, Fuel-, and Energy Constraints”, IEEE Trans. Applied Ind., Vol. 82, pp. 321–325, 1963.
    Johnson, C. D., and Gibson, J. E., “Optimal Control of a Linear Regulator with Quadratic Index of Performance and Fixed Terminal Time”, IEEE Trans. Automatic Control, Vol. AC-9, pp. 355–360, 1964.
    Ben-Asher, J. Z., Isaac, Y., Advances in Missile Guidance Theory, Vol. 180 of Progress in Astronautics and Aeronautics, AIAA, 1998.
    Shima, T., & Shinar, J., “Time-varying linear pursuit-evasion game models with bounded controls”; Journal of Guidance Control and Dynamics, 25(3), 425–432; 2002.
    Shinar, J. et.al., “Pursuit of an evader with hybrid dynamics-Analysis and Design of Hybrid Systems”; Conf. IFAC; Vol. 3, Part 1; 2007.
    Shinar, J. and Gutman, S., “Three-Dimensional Optimal Pursuit and Evasion with Bounded Control”, IEEE Trans. on Automatic Control, Vol. AC-25, No. 3, 1980, pp. 492–496.
    Shinar, J., and Steinberg, D., “Analysis of Optimal Evasive Maneuvers Based on a Linearized Two-Dimensional Model”, Journal of Aircraft, Vol. 14, No. 8, 1977, pp. 795–802.
    Ming-Hsiung Hsueh, Chin-I Huang, Li-Chen Fu., “A Differential Game Based Guidance Law for the Interceptor Missiles”, The 33rd Annual Conference of the IEEE Industrial Electronics Society (IECON), Nov. 5–8, 2007, Taipei, Taiwan.

Appendix: Vector Algebra and Calculus
A2.1 A Brief Review of Matrix Algebra and Calculus

This Appendix is intended to highlight the various vector-matrix operations used in the text.

    The order of closed brackets used in equations or mathematical expressions will generally be: ; on a few occasions, however, for reasons of clarity and where there is no confusion this order is not followed.
    A vector is written as a lower case bold letter with an underscore, for example, or etc.
    A scalar function or a scalar is written as a lower or upper case letter without an underscore, for example, , or ; if a scalar is a function of other variables, these may or may not appear inside a bracket following the variable, for example, or , and so on.
    A matrix will be denoted by a capital letter or a bracketed capital letter, for example, , , , , and so on, or a capital letter with arguments within the bracket and where required with letter or number subscripts for example, , ; letter subscripts signify partial differential operations.
    Transpose of a matrix or a vector is denoted by a superscript , for example, or and an inverse matrix is denoted by a superscript , for example, , and so on.
    If an algebraic equation continues beyond a single line the continuation of this equation is indicated by three dots as ().

It is assumed that the reader is familiar with basic matrix operations such as matrix transpose, matrix addition, subtraction, multiplication, and inversion. Other matrix/vector operations utilized in the text are the following.
A2.2 Characteristic Equations and Eigenvalues

The characteristic matrix of matrix with constant elements is given by the matrix . The equation  (where ) will be referred to as the characteristics equation of . The roots of this characteristic equation are the eigenvalues or simply of matrix . A matrix is positive definite (semi-definite) if: (). Similarly, is negative definite (semi-definite) if: ().
A2.3 Differential of Linear, Bi-Linear, and Quadratic Forms

 

    Given a vector function: , then its differential w.r.t. the vector is defined as:
    (A2.3.1)numbered Display Equation

    The differential w.r.t. a scalar is defined as:
    (A2.3.2)numbered Display Equation

    Given a scalar function: , then its differential w.r.t. a vector is given by:
    (A2.3.3)numbered Display Equation
    (A2.3.4)numbered Display Equation

A2.4 Partial Differentiation of Scalar Functions w.r.t. a Vector

Given a scalar function: , then their partial differential w.r.t. vectors are given by:
(A2.4.1)numbered Display Equation

(A2.4.2)numbered Display Equation

where

    is the vector defined in (A2.4.1).
    is the row vector defined in (A2.4.2).
    is the state vector.
    is the input vector.

A2.5 Partial Differentiation of Vector Functions w.r.t. a Vector

Given a vector function: of vectors then the corresponding Jacobian matrices: and are given by:
(A2.5.1)numbered Display Equation

(A2.5.2)numbered Display Equation

where
numbered Display Equation

A2.6 The Hessian Matrix

Consider the matrices given in (A2.5.1) and (A2.5.2), then the corresponding Hessian matrices: , , and , which are matrices of second partial derivatives, are given by:
(A2.6.1)numbered Display Equation

The matrix: , can similarly be constructed. Thus:
(A2.6.2)numbered Display Equation

The matrix: , can similarly be constructed.
A2.7 Partial Differentiation of Scalar Quadratic and Bilinear Functions w.r.t. a Vector

Given vector functions: , and a scalar bilinear function , with:
(A2.7.1)numbered Display Equation

then
(A2.7.2)numbered Display Equation

(A2.7.3)numbered Display Equation

where

    is a vector.
    is the Jacobian matrix.
    is the Jacobian matrix.

A2.8 First and Second Variations of Scalar Functions

Given a scalar function: of vectors ; then the scalar valued first variation is given by:
(A2.8.1)numbered Display Equation

where

    is the vector of first partial derivatives of w.r.t. [see equation (A2.7.2)] evaluated at .
    is row vector of first partial derivatives of w.r.t. [see equation (A2.7.3)] evaluated at .

The scalar valued second variation is given by:
(A2.8.2)numbered Display Equation

or in matrix notation:
(A2.8.3)numbered Display Equation

    is the matrix of second partial derivatives of w.r.t. evaluated at .
    is the matrix of second partial derivatives of w.r.t. evaluated at .
    is the matrix of second partial derivatives of w.r.t. evaluated at .
    is the matrix of second partial derivatives of w.r.t. evaluated at .
    (A2.8.4)numbered Display Equation

A2.9 Properties of First and Second Variations for Determining the Nature (Min/Max Values) of Scalar Functions

Given that a stationary point, say , exists for a scalar quadratic function, then the eigenvalues of the Hessian matrix [equation (A2.7.4)] of this function can be used to determine the nature of the stationary point (i.e., maximum, minimum or a saddle point). That is:

    If all the eigenvalues of are (i.e., the Hessian is at least positive semi-definite), then the stationary point is a relative (local) minimum.
    If all the eigenvalues of are negative (i.e., the Hessian is at least negative semi-definite), then the stationary point is a relative (local) maximum.
    If the eigenvalues of are both and , then the stationary point is a saddle point.

Example A2.9.1

(see Section 2.4.1): Consider the following Hamiltonian from (2.4.5):
(A2.9.1)numbered Display Equation

Now:
(A2.9.2)numbered Display Equation

and:
(A2.9.3)numbered Display Equation

which gives us:
(A2.9.4)numbered Display Equation

and if matrix is positive semi-definite and is at least positive definite.
A2.9.1 Extension to Multi-Vector Case

Given any which is a scalar function of vectors and ; then the scalar valued first variation: is given by:
(A2.9.5)numbered Display Equation

where
numbered Display Equation

The scalar valued second variation is given by:
(A2.9.6)numbered Display Equation

Example A2.9.2

Consider equation (A2.9.6) with , , then we get:
(A2.9.7)numbered Display Equation

which may be written as:
(A2.9.8)numbered Display Equation

where
numbered Display Equation

Equation (A2.9.8) in matrix notation may be written as:
(A2.9.9)numbered Display Equation

For optimization problems considered in this book, the following hold: ; ; .

Example A2.9.3

(see Section 2.5.1): Consider the following Hamiltonian from equation (2.5.6):
(A2.9.10)numbered Display Equation

Now:
(A2.9.11)numbered Display Equation

which gives us:
(A2.9.12)numbered Display Equation

and:
(A2.9.13)numbered Display Equation

which gives us:
(A2.9.14)numbered Display Equation

Also:
(A2.9.15)numbered Display Equation

which gives us:
(A2.9.16)numbered Display Equation

Hence the second variation is given by:
(A2.9.17)numbered Display Equation

which gives us:
(A2.9.18)numbered Display Equation

Thus, for matrix (positive semi-definite) and matrices (positive definite).

Example A2.9.4

(see Section 2.5.2): Consider the following Hamiltonian from equations (2.5.33) through (2.5.35):
(A2.9.19)numbered Display Equation

(A2.9.20)numbered Display Equation

(A2.9.21)numbered Display Equation

It can easily be verified that the scalar valued second variations , , and are given by:
(A2.9.22)numbered Display Equation

(A2.9.23)numbered Display Equation

(A2.9.24)numbered Display Equation

provided matrix (positive semi-definite), and (positive definite).
A2.10 Linear System Dynamical Model

In many applications linear system dynamical models provide a sufficiently accurate representation of a practical system for control analysis and synthesis. Linear models will form the basis of missiles and autonomous systems for which we shall consider implementing the differential game theory-based guidance strategies. Such a dynamical model is characterized by the following vector differential equation:
(A2.10.1)numbered Display Equation

For piecewise continuous in , the vector differential equation (A2.10.1) has a unique solution given by:
(A2.10.2)numbered Display Equation

where the system transition matrix satisfies the matrix differential equation:
(A2.10.3)numbered Display Equation

The transition matrix has the following properties:

    ,
    ,
    ,

In particular, if , a constant coefficient matrix is then:
(A2.10.4)numbered Display Equation

and
(A2.10.5)numbered Display Equation

1: Differential Game Theory and Applications to Missile Guidance
2: Optimum Control and Differential Game Theory
Differential Game Theory with Applications to Missiles and Autonomous Systems Guidance
3: Differential Game Theory Applied to Two-Party Missile Guidance Problem



Skip to Content
Search 50,000+ courses, events, titles, and more
3
Differential Game Theory Applied to Two-Party Missile Guidance Problem
Nomenclature

    is the x position of vehicle in fixed axis.

    is the y position of vehicle in fixed axis.

    is the z position of vehicle in fixed axis.

    is the x velocity of vehicle in fixed axis.

    is the y velocity of vehicle in fixed axis.

    is the z velocity of vehicle in fixed axis.

    is the x acceleration of vehicle in fixed axis.

    is the y acceleration of vehicle in fixed axis.

    is the z acceleration of vehicle in fixed axis.

    is the x position of vehicle w.r.t. in fixed axis.

    is the y position of vehicle w.r.t. in fixed axis.

    is the z position of vehicle w.r.t. in fixed axis.

    is the x velocity of vehicle w.r.t. in fixed axis.

    is the y velocity of vehicle w.r.t. in fixed axis.

    is the z velocity of vehicle w.r.t. in fixed axis.

    is the x acceleration of vehicle w.r.t. in fixed axis.

    is the y acceleration of vehicle w.r.t. in fixed axis.

    is the z acceleration of vehicle w.r.t. in fixed axis.

    is the (3 × 1) position vector of vehicle in fixed axis.

    is the (3 × 1) velocity vector of vehicle in fixed axis.

    is the (3 × 1) acceleration vector of vehicle in fixed axis.

    is the (3 × 1) position vector of vehicle w.r.t. in fixed axis.

    is the (3 × 1) velocity vector of vehicle w.r.t. in fixed axis.

    is the (3 × 1) acceleration vector of vehicle w.r.t. in fixed axis.

    is the (6 × 1) relative state vector between vehicle w.r.t. in fixed axis.

    is a (6 × 6) state coefficient matrix.

    is a (6 × 3) control (input) coefficient matrix.

    is a 6 × 6 final state PI weightings matrix.

    is a 3 × 3 unity matrix.

    is a 6 × 6 state PI weightings matrix.

    is the 3 × 3 pursuer's demanded acceleration PI weightings matrix.

    is the 3 × 3 evader's demanded acceleration PI weightings matrix.

    is the PI or the objective function.

    is a Hamiltonian.

    is the matrix Riccati differential equation solution.

    is the time-to-go.

    are interceptor (pursuer) state feedback disturbance input gains.

    are target (evader) state feedback and disturbance input gains.

    is the vector Riccati differential equation solution.

Abbreviations

3-D:

    three dimensions
AI:

    artificial intelligence
APN:

    augmented proportional navigation
GTG:

    game theoretic guidance
MRDE:

    matrix Riccati differential equation
OF:

    objective function
OG:

    optimum guidance
PI:

    performance index
PN:

    proportional navigation
VRDE:

    vector Riccati differential equation

3.1 Introduction

Tactical missiles have been in use since WWII and their guidance systems have progressively evolved from those employing proportional navigation (PN) and augmented proportional navigation (APN) to those employing optimal guidance (OG) and game theoretic guidance (GTG). One reason for this development is the fact that the implementation hardware/software for the guidance system has evolved over the years and now offers greater flexibility to a guidance system designer to implement advanced algorithms for missile navigation, guidance and control. Developments in the area of IR/RF missile-borne seekers, strap-down navigation systems, and airborne processors have prompted guidance engineers to explore techniques that are more suited for continuously evolving and relatively more complex battlefield scenarios. With the advent of state estimation techniques such as the Kalman Filter and others, it is now possible to implement the OG, GTG, and GTG plus AI (artificial intelligence) guidance on practical missile systems.

It is noteworthy that the PN and APN are still being used in a large number of modern missile systems. The PN and APN guidance performance has been studied by a number of authors.1, 2, 3, 4, 5 It is also interesting to note that both PN and APN guidance can be derived using the optimum guidance theory and state space representation of the interceptor and target kinematics model. Thus, we may regard both PN and APN as special cases of OG and GTG; this connection is explored in this chapter. Given the desire to reduce weapon life-cycle cost, and at the same time extend the operational envelope to cope with complex engagement scenarios that require the capability to adapt to an adversary's “intelligent” engagement tactics, it is necessary to consider OG and GTG guidance approaches for future tactical missiles. Augmentation of these guidance techniques with those that have evolved in the field of AI also needs to be considered.

Application of the differential game theory to missile guidance has been considered by a number of authors.6, 7, 8, 9, 10, 11, 12, 13 Shinar et al.7 presented an analysis of a complex combat scenario involving two parties (two aircraft), both equipped with interceptor missiles. The objective of each party was to shoot down the opponent's aircraft without their own aircraft being intercepted (hit) by their opponent's missile. Such a scenario, where the strategy of each party is for its missile to intercept the opponent's aircraft and perform evasion maneuvers of its own aircraft so as to avoid being hit by the opponent's missile, is typical of engagement scenarios where the game theoretic approach to missile guidance can be used. Shinar refers to this situation as a “non-cooperative differential game,” which can also be classed as a “game of a kind.” Encounter between the two aircraft (blue and red), under the above conditions, results in one of the following outcomes:

    Win for blue (red alone is shot down)
    Win for red (blue alone is shot down)
    Mutual kill (both red and blue are shot down)
    Draw (both red and blue escape)

Shinar goes on to consider further combat strategies that can arise out of the above scenario and suggests the application of artificial intelligence (AI) augmentation to the differential game guidance. This latter aspect can be considered from the perspective of augmenting the GTG with a “rule-based” AI—for switching the performance index (PI) weighting parameters and/or for applying additional maneuvers to evade the pursuer. In this chapter, our main focus will be on the formulation and solution of the GTG problem involving two parties where the objective of one party (pursuer) is to implement a strategy to intercept, while the objective of the other (evader) is to implement a strategy to evade the former. Ben-Asher et al.8 considered the application of the differential game theory to missile guidance and utilized the linear system quadratic PI (LQPI) approach in order to derive guidance strategies (in terms of guidance acceleration commands) for the pursuer and the evader in a two-party game scenario. This approach was based on defining the interceptor and target kinematics in linear state space form and the PI that included a scalar quadratic function of states and controls (the so-called LQPI problem). The above authors considered engagement kinematics in 2-D and the PI, which included the miss-distance; in this chapter we have generalized this problem to a 3-D case and a PI that could include relative velocity terms and thus allow greater control of vehicle flight trajectories.

The two-party GTG problem can be stated in a general form as follows. Given the following state space (relative kinematics) model:
(3.1.1)numbered Display Equation

where

    is the relative state (position and velocity in fixed axis) vector between the interceptor 1 and target 2.
    is the (3 × 1) position vector of vehicle w.r.t. in fixed axis.
    is the (3 × 1) velocity vector of vehicle w.r.t. in fixed axis.
    are commanded acceleration vectors respectively of the interceptor 1 (pursuer) and the target 2 (evader).
    are additional (prespecified) disturbance vectors respectively of the interceptor and the target. These are included to admit additional evasion and/or pursuit maneuvers that the players might implement.

The guidance problem is, therefore, that of computing interceptor and target accelerations , such that the optimum value of the PI is given by:
(3.1.2)numbered Display Equation

If we assume a scalar quadratic PI then we can convert the above Min/Max problem to just a minimization problem by changing the sign of the quadratic term involving the input for evasion , in the PI to negative as given below:
(3.1.3)numbered Display Equation

where

    is a positive semi-definite matrix that defines the PI penalty weightings on the final relative state.
    are positive definite matrices that define the PI penalty weightings on the inputs.

Ben-Asher8 solved the problem (3.1.1) through (3.1.3) for a special case of 2-D with a PI consisting of miss-distance term only. In this current chapter we shall consider engagement in 3-D (azimuth and elevation planes) and define a PI that incorporates the miss-distance term as well as additional terms consisting of relative velocities that may allow us to shape the engagement trajectory and more effectively deal with large heading errors, unfavorable engagement geometries and severe interceptor and target maneuvers. It must be pointed out that, in general, the game outcome depends upon which of the parties “plays first”;7, 8 however, if we assume that both parties apply optimum strategies (guidance commands) “almost simultaneously” and that the PI optimization solution satisfies the “saddle point” condition then the outcome becomes independent of the order of the play.

Both OG and GTG are derived in this chapter, based on optimizing a performance (PI) that is a function of system states and controls. In the case of the OG, which can be regarded as a special case of the GTG, it is assumed that the target does not implement any evasion strategy while the interceptor implements the intercept strategy. Thus, with a slight modification, the objective function (3.1.3) may be used to derive the OG law. This yields a linear state feedback guidance law involving gain terms derived by solving the well-known, matrix Riccati differential equation (see Section 3.3). This approach has been adopted in this chapter to solve the GTG and the OG problems. In both cases, closed form solutions of the Riccati equation and of the resulting feedback gains are derived as a function of time to go. While the emphasis in this chapter is on two-party games involving one interceptor against one target, the development of the kinematics equations and the guidance law derivation is general enough to be extended to three-party and multi-party game situations (see Chapters 2 and 4).

Intercept and evasion strategies, implemented by the parties involved, are based on their knowledge of relative states (i.e., the parties learn from the environment) and on the optimization of an objective function (i.e., the decision-making criteria). Rule-based AI can also be used that will allow adaptively changing the PI weightings and/or implementing additional maneuvers . Section 3.2 of this chapter presents the development of a 3-D engagement kinematics model in state space form. Section 3.3 presents the formulation of the PI and the solution of the GTG problem. Solutions of the matrix Riccati differential equation (MRDE) and the vector Riccati differential equation (VRDE) are considered in Section 3.4, along with the feedback implementation of the guidance law. Relationships between the OG and GTG and the conventional PN and APN guidance are explored in Sections 3.5 and 3.6. Section 3.7 contains conclusions resulting from the material presented in this chapter. Further useful reading on the subject is given in the references.10, 11, 12, 13, 14
3.2 Development of the Engagement Kinematics Model

Typical two-vehicle engagement geometry is shown in Figure 3.2.1 ( is the target and is the interceptor); this scenario may be extended to the case of targets and interceptors; that is vehicles. The engagement kinematics model in this chapter is derived with this in mind. The motion (kinematics) of each vehicle can be described by a set of first order differential equations representing states of the vehicles (i.e., position, velocity and acceleration) defined in fixed (e.g., inertial) frame. The kinematics equations may be written as:
(3.2.1)numbered Display Equation

(3.2.2)numbered Display Equation

where

    The above variables are functions of time .
    is the x position of vehicle in fixed axis.
    is the y position of vehicle in fixed axis.
    is the z position of vehicle in fixed axis.
    is the x velocity of vehicle in fixed axis.
    is the y velocity of vehicle in fixed axis.
    is the z velocity of vehicle in fixed axis.
    is the x acceleration of vehicle in fixed axis.
    is the y acceleration of vehicle in fixed axis.
    is the z acceleration of vehicle in fixed axis.

A flat-earth assumption is made and that -axis is assumed positive down.
Graph shows point T indicating target and point I indicating interceptor and line connecting them is line of sight and other dotted lines zj and zi, xj and xi, et cetera, on X, Y, and -Z.

Figure 3.2.1 Interceptor/target engagement geometry.
3.2.1 Relative Engage Kinematics of n Versus m Vehicles

We now consider relative states of the vehicles; the kinematics equations may be written as follows:
(3.2.3)numbered Display Equation

(3.2.4)numbered Display Equation

where

    is the x position of vehicle w.r.t. in fixed axis.
    is the y position of vehicle w.r.t. in fixed axis.
    is the z position of vehicle w.r.t. in fixed axis.
    is the x velocity of vehicle w.r.t. in fixed axis.
    is the y velocity of vehicle w.r.t. in fixed axis.
    is the z velocity of vehicle w.r.t. in fixed axis.
    is the x acceleration of vehicle w.r.t. in fixed axis.
    is the y acceleration of vehicle w.r.t. in fixed axis.
    is the z acceleration of vehicle w.r.t. in fixed axis.

For the engagement between an interceptor against a target (two-party engagement), we may regard suffix to represent the interceptor and suffix to represent the target. In the derivation of the optimal guidance law it will be useful to represent the above equations in vector/matrix notation.
3.2.2 Vector/Matrix Representation

We can write equations (3.2.1) and (3.2.2) as:
(3.2.5)numbered Display Equation

Similarly we can write the relative kinematics equations (3.2.3) and (3.2.4) as:
(3.2.6)numbered Display Equation

where

    is the (3 × 1) position vector of vehicle in fixed axis.
    is the (3 × 1) velocity vector of vehicle in fixed axis.
    is the (3 × 1) acceleration vector of vehicle in fixed axis.
    is the (3 × 1) position vector of vehicle w.r.t. in fixed axis.
    is the (3 × 1) velocity vector of vehicle w.r.t. in fixed axis.
    is the (3 × 1) acceleration vector of vehicle w.r.t. in fixed axis.

Equation (3.2.6) may be combined together to give us:
(3.2.7)numbered Display Equation

This can be written as:
(3.2.8)numbered Display Equation

where

    is the (6 × 1) relative state vector between vehicle w.r.t. in fixed axis.
    is the (6 × 6) state coefficient matrix; is the identity matrix.
    is the (6 × 3) control (input) coefficient matrix, and is the identity matrix.

In this chapter, the guidance algorithm is derived on the basis of a linear engagement kinematics model defined in fixed axis (e.g., inertial axis); the guidance commands are also generated in fixed axis. For testing and performance of the guidance strategies derived in this chapter, a non-linear engagement kinematics model was used for the simulation model; this is developed in Chapter 5. The guidance commands are applied in the vehicle body axis (through appropriate transformation), which accounts for changes in body attitude; also the autopilot dynamics and the maximum and minimum acceleration limits are included in the simulation model. Several authors5 have included autopilot lags in the guidance law derivations and the material presented in this chapter may be extended to this case.
3.3 Optimum Interceptor/Target Guidance for a Two-Party Game

Here we address the problem of a target, that is being engaged by an interceptor, implementing a guidance strategy to avoid intercept, whereas the interceptor implements a strategy to try to intercept the target. These strategies are implemented via the application of guidance (lateral) acceleration commands. The interceptor utilizes its guidance input command to effect intercept of the target, this is specified by ; in addition, it may, if required, perform additional prespecified maneuver . The total interceptor acceleration in this case may be written as:
(3.3.1)numbered Display Equation

The target , on the other hand, applies an evasive maneuver and an additional prespecified (disturbance) maneuver ; this latter component could be, for example, a random maneuver or a maneuver of a periodical wave form. With these maneuvers, the total evader acceleration is of the form:
(3.3.2)numbered Display Equation

The modified form of the kinematics model (3.2.8), including the above maneuvers, may be written as:
(3.3.3)numbered Display Equation

We shall compute the evasion and pursuit guidance commands , , which satisfy the specified criteria. We shall consider the application of the differential game and the optimum control principles developed in Chapter 2, to derive evasion and pursuit guidance strategies.
3.3.1 Construction of the Differential Game Performance Index

In formulating the differential game-based guidance problem, the following assumptions are made.

    Both parties have all the necessary information of the relative states, with respect to each other, to enable the parties to implement the necessary guidance laws. Countermeasures designed to conceal states of the parties involved are not considered.
    If a seeker/tracker is used to construct system relative states using seeker information (e.g., utilizing a Kalman Filter), then state estimation errors and processing delay have to be included. However, for the purpose of our current considerations it is assumed the system states are exact and are available to both parties almost instantaneously.
    The maximum and the minimum accelerations achievable by the vehicles involved in the game are limited. For our current derivation constraints on the accelerations are considered to be “soft”; that is, the change in acceleration and acceleration rate is gradual in the neighborhood of the maximum/minimum values. This type of constraint can be implemented in the PI through the use of “penalty weightings” associated with the demanded accelerations. This approach leads to a relatively easy solution for implementing these constraints.
    In the derivation of the guidance laws, autopilot lags are ignored. These may be included in the actual simulation studies in order to assess the guidance performance including the autopilot.

Under the above assumptions we can proceed to construct the PI that the parties to the game will need to minimize or maximize in order to derive their respective strategies. The PI selected for the problem under consideration includes interceptor/target states that represent the miss-distance as well as other states that influence this. In the past, most authors8, 10 have used miss-distance and demanded accelerations terms to construct the PI. In this chapter, we shall generalize the objective function by including terms in relative position and relative velocity as well as demanded accelerations.

We shall assume the PI that we wish to minimize is given by:
(3.3.4)numbered Display Equation

where

    is the PI.
    is a weighted square of the relative separation between the interceptor and the target.
    is a weighted projection of the relative velocity on to the relative range.
    is a weighted square of the relative velocity of the interceptor w.r.t. the target.
    is a weighted square of the interceptor acceleration.
    is a weighted square of the target acceleration.
    are PI weightings matrix on the final values of states.
    are PI weightings matrix on demanded accelerations.

By varying the relative values of the PI weightings , constraints on system final state and on control can be implemented. Note that this PI contains the following terms.

    Weighted interceptor/target relative position term: ; at the final time is the miss-distance squared for .
    Weighted interceptor/target relative position and velocity terms: and ; these terms represent engagement trajectory shaping terms.
    Weighted interceptor/target demanded acceleration terms: and ; these terms allow soft constraints on controls (demanded accelerations) to be implemented.
    Relative values of penalty weightings: and determine soft constraints on states and control variables.

The objective function as given in equation (3.3.4) can be minimized w.r.t. in order to derive the intercept guidance commands, and maximized w.r.t. . By virtue of the negative sign associated with we simply minimize the PI. It will be convenient to write the PI (also referred to as the objective function – OF) as:
(3.3.5)numbered Display Equation

where

    is a 6 × 6 final state function penalty weighting matrix.
    is a 3 × 3 pursuer's demanded acceleration function penalty weighting matrix.
    is a 3 × 3 evader's demanded acceleration function penalty weighting matrix.

We shall define: .

The game theoretic guidance problem can be stated as that of minimizing the following PI:
(3.3.6)numbered Display Equation

For a minimum or a maximum of the PI to exist, it is a requirement that the matrix be at least positive semi-definite, and matrices and be positive definite. That is, the determinants: and , . These conditions imply that (see Appendix A3.1):
(3.3.7)numbered Display Equation

3.3.2 Weighting Matrices

For the solution of the game theory guidance problem considered in this chapter the following types of (diagonal matrix) structures are utilized:
(3.3.8)numbered Display Equation

(3.3.9)numbered Display Equation

In the sequel we also will need the combined matrix R, which is defined as:
(3.3.10)numbered Display Equation

It can easily be verified that if we write as:
(3.3.11)numbered Display Equation

and
(3.3.12)numbered Display Equation

Matrices of the type shown in (3.3.8) and (3.3.12) are used to derive the general solutions to the MRDE and VRDE. The following special cases will also be considered that will enable us to derive certain useful results, which will be used later in this and other chapters.

Case 1

For this case we assume that: , that is, , i.e. , i.e. .

and ; that is, , this last equality simply implies that: ; that is: .

Case 2

For this case assume that: ; and .

This is equivalent to setting the weightings on the velocity terms in the PI index to zero; in which case the PI becomes only a function of the miss distance squared and the terms involving interceptor and target accelerations.
3.3.3 Solution of the Differential Game Guidance Problem

In this section we present the solution to the problem of optimization of the PI (3.3.6) subject to the condition that the kinematics model (3.3.3) holds. In doing so we shall follow the technique described in Chapter 2. This involves the construction of the Hamiltonian, which is then minimized w.r.t. and maximized w.r.t. . The Hamiltonian may be written as:
(3.3.13)numbered Display Equation

Necessary conditions for are given by:
(3.3.14)numbered Display Equation

(3.3.15)numbered Display Equation

(3.3.16)numbered Display Equation

The terminal condition for is given by: . The corresponding sufficient conditions are:
(3.3.17)numbered Display Equation

Now, applying the necessary conditions (3.3.14) and (3.3.15) to the Hamiltonian (3.3.13), we get:
(3.3.18)numbered Display Equation

(3.3.19)numbered Display Equation

Equations (3.3.18) and (3.3.19) give us:
(3.3.20)numbered Display Equation

(3.3.21)numbered Display Equation

Since we are interested in constructing the guidance commands as functions of system relative states, we assume that is of the form:
(3.3.22)numbered Display Equation

where

    is a 6 × 6 matrix, which will be later shown to be a solution of the matrix Riccati differential equation (MRDE).
    is a 6 × 1 vector, which will be later shown to be a solution of the vector Riccati differential equation (VRDE).

Thus
(3.3.23)numbered Display Equation

(3.3.24)numbered Display Equation

Since we are interested in state feedback guidance laws, we write these equations as:
(3.3.25)numbered Display Equation

(3.3.26)numbered Display Equation

where

    is the feedback gain for a pursuer; and is the pursuer gain for the disturbance input.
    is the state feedback gain for the evader; and is the evader gain for the disturbance input.

Now applying the necessary condition (3.3.16), we get, using equation (3.3.13):
(3.3.27)numbered Display Equation

where
numbered Display Equation

Substituting for , , and , and for and , and after algebraic simplification (see Appendix A3.2) it can be shown that equation (3.3.27) leads to:
(3.3.28)numbered Display Equation

Since the solution of equation (3.3.28) must hold for all , it must satisfy the following differential equations:
(3.3.29)numbered Display Equation

(3.3.30)numbered Display Equation

With terminal conditions , and . Equation (3.3.29) will be referred to as the matrix Riccati differential equation (MRDE) and equation (3.3.30) will be referred to as the vector Riccati differential equation (VRDE).
3.4 Solution of the Riccati Differential Equations
3.4.1 Solution of the Matrix Riccati Differential Equations (MRDE)

In this section we consider the solution of the MRDE (3.3.29). We write this equation as:
(3.4.1)numbered Display Equation

where
numbered Display Equation

The approach adopted to solve the MRDE involves an inverse matrix technique, where the solution of an inverse matrix version of the MRDE is first obtained and then by re-inverting the resulting solution, the Riccati matrix is obtained. This approach is given in the Appendix, where an expression for , the inverse MRDE solution, is first obtained. This is re-inverted to obtain expressions for the elements of . The general solution of the MRDE is given in the Appendix, equations (A3.3.28) through (A3.3.36).

Case 1

For weighting parameters selected for this case: ; ; and ; and writing . The MRDE solution gives us [see (A3.3.28) through (A3.3.36)]:
(3.4.2)numbered Display Equation

(3.4.3)numbered Display Equation

(3.4.4)numbered Display Equation

3.4.2 State Feedback Guidance Gains

The feedback gain matrix for the interceptor (pursuer) is given by:
(3.4.5)numbered Display Equation

The feedback gain matrix for the target (evader) is given by:
(3.4.6)numbered Display Equation

Case 2

One case of particular interest is when the following PI weightings are used. Substituting: ; ; and in equations (3.4.2) through (3.4.4) gives us:
(3.4.7)numbered Display Equation

(3.4.8)numbered Display Equation

(3.4.9)numbered Display Equation

Note that:
(3.4.10)numbered Display Equation

Substituting for from (3.4.8) and (3.4.9), the feedback gain matrix for the pursuer in this case is given by:
(3.4.11)numbered Display Equation

The feedback gain matrix for the evader is given by:
(3.4.12)numbered Display Equation

3.4.3 Solution of the Vector Riccati Differential Equations (VRDE)

The VRDE given in equation (3.3.25) may be written as:
(3.4.13)numbered Display Equation

Writing: ; equation (3.4.13) (in its decomposed form) may be written as (see Appendix A3.4):
(3.4.14)numbered Display Equation

(3.4.15)numbered Display Equation

(3.4.16)numbered Display Equation

(3.4.17)numbered Display Equation

(3.4.18)numbered Display Equation

(3.4.19)numbered Display Equation

Unfortunately, it is not easily possible to obtain analytical solutions for equations (3.4.14) through (3.4.19), except for special cases where , and , are constants. This case will be considered later on in this section. In general, however, equations (3.4.14) through (3.4.19) have to be solved backward in time. For this purpose we make the following substitutions.

Let , ; ; ; ; . Hence the above equations (3.4.14) through (3.4.19) may be written as:
(3.4.20)numbered Display Equation

(3.4.21)numbered Display Equation

(3.4.22)numbered Display Equation

(3.4.23)numbered Display Equation

(3.4.24)numbered Display Equation

(3.4.25)numbered Display Equation

These equations satisfy the boundary condition , and must be solved backward in time, that is, . In the absence of an explicit closed form solution to equations (4.4.20) through (4.4.25) we shall write the general solution as:
(3.4.26)numbered Display Equation

3.4.4 Analytical Solution of the VRDE for the Special Case

Analytical solution of the VRDE is possible for Case 2, when: ; ; ; ; and , are constants. For this case (see Appendix A3.4), the solution of equations (3.4.20) through (3.4.25) gives us:
(3.4.27)numbered Display Equation

(3.4.28)numbered Display Equation

(3.4.29)numbered Display Equation

(3.4.30)numbered Display Equation

(3.4.31)numbered Display Equation

(3.4.32)numbered Display Equation

Noting that: , the feedback guidance terms for the disturbance term may be written as:
(3.4.33)numbered Display Equation

(3.4.34)numbered Display Equation

3.4.5 Mechanization of the Game Theoretic Guidance

Using the expressions for the feedback guidance law equations (3.3.20) and (3.3.21), and those for the feedback gains given in equations (3.4.5) and (3.4.6) and (3.4.33) and (3.4.34), we get, for the general case, and with PI weightings of Case 1:

; ; and :
(3.4.35)numbered Display Equation

(3.4.36)numbered Display Equation

For PI weighting parameters of Case 2:

; ; and ; constants, we get [see equations (3.4.11) and (3.4.12) and (3.4.33) and (3.4.34)]:
(3.4.37)numbered Display Equation

(3.4.38)numbered Display Equation

Obviously, if neither party exercises its option of utilizing the disturbance maneuver, then the last term in the above expressions becomes zero and the guidance law becomes:
numbered Display Equation

3.5 Extension of the Game Theory to Optimum Guidance

The development of the optimum guidance not involving target evasion maneuvers can proceed directly from the game theory development presented in earlier sections. For this case, the PI takes the following form:
(3.5.1)numbered Display Equation

where

    is a 6 × 6 final state function penalty weighting matrix.
    is a 3 × 3 pursuer's demanded acceleration function penalty weighting matrix.

Note that in this case, the first term in the PI is only the miss distance and that the game theory-based target evasion maneuver is not present. Similarly in the kinematics equations prespecified target acceleration is present, whereas is zero. The kinematics model for the engagement, equation (3.3) may be written as:
(3.5.2)numbered Display Equation

Following the approach presented earlier it follows that the optimum guidance law for the interceptor in this case is given by:
(3.5.3)numbered Display Equation

Or in terms of time-to-go (3.5.3) has the form:
(3.5.4)numbered Display Equation

Note that the MRDE and the VRDE are similar to those previously derived in Section 3.4. That is:
(3.5.5)numbered Display Equation

(3.5.6)numbered Display Equation

As far as the solution of these equations (3.5.5) and (3.5.6) is concerned, these are identical to those derived earlier with replaced by and . It can be easily verified that, for this case [see equations (3.4.7) through (3.4.9)]:
(3.5.7)numbered Display Equation

(3.5.8)numbered Display Equation

(3.5.9)numbered Display Equation

The feedback gain matrix for the interceptor in this case is given by [see equation (3.4.11)]:
(3.5.10)numbered Display Equation

The disturbance term for constant target maneuver is given by [see equation (3.4.33)]:
(3.5.11)numbered Display Equation

The feedback guidance law may be written as:
(3.5.12)numbered Display Equation

It is interesting to note that if , then (3.5.12) becomes:
(3.5.13)numbered Display Equation

This relationship provides the “link” between the optimal guidance and the conventional guidance such as PN and APN, and will be further elaborated in the next section.
3.6 Relationship with the Proportional Navigation (PN) and the Augmented PN Guidance

In order to establish a link between optimum guidance and the PN and APN guidance we shall assume that the engagement trajectory is such that the azimuth and elevation sightline angles: , (Figure A3.1) remain small during engagement; that is, the trajectory remains close to a collision course geometry. For this condition it follows that the interceptor/target relative velocity is pointed approximately along the sight line and is approximately equal to the closing velocity . We write equation (3.5.13), the state feedback guidance acceleration , as:
(3.6.1)numbered Display Equation

It is shown in Appendix A3.5, equations (A3.5.5) through (A3.5.7), that:
numbered Display Equation

Thus equation (3.6.1) reduces to:
(3.6.2)numbered Display Equation

This is the well-known APN guidance law when the target acceleration maneuver is constant. The navigation gain is associated with the sightline rate, and associated with target acceleration. When there is no target maneuver we get the PN guidance, which may be written as:
(3.6.3)numbered Display Equation

3.7 Conclusions

This chapter was focused on the application of differential game theory to a two-party game scenario, where the interceptor's objective was to intercept the target while the target's strategy was to avoid intercept. Guidance laws derived in this chapter could allow additional maneuvers to be implemented (say based on AI) through the disturbance inputs. It was further shown that OG was a special case of the GTG. Both these guidance techniques follow similar procedures for deriving the state feedback guidance laws and the PI are of the same form. A 3-D interceptor/target engagement was considered and guidance laws were derived that should give designers the flexibility to choose guidance gains (by selecting appropriate PI weights) so as to meet their specific engagement objectives. For a number of important cases closed form expressions have been obtained for the feedback gains. Relationship between the GTG, the OG and the classical PN and APN has also been demonstrated.

The game theory-based guidance technique considered in this chapter provides a useful tool to study vulnerabilities of existing missile systems against current and future threat missile systems that may incorporate “intelligent” guidance. Also, it allows future missile guidance design based on the game theory approach augmented by AI to be implemented. Further research is required in this area in order to evaluate the performance of the game theoretic guidance in realistic missile engagement environments.
References

    Kreindler, E., “Optimality of Proportional Navigation,” AIAA Journal, Vol. 11, No. 6, 1973, pp. 878–880.
    Nesline, W. N., and Zarchan, P., “A New Look at Classical vs Modern Homing Missile Guidance” Journal of Guidance and Control, Vol. 4, No. 1 1981, pp. 78–84.
    Ho, Y. C., Bryson, A.E., and Baron, S., “Differential-Game and Optimal Pursuit-Evasion Strategies,” IEEE Trans Automatic Control, Vol. C-10, No. 4, 1965, pp. 385–389.
    Gutman, S., “On Optimal Guidance for Homing Missiles,” Journal of Guidance and Control, Vol. 2, No. 4, 1979, pp. 296–300.
    Zarchan, P., Tactical and Strategic Missile Guidance, 2nd edition, Vol. 199 of Progress in Astronautics and Aeronautics, AIAA, 2002.
    Isaacs, R., Differential Games, Dover Publications, 1965.
    Shinar, J., Siegel, A. W., Gold, Y. I., “On the analysis of a Complex Differential Game Using Artificial Intelligence Techniques”; Proceedings of the 27th IEEE Conference on Decision and Control, Austin, Texas, Dec. 1988.
    Ben-Asher, J.Z., Isaac, Y., Advances in Missile Guidance Theory, Vol. 180 of Progress in Astronautics and Aeronautics, AIAA, 1998.
    Shinar, J., Siegel, A., and Gold, Y., “On the analysis of a complex differential game using artificial intelligence,” Proceedings of the 27th IEEE Conference on Decision and Control, 1988, pp. 1436–1441.
    Faruqi, F. A., “Intelligent 3-Party Game Theoretic Approach to Missile Guidance”, Proc. AAIA (Conf. GNC/AFM/MST/ASC), paper 152-GNC-69 on Guidance, Navigation & Control, Aug. 2012.
    Faruqi, F. A., “Integrated Navigation, Guidance, and Control of Missile Systems: 3-D Dynamic Model “, DSTO Technical Rept TR-2805, Fabruary 2013.
    Shinar, J., Guelman, M., Silberman, G., and Green, A., “On optimal missile avoidance — a comparison between optimal control and differential game solutions,” IEEE International Conference on Control and Applications, 1989, pp. 453–459.
    Shinar, J. and Shima, T., “A game theoretical interceptor guidance law for ballistic missile defence,” Proceedings of the 35th IEEE Conference on Decision and Control, 1996, pp. 2780–2785.
    Sage, A. P., Optimum Systems Control, Prentice Hall, 1968.

Appendix
A3.1 Verifying the Positive Semi-Definiteness of Matrix [S]

Now, the determinant of partitioned matrix may be written as:
(A3.1.1)numbered Display Equation

For to be positive semi-definite, we must have:
(A3.1.2)numbered Display Equation

(A3.1.3)numbered Display Equation

Note that: can be either positive or negative.
A3.2 Derivation of Riccati Differential Equations

Substituting for and from equations (3.3.20), (3.3.22) into equation (3.3.3) gives us:
(A3.2.1)numbered Display Equation

Using equation (3.3.22), equation (3.3.27) may be written as:
(A3.2.2)numbered Display Equation

Substituting for from equation (A3.2.1) gives us:
numbered Display Equation

(A3.2.3)numbered Display Equation

Re-arranging the terms, equation (A3.2.3) can be written as:
(A3.2.4)numbered Display Equation

A solution of equation (A3.2.4) is obtained if both the LHS and the RHS are equal to zero; that is:
numbered Display Equation

Since the above equations hold for all , we get:
(A3.2.5)numbered Display Equation

(A3.2.6)numbered Display Equation

where for convenience we write: .

These differential equations satisfy the boundary conditions and . Equation (A3.2.5) will be referred to as the matrix Riccati differential equation (MRDE) and equation (A3.2.6) will be referred to as the vector Riccati differential equation (VRDE).
A3.3 Solving the Matrix Riccati Differential Equation

Let us write the matrix as:

; then ; and differential of this term gives: ; or
(A3.3.1)numbered Display Equation

Substituting for in equation (A3.2.5), we obtain the inverse-MRDE for as:
(A3.3.2)numbered Display Equation

We solve for , the inverse Riccati matrix first, and then invert this to obtain the Riccati solution for . Because both and matrices are symmetric, we may write:
(A3.3.3)numbered Display Equation

Terminal condition for matrix is given by: . We write the (partitioned) matrix as:
(A3.3.4)numbered Display Equation

where
numbered Display Equation

A3.3.1 Inversion of Matrix

We write the inverse of matrix as:
(A3.3.5)numbered Display Equation

Since is symmetric, then so is and for to be the inverse of , we must have:
numbered Display Equation

numbered Display Equation

The above equality implies that:
(A3.3.6)numbered Display Equation

(A3.3.7)numbered Display Equation

(A3.3.8)numbered Display Equation

(A3.3.9)numbered Display Equation

Equation (A3.3.8) gives us:
(A3.3.10)numbered Display Equation

Substituting equation (A3.3.10) into equation (A3.3.6) gives us:
(A3.3.11)numbered Display Equation

Substituting equation (A3.3.11) into equation (A3.3.10) gives us:
(A3.3.12)numbered Display Equation

Also, equation (A3.3.7) gives us:
(A3.3.13)numbered Display Equation

Equations (A3.3.11) and (A3.3.13) give us:
(A3.3.14)numbered Display Equation

Now, it follows from (A3.3.4) that:
numbered Display Equation

Using expressions for and , equations (A3.3.11), (A3.3.12), and (A3.3.14) give us:
(A3.3.15)numbered Display Equation

(A3.3.16)numbered Display Equation

(A3.3.17)numbered Display Equation

Inverse matrix can now be constructed using expressions for .
A3.3.2 Solution of the Inverse Matrix Riccati Differential Equation

In this section we decompose equation (A3.3.2) in its elemental form to facilitate the solution of the inverse MRDE for matrix . Now:
(A3.3.18)numbered Display Equation

and
numbered Display Equation

It follows from the above that:
(A3.3.19)numbered Display Equation

also
(A3.3.20)numbered Display Equation

Hence the RHS of equation (A3.3.2) may be written as:
(A3.3.21)numbered Display Equation

Since is a symmetric matrix, we need to consider only the elements of the upper triangular matrix. Thus, using equation (A3.3.21), differential equation (A3.3.2) may be written (in its elemental form) as:
numbered Display Equation

The terminal conditions given by , may be written as:
numbered Display Equation

Integrating the above differential equations with terminal conditions and writing: , time-to-go, we get expressions for ; these are given in Table A3.1 below.

Table A3.1 Solution of the inverse MRDE.
images
images
images

In view of Table A3.1, we may write:
(A3.3.22)numbered Display Equation

Inversion of this matrix to obtain can proceed in the same way as shown earlier for the inversion of . Since is a symmetric matrix, we write it as:
(A3.3.23)numbered Display Equation

where
numbered Display Equation

and
numbered Display Equation

For to be the inverse of , we must have:
(A3.3.24)numbered Display Equation

Using expressions for and above, it can be shown that:
(A3.3.25)numbered Display Equation

(A3.3.26)numbered Display Equation

(A3.3.27)numbered Display Equation

where
numbered Display Equation

Substituting for , from Table A3.1 we can derive expressions for , using equations (A3.3.25) through (A3.3.27). A detailed derivation is shown below:
numbered Display Equation

where
numbered Display Equation

which simplifies to:
(A3.3.28)numbered Display Equation

By proceeding in the same manner as above it can be shown that:
(A3.3.29)numbered Display Equation

(A3.3.30)numbered Display Equation

Also writing:
numbered Display Equation

where

numbered Display Equation

It can be shown that the above expression gives us:
(A3.3.31)numbered Display Equation

Similarly, it can be shown that:
(A3.3.32)numbered Display Equation

(A3.3.33)numbered Display Equation

Further writing:
numbered Display Equation

where

numbered Display Equation

It can be shown that:
(A3.3.34)numbered Display Equation

Similarly, it can be shown that:
(A3.3.35)numbered Display Equation

(A3.3.36)numbered Display Equation

A3.4 Solution of the Vector Riccati Deferential Equation

Let us now consider equation (A3.2.6):
(A3.4.1)numbered Display Equation

Now:
(A3.4.2)numbered Display Equation

Writing: ; equation (A3.4.1) (in its decomposed form) may be written as:
(A3.4.3)numbered Display Equation

(A3.4.4)numbered Display Equation

(A3.4.5)numbered Display Equation

(A3.4.6)numbered Display Equation

(A3.4.7)numbered Display Equation

(A3.4.8)numbered Display Equation

Unfortunately, it is not easily possible to obtain analytical solutions to equations (A3.4.3) through (A3.4.8), except for special cases where , and , are constants. This case will be considered later on in this Appendix. In general, equations (A3.4.3) through (A3.4.8) have to be solved backward in time. For this purpose we make the substitutions:

Let: , ; ; ; ; . Hence, the above equations (A3.4.3) through (A3.4.8) may be written as:
(A3.4.9)numbered Display Equation

(A3.4.10)numbered Display Equation

(A3.4.11)numbered Display Equation

(A3.4.12)numbered Display Equation

(A3.4.13)numbered Display Equation

(A3.4.14)numbered Display Equation

These equations satisfy the boundary condition that , and must be solved backwards in time, that is, . We shall regard as time-to-go equivalent of .
A3.4.1 Analytic Solution of the VRDE—Case 2

Analytical solution of the VRDE is possible for the case when: ; ; and . For this case:
(A3.4.15)numbered Display Equation

(A3.4.16)numbered Display Equation

(A3.4.17)numbered Display Equation

Multiplying both sides of equations (A3.4.9) through (A3.4.11) respectively by , , ; we get:
(A3.4.18)numbered Display Equation

(A3.4.19)numbered Display Equation

(A3.4.20)numbered Display Equation

(A3.4.21)numbered Display Equation

(A3.4.22)numbered Display Equation

(A3.4.23)numbered Display Equation

Subtracting equations (A3.4.18) through (A3.4.20) respectively from equations (A3.4.21) through (A3.4.23) and rearranging the terms, we get:
numbered Display Equation

which gives us:
(A3.4.24)numbered Display Equation

Substituting from equation (A3.4.24) into equations (A3.4.9) through (A3.4.11), with , gives us:
numbered Display Equation

And substituting for from (A3.4.15) through (A3.4.17) gives us:
(A3.4.25)numbered Display Equation

(A3.4.26)numbered Display Equation

(A3.4.27)numbered Display Equation

After some algebraic manipulation we get:
(A3.4.28)numbered Display Equation

(A3.4.29)numbered Display Equation

(A3.4.30)numbered Display Equation

Assuming are constants, then equations (A3.4.28) through (A3.4.30) give us:
(A3.4.31)numbered Display Equation

(A3.4.32)numbered Display Equation

(A3.4.33)numbered Display Equation

and it follows from (A3.4.24) that:
(A3.4.34)numbered Display Equation

(A3.4.35)numbered Display Equation

(A3.4.36)numbered Display Equation

Finally, the disturbance term in the feedback guidance may be written as:
(A3.4.37)numbered Display Equation

(A3.4.38)numbered Display Equation

A3.5 Sight Line Rates for Small Angles and Rates

In order to establish the connection between the optimal guidance and the PN and APN we shall assume that the engagement trajectory is such that the azimuth and elevation sightline angles (Figure A3.5.1) remain small during engagement, that is, the trajectory remains close to collision close geometry. For this condition it follows that the interceptor/target relative velocity is pointed approximately along the sight line and is approximately equal to the closing velocity .

In Figure A3.5.1, we define the sightline angles as follows: are respectively the azimuth and elevation sightline angles of the target w.r.t. interceptor.
Graph shows point T indicating target and point I indicating interceptor on X, Y, and -Z, along with other points like zj, zi, xj, xi, yi, yj, r12, et cetera, which are all interconnected to each other.

Figure A3.5.1 Interceptor/target engagement geometry.

Now for small, we get:
(A3.5.1)numbered Display Equation

where

    is the projection of separation range on to the x-y plane.

Also for small, we get:
(A3.5.2)numbered Display Equation

is the separation range between the interceptor and the target.

It follows that:
numbered Display Equation

(A3.5.3)numbered Display Equation

and
numbered Display Equation

(A3.5.4)numbered Display Equation

From equation (A3.5.1) we get:
(A3.5.5)numbered Display Equation

Noting that: ; ; ; ; ; . Hence,
(A3.5.6)numbered Display Equation

(A3.5.7)numbered Display Equation

2: Optimum Control and Differential Game Theory
3: Differential Game Theory Applied to Two-Party Missile Guidance Problem
Differential Game Theory with Applications to Missiles and Autonomous Systems Guidance
4: Three-Party Differential Game Theory Applied to Missile Guidance Problem


ion



Skip to Content
Search 50,000+ courses, events, titles, and more
5
Four Degrees-of-Freedom (DOF) Simulation Model for Missile Guidance and Control Systems
Nomenclature

xij = xi − xj:

    is the x position of vehicle i w.r.t. j in fixed axis.
yij = yi − jj:

    is the y position of vehicle i w.r.t. j in fixed axis.
zij = zi − zj:

    is the z position of vehicle i w.r.t. j in fixed axis.
uij = ui − uj:

    is the x velocity of vehicle i w.r.t. j in fixed axis.
vij = vi − vj:

    is the y velocity of vehicle i w.r.t. j in fixed axis.
wij = wi − wj:

    is the x velocity of vehicle i w.r.t. j in fixed axis.

    is the x acceleration of vehicle i w.r.t. j in fixed axis.

    is the y acceleration of vehicle i w.r.t. j in fixed axis.

    is the z acceleration of vehicle i w.r.t. j in fixed axis.

    are respectively the position, velocity, and acceleration vectors of vehicle i in fixed axis.

    are respectively the position, velocity, and acceleration vectors of vehicle i w.r.t. j in fixed axis.
Rij:

    is the separation range of vehicle i w.r.t. j.

    is the closing velocity of vehicle i w.r.t. j.
ψij, θij:

    are line-of-sight (LOS) angles of vehicle i w.r.t. j in azimuth and elevation planes respectively.

    are the (x, y, z) accelerations by vehicle i in body axis.

    are the demanded (x, y, z) accelerations by vehicle i in body axis.
(ψi, θi, φi):

    are (yaw, pitch, and roll) angles respectively, of vehicle i w.r.t. the fixed axis.
[Tfb]i:

    is the transformation matrix from body axis to fixed axis.
Vi:

    is the velocity of vehicle i.

    is the autopilot longitudinal time-constant for vehicle i.

    are autopilot lateral time-constants for vehicle i.

    is the line-of-sight (LOS) rotation vector of vehicle i w.r.t. j.

    is the body rotation rate vector for vehicle i in fixed axis.

    is the body rotation rate vector for vehicle i in body axis.

    are demanded body rotation vectors for vehicle i in fixed axis and in body axis respectively.

Abbreviations

4-DOF:

    four degrees-of-freedom
APN:

    augmented PN
PN:

    proportional navigation

5.1 Introduction

In the past,1, 2 linear kinematics models, based on the assumption that the engagement geometry remains close to collision course, have been used for development and performance analysis of guidance laws for missiles. The model developed in this chapter also utilizes a linear kinematics model, but since this model takes into account vehicle body rotation it can accommodate large variations in engagement geometries. This latter fact is particularly relevant in cases where the target implements evasive maneuvers, resulting in large variations of the engagement trajectory from that of the collision course.3 Linearized models are convenient for deriving guidance laws (in analytical form), but the study of their performance characteristics still requires non-linear models that incorporate changes in body attitudes and implementation of guidance commands in body axis rather than a fixed axis.

In this chapter a mathematical model for multi-party engagement kinematics is derived suitable for developing, implementing, and testing modern missile guidance systems. The model developed here is suitable for both conventional and more advanced optimal intelligent guidance, particularly those based on the game theory guidance techniques. The model accommodates changes in vehicle body attitude and other non-linear effects such as limits on lateral acceleration and may be extended to include aerodynamic effects. Body incidence is assumed to be small and is neglected. The model presented in this chapter will be found suitable for computer simulation analysis of multi-party engagements. Section 5.2 of this chapter considers, in some detail, the derivation of engagement dynamics, whereas in Section 5.3, derivations of some of the well-known conventional guidance laws, such as the proportional navigation (PN) and the augmented PN (APN), are given. The model derived in this chapter will be referred to as the four degrees-of-freedom model as it includes three degrees (x, y, z) of translational motion and one degree of rotational motion.
5.2 Development of the Engagement Kinematics Model
5.2.1 Translational Kinematics for Multi-Vehicle Engagement

A typical two-vehicle engagement geometry is shown in Figure 5.2.1; we shall utilize this to develop the translational kinematics differential equations that relate positions, velocities, and accelerations in x, y, z-planes of individual vehicles as well as the relative positions, velocities, and accelerations. We define the following variables:

    (xi, yi, zi): are the (x, y, z) positions respectively of vehicle i in fixed axis.
    (ui, vi, wi): are the (x, y, z) velocities respectively of vehicle i in fixed axis.
    are the (x, y, z) accelerations respectively of vehicle i in fixed axis.

The above variables as well as others utilized in this chapter are functions of time t. The engagement kinematics involving n interceptors (often referred to as pursuers) and m targets (referred to as the evaders) (i = 1, 2, …, n + m), in fixed axis (e.g., inertial axis) is given by the following set of differential equations:
(5.2.1)numbered Display Equation

(5.2.2)numbered Display Equation

(5.2.3)numbered Display Equation

(5.2.4)numbered Display Equation

(5.2.5)numbered Display Equation

(5.2.6)numbered Display Equation

In order to develop relative kinematics equations for multiple vehicles i, j involved in an engagement (i: i = 1, 2, …, n; j = 1, 2, …, m; j ≠ i), we shall write the relative states as:

    xij = xi − xj: is the x position of vehicle i w.r.t. j in fixed axis.
    yij = yi − jj: is the y position of vehicle i w.r.t. j in fixed axis.
    zij = zi − zj: is the z position of vehicle i w.r.t. j in fixed axis.
    uij = ui − uj: is the x velocity of vehicle i w.r.t. j in fixed axis.
    vij = vi − vj: is the y velocity of vehicle i w.r.t. j in fixed axis.
    wij = wi − wj: is the x velocity of vehicle i w.r.t. j in fixed axis.
    is the x acceleration of vehicle i w.r.t. j in fixed axis.
    is the y acceleration of vehicle i w.r.t. j in fixed axis.
    is the z acceleration of vehicle i w.r.t. j in fixed axis.

Graph shows plotting on X, Y, and Z for vehicle engagement geometry where thetaij and yij, which intersect on dashed line, are points on Y axis and line that joins to uj and other points are ui and xij.

Figure 5.2.1 Vehicle engagement geometry.
5.2.2 Vector/Matrix Representation

It will be convenient for model development to write equations (5.2.1) through (5.2.6) in vector notation as follows:
(5.2.7)numbered Display Equation

(5.2.8)numbered Display Equation

where

    is the position vector of vehicle i in fixed axis.
    is the velocity vector of vehicle i in fixed axis.
    is the acceleration vector of vehicle i in fixed axis.

Corresponding differential equations for relative kinematics in vector notation are given by:
(5.2.9)numbered Display Equation

(5.2.10)numbered Display Equation

where

    is the position vector of vehicle i w.r.t. j in fixed axis.
    is the velocity vector of vehicle i w.r.t. j in fixed axis.
    is the acceleration vector of vehicle i w.r.t. j in fixed axis.

The above formulation admits consideration of one-one engagement as well as many-on-many.
5.2.3 Rotational Kinematics: Relative Range, Range Rates, Sightline Angles, and Rates

In this section, we develop rotational kinematics equations involving range and range rates, and sight-line (LOS) angle and angular rate. Measurements of these variables are generally obtained directly from an on-board seeker (radar or IR) or derived from an on-board navigation system or by other indirect means.
5.2.3.1 Range and Range Rates

The separation range Rij of vehicle i w.r.t. j may be written as:
(5.2.11)numbered Display Equation

Expressions for range rate may be obtained by differentiating the above equations, and are given by:
(5.2.12)numbered Display Equation

Another quantity that is often employed in the study of vehicle guidance is the “closing velocity” , which is given by:
(5.2.13)numbered Display Equation

As noted above, the range and range rate measurements are either directly available or indirectly computed from other available information [(or estimated using, e.g., a Kalman Filter (KF)]. To account for errors in these values, we may write:
(5.2.14)numbered Display Equation

(5.2.15)numbered Display Equation

where

    is the estimated/measured value of the relative range.
    is the estimated/measured value of the relative range rate.
    ΔRij: is the measurement error in relative range.
    is the measurement error in relative range rate.

5.2.3.2 Sightline Rates

The sightline rotation vector (see Figure 5.2.2) is related to the relative range and velocity as follows:
(5.2.16)numbered Display Equation

where

    is the LOS rotation vector of vehicle i w.r.t. j as defined in (as seen in) fixed axis.

It is well known that the vector triple product, which is the cross-product of a vector with the result of another cross-product, is related to the dot product by the following formula4: . Taking the cross-product of both sides of (5.2.16) by and applying this rule, we get:
(5.2.17)numbered Display Equation

Since and are mutually orthogonal, therefore ; hence:
(5.2.18)numbered Display Equation

If sightline rate values are required in body frame then equation (5.2.18) has to be transformed to body axis to obtain sightline rates in body axis. The measurement obtained from the seeker used to construct the guidance commands is given by:
(5.2.19)numbered Display Equation

where

    is the seeker LOS rate measurement error.

The above relationships (5.2.11) through (5.2.19) will also be referred to as the seeker model.
Graph shows plotting on X, Y, and Z for line-of-sight rotation, where theta ij and yij are points which intersect on dashed line, and other lines include ui, xij, w1ij, w2ij, et cetera.

Figure 5.2.2 Line-of-sight rotation.
5.3 Vehicle Navigation Model

The vehicle navigation part of the model is concerned with developing equations that allow the angular rotation of the vehicle body to be generated and subsequently computing the elements of the transformation (direction cosine) matrix. We shall utilize the quaternion algebra4 to achieve this.

Let us define the following:

    are (x, y, z) body axis accelerations achieved by vehicle i.

The transformation matrix from fixed to body axis [Tbf]i for vehicle i is given by (see Figure 5.3.1):
(5.3.1)numbered Display Equation

Abbreviations s and c are used for sin and cos of angles, respectively.
Graph shows axis rotation convention on xi, yi, and zi, which have various points and lines like Pi, xb, yb, zb, ri, yi, fi, thetai, et cetera, which are interconnected along with dashed lines.

Figure 5.3.1 Axis rotation convention ψ → θ → φ.

This equation may also be written as:
(5.3.2)numbered Display Equation

In vector/matrix notation this equation, along with its companion (inverse) transformation, may be written as:
(5.3.3)numbered Display Equation

(5.3.4)numbered Display Equation

where

    (ψi, θi, φi): are respectively yaw, pitch, and roll (Euler) angles of vehicle i w.r.t. the fixed axis.
    is the acceleration vector of vehicle i in its body axis.
    [Tfb]i = [Tbf]iT = [Tbf]i− 1: is the transformation matrix from body axis to fixed axis for vehicle i.

5.3.1 Application of Quaternion to Navigation

A fuller exposition on quaternion algebra is given in4; in this section, the main results are utilized for the navigation model for constructing the transformation matrix. We define the following quantities, referred to as the quaternions, for vehicle i as follows:
(5.3.5)numbered Display Equation

(5.3.6)numbered Display Equation

(5.3.7)numbered Display Equation

(5.3.8)numbered Display Equation

It can be shown that the transformation matrix [Tbf]i for vehicle i may be written as:
(5.3.9)numbered Display Equation

where

The elements of are functions of the quaternions and are given by the following relations:
(5.3.10)numbered Display Equation

(5.3.11)numbered Display Equation

(5.3.12)numbered Display Equation

(5.3.13)numbered Display Equation

(5.3.14)numbered Display Equation

(5.3.15)numbered Display Equation

(5.3.16)numbered Display Equation

(5.3.17)numbered Display Equation

(5.3.18)numbered Display Equation

The time-evolution of quaternion is given by the following differential equation:
(5.3.19)numbered Display Equation

In vector notation equation (5.3.19) may be written as:
(5.3.20)numbered Display Equation

where
numbered Display Equation

    is the quaternion vector for vehicle i.
    is the rotation vector of vehicle i w.r.t. to the fixed axis as seen in the body axis (also referred to as body rate vector).

The Euler angles, in terms of the elements of the transformation matrix, may be written as:
(5.3.21)numbered Display Equation

(5.3.22)numbered Display Equation

(5.3.23)numbered Display Equation

numbered Display Equation

5.4 Vehicle Body Angles and Flight Path Angles

Vehicle (absolute) velocity in fixed axis (which is the same as the absolute velocity in body axis) is given by:
(5.4.1)numbered Display Equation

where

    is a velocity vector of vehicle i in body axis.
    Vbi = Vi: is the velocity of vehicle i in body axis.

Given that the body incidence angles in pitch and yaw are (αi, βi), the flight path angles in pitch and yaw (i.e., angles that the velocity vector makes with the fixed axis) are respectively (θi − αi) and (ψi − βi).

where

    is the body pitch incidence (angle).
    is the body yaw incidence (side-slip angle).

Assuming that (vbi, wib) ≪ ubi lends justification to the assumption that (αi, βi) are small. Furthermore differentiating expressions for (αi, βi) and simplifying gives us:
(5.4.2)numbered Display Equation

(5.4.3)numbered Display Equation

For , we get . In this chapter we shall assume that the incidence angles (αi, βi) and the rates are small and hence can be ignored; and the vehicle body may be assumed to be aligned to the velocity vector.
5.4.1 Computing Body Rates (pi, qi, ri)

We now consider equations (A5.2.1) through (A5.2.3), from Appendix A5.2, for vehicle i, which we write as:
(5.4.4)numbered Display Equation

(5.4.5)numbered Display Equation

(5.4.6)numbered Display Equation

In matrix notation equations (5.4.4) through (5.4.6) may be written as:
(5.4.7)numbered Display Equation

This equation is of the form:
(5.4.8)numbered Display Equation

If it is assumed that results in only a rotation of the velocity vector, then the velocity and rotation vectors are orthogonal to , and can be assumed to be mutually orthogonal, that is:
(5.4.9)numbered Display Equation

Taking the cross-product of equation (5.4.8) with , applying the triple cross-product rule, and noting the fact that , we get:
(5.4.10)numbered Display Equation

which gives:
(5.4.11)numbered Display Equation

Assuming that the missile body is always aligned with the velocity vector, then it implies that ; it follows that the second term on the RHS of (5.4.11) is zero, which gives us:
(5.4.12)numbered Display Equation

5.5 Vehicle Autopilot Dynamics

Assuming a first order lag for the autopilot, we may write for vehicle i:
(5.5.1)numbered Display Equation

(5.5.2)numbered Display Equation

(5.5.3)numbered Display Equation

In vector/matrix notation equations (5.5.1) through (5.5.3) may be written as:
(5.5.4)numbered Display Equation

where

    is vehicle i autopilot's longitudinal time-constant.
    is vehicle i autopilot's (lateral) yaw-plane time-constant.
    is vehicle i autopilot's (lateral) pitch-plane time-constant.
    numbered Display Equation
    is the x acceleration demanded by vehicle i in its body axis.
    is the y acceleration demanded by vehicle i in its body axis.
    is the z acceleration demanded by vehicle i in its body axis.
    is the demanded acceleration vector of vehicle i in body axis.

5.6 Aerodynamic Considerations

Generally, the longitudinal acceleration of a missile is not varied in response to the guidance commands and may be assumed to be zero. However, the nominal acceleration values, which define the steady-state flight conditions, written as:
numbered Display Equation

where

    is the nominal value of aerodynamic force in ybi-direction; are respectively the thrust and drag values.
    is a nominal value of the aerodynamic force in ybi-direction.
    is a nominal value of the aerodynamic force in zbi-direction.
    (ψi θi φi): are yaw, pitch, and roll (Euler) angles of vehicle i.
    mi: is the mass of vehicle i.
    g: is the gravitational acceleration.

The aerodynamic forces change due to changes in flight conditions. For the current version of the simulation model it is assumed that is a constant (and zero). The variations in lateral accelerations: , , on the other hand, provide the necessary control effort required for guidance; the limits on these may be implemented as follows (see Appendix A5.2):
numbered Display Equation

5.7 Conventional Guidance Laws
5.7.1 Proportional Navigation (PN) Guidance

There are at least three versions of PN guidance laws that the author is aware of; in this section we consider two of these, which are (for interceptor i—the pursuer against a target j—the evader):
5.7.1.1 PN Version 1

This implementation is based on the principle that the demanded body rate of the attacker i is proportional to LOS rate to the target j that is:
(5.7.1)numbered Display Equation

where

    is the demanded body rotation vector of vehicle i in the fixed axis.
    are the navigation constants attached to the respective demand channels. If the longitudinal acceleration is not a variable (as is the case in most missiles), then .

The acceleration demanded of vehicle i is given by:
(5.7.2)numbered Display Equation

Since the guidance commands are applied in body axis, we need to transform equation (5.7.2) to body axis, thus:
(5.7.3)numbered Display Equation

Assuming that the longitudinal acceleration in response to the guidance commands is zero, we get:
(5.7.4)numbered Display Equation

5.7.1.2 PN Version 2

This implementation is based on the principle that the demanded lateral acceleration of the attacker i is proportional to the acceleration normal to the LOS, caused by the LOS rotation. Now, the LOS acceleration is given by:
(5.7.5)numbered Display Equation

Transforming to body axis gives us:
(5.7.6)numbered Display Equation

Once again, assuming that the longitudinal acceleration in response to the guidance commands is zero, we get:
(5.7.7)numbered Display Equation

where

    is the normal LOS acceleration.

Note that the difference between the PN guidance (5.7.3) and (5.7.6) is that the vector the missile velocity vector in (5.7.3) is replaced by the relative velocity vector in (5.7.6).
5.7.2 Augmented Proportional Navigation (APN) Guidance

Finally, a variation of the PN guidance law is the APN that includes the influence of the target acceleration, and can be implemented as follows:
(5.7.8)numbered Display Equation

where

    is the (target) acceleration navigation constant.
    (PNG): is the proportional navigation guidance law given in (5.3.1) through (5.3.7)

5.7.3 Optimum Guidance and Game Theory-Based Guidance

The optimum guidance and the game theory based guidance were considered in Chapters 3 and 4 and may be implemented in the model derived this chapter.
5.8 Overall State Space Model

The overall non-linear state space model (e.g., for APN guidance) that can be used for sensitivity studies and for non-linear or Monte-Carlo analysis is given below:
(5.8.1)numbered Display Equation

(5.8.2)numbered Display Equation

(5.8.3)numbered Display Equation

(5.8.4)numbered Display Equation

(5.8.5)numbered Display Equation

(5.8.6)numbered Display Equation

(5.8.7)numbered Display Equation

The overall state space model that can be implemented on the computer is given in Table A5.1, and a block diagram is given in Figure A5.1.1.
5.9 Conclusions

In this chapter, a mathematical model is derived for multi-vehicle guidance, navigation, and control suitable for developing, implementing, and testing modern missile guidance systems. The model allows for incorporating changes in body attitude in addition to autopilot lags, vehicle acceleration limits, and aerodynamic effects. This model will be found suitable for studying the performance of both the conventional and the modern guidance such as those that arise from game theory and intelligent control theory. The flight dynamic model developed in this chapter was implemented as the guidance and control simulation test-bed using MATLAB and included in Chapter 6. It was used to undertake simulation studies for the game theory-based guidance laws. The following are considered to be the main contributions of this chapter:

    A 4-DOF multi-vehicle engagement model is derived for the purposes of developing, testing, and carrying out guidance performance studies.
    The model incorporates non-linear effects including large changes in vehicle body attitude, autopilot lags, acceleration limits, and aerodynamic effects.
    The model can easily be adapted for multi-run non-linear analysis of guidance performance and for undertaking Monte Carlo analysis.
    Method for calculating the collision course heading and heading error is also derived and included in Appendix A5.3. This may be used to study the guidance performance for different heading errors.

References

    Ben-Asher, J.Z., Isaac, Y., Advances in Missile Guidance Theory, Vol. 180 of Progress in Astronautics and Aeronautics, AIAA, 1998.
    Zarchan, P., Tactical and Strategic Missile Guidance, 2nd edition, Vol. 199 of Progress in Astronautics and Aeronautics, AIAA, 2002.
    Etkin, B., Lloyd, D.F., Dynamics of Flight, 3rd edition, John Wiley & Sons, Inc. New York, 1996.
    Titterton, D. H., Weston, L., Strapdown Inertial Navigation, IEEE, 2004.

Appendix
A5.1 State Space Dynamic Model

Table A5.1 State space dynamics model for navigation, seeker, guidance, and autopilot.
	ALGORITHM 	MODULE
1 		Translational Kinematics
2 		Rotational Kinematics(Seeker Model)
3 	3.1 3.2 	Guidance Laws
4 		Autopilot
5 	5.1 Quaternions:5.2 Quaternion Evolution:; 5.3 The Transformation Matrix: 	Navigation Model
	; [Tfb]i = [Tbf]iT 	
Diagram shows guidance and block with kinematics, seeker, guidance module, autopilot, and navigation parts in circuit and other points like aj, aji, uji, xji, Rji, et cetera.

Figure A5.1.1 Guidance and control block diagram.
A5.2 Aerodynamic Forces and Equations of Motion

For a symmetrical body (Izx = 0; Iy = Iz), the equations of motion for an aerodynamic vehicle are given by (see Figure A5.2.1):4
(A5.2.1)numbered Display Equation

(A5.2.2)numbered Display Equation

(A5.2.3)numbered Display Equation

(A5.2.4)numbered Display Equation

(A5.2.5)numbered Display Equation

(A5.2.6)numbered Display Equation

where

    (ub, vb, wb): are vehicle velocities in body axis.
    (abx, axb, abx): are vehicle accelerations in body axis.
    (p, q, r): are vehicle body rotation rates w.r.t. fixed axis defined in body axis.
    (X, Y, Z): are aerodynamic forces acting on vehicle body defined in body axis.
    (L, M, N): are aerodynamic moments acting on vehicle body defined in body axis.
    (Ix, Iy, Iz): are vehicle body inertias.
    m: is the vehicle mass.
    (ψ, θ, φ): are Euler angles w.r.t. fixed axis.

Diagram shows lines M, Y, q; N, Z, r; and L, X, V, p which intersects each other and structure of conical airplane with squared blades at back, for aerodynamic forces and rotations.

Figure A5.2.1 Aerodynamic forces and rotations.
Diagram shows point M, which has lines Z, Y, Z, Q, X, and VM beginning from it, and dotted lines from VM, VT, and Q meet at point P and other points include RMT, theta T, VC, et cetera.

Figure A5.3.1 Interceptor/target collision course engagement geometry.

For a non-rolling vehicle: ; this assumption enables us to decouple the yaw and pitch kinematics. Equations (A5.2.1) through (A5.2.6) give us:
(A5.2.7)numbered Display Equation

(A5.2.8)numbered Display Equation

(A5.2.9)numbered Display Equation

(A5.2.10)numbered Display Equation

(A5.2.11)numbered Display Equation

(A5.2.12)numbered Display Equation

The accelerations about the vehicle body center of gravity (CG) is given by:
(A5.2.13)numbered Display Equation

(A5.2.14)numbered Display Equation

(A5.2.15)numbered Display Equation

where (abx, ayb, abz): are body accelerations.

If we consider perturbation about the nominal, we get:
numbered Display Equation

A5.2.1 Yaw-Plane Equations

For yaw-plane kinematics only, we assume that: (i.e., zero pitch motion), therefore, the X and Y-plane steady-state equations (in body axis) may be written as:
(A5.2.16)numbered Display Equation

(A5.2.17)numbered Display Equation

here we define: ; . Also, the total thrust is defined as: , and the total drag is defined as: .

For “nominal flight” condition in the yaw-plane ; and the perturbation equations are given by:
(A5.2.18)numbered Display Equation

(A5.2.19)numbered Display Equation

where

    δaby: is the body axis lateral acceleration.
    δabx: is the body axis longitudinal acceleration.

During guidance maneuver are not directly controlled, hence we may assume δabx to be zero.
A5.2.2 Pitch-Plane Kinematics Equations

Unlike the previous case, for pitch-plane kinematics, we get:
(A5.2.20)numbered Display Equation

(A5.2.21)numbered Display Equation

The X, Z (pitch)-plane perturbation kinematics (in body axis) is given by:
(A5.2.22)numbered Display Equation

(A5.2.23)numbered Display Equation

where

    δabz: is the body axis lateral acceleration.

As in the case of the yaw-plane, during guidance are not directly controlled, hence we may assume δabx to be zero. The reader will recognize that in the main text of this chapter:
(A5.2.24)numbered Display Equation

A5.2.3 Calculating the Aerodynamic Forces

For the purposes of the simulation under consideration we may assume that the vehicle thrust profile , say as a function of time, is given; then the drag force , which depends on the vehicle aerodynamic configuration, is given by:
(A5.2.25)numbered Display Equation

(A5.2.26)numbered Display Equation

(A5.2.27)numbered Display Equation

where the term in the bracket is the dynamic pressure; ρ being the air density, S is the body characteristic surface area and is the steady-state velocity. CD is the drag coefficient and CL is the lift coefficient.

represent respectively the pitch- and the yaw-plane nominal (steady-state) incidence angles. Contributions to thrust and/or drag due to control deflections are small and ignored. Also:
(A5.2.28)numbered Display Equation

(A5.2.29)numbered Display Equation

(δα, δβ) represent respectively the variation in pitch- and yaw-plane incidence angles as a result of control demands; these are assumed to be small. Note that for a given (δα, δβ), δY, δZ∝V2, the maximum/minimum acceleration capability of a vehicle is rated at the nominal velocity , then the maximum/minimum acceleration at any other velocity V is given by:
numbered Display Equation

A5.2.4 Body Incidence

The body incidence angles (α, β) are given by (vb, wb ≪ ub):
numbered Display Equation

represent the angle that the body makes w.r.t. “flight path” or with the direction of the total velocity vector V. In this chapter we shall assume that these angles are small and may be ignored, in which case the body can be assumed to be aligned with the velocity vector.
A5.3 Computing Collision Course Missile Heading Angles
A5.3.1 Computing () Given (VT, , , , )

Here we wish to compute βTS, the angle between the target velocity vector and the (missile/target) sightline vector measured in (VT × RTM × VM − plane), given the following data:

    (ψT, θT): are target velocity vector azimuth and elevation angles respectively.
    (ψS, θS): are LOS velocity vector azimuth and elevation angles respectively.
    VT: is the target velocity vector.

Now the unit vector along the target body and the unit LOS vector may be written as:
(A5.3.1)numbered Display Equation

(A5.3.2)numbered Display Equation

where

    is the unit vector along the target velocity.
    is the unit vector along the target/missile sightline (LOS).

It follows from equations (A5.3.1) and (A5.3.2) that the (scalar) dot product of may be written as:
(A5.3.3)numbered Display Equation

Equation (A5.3.3) gives us:
(A5.3.4)numbered Display Equation

where

    βTS: is the angle between the target velocity vector and the target/missile sightline vector measured in (VT × RTM × VM − plane).

A5.3.2 Computing Given (VM, )

Here we wish to compute: (βMS)cc, the angle between the missile collision course velocity vector and the sightline vector in (VT × RTM × VM − plane), given the following data:

    VM: is the target velocity vector.
    βTS: as computed as shown in the previous section.

Consideration of collision course engagement in (VM × VT × RMT − plane) gives us:
(A5.3.5)numbered Display Equation

Equation (A5.3.5) gives us:
(A5.3.6)numbered Display Equation

where

    βMS: is the angle between the missile velocity vector and the sightline vector in (VT × RTM × VM − plane).

A5.3.3 Computing the Closing Velocity (VC) and Time-to-Go (Tgo)

We shall define:
(A5.3.7)numbered Display Equation

Also, the target/missile range-to-go (RMT) is defined as:
(A5.3.8)numbered Display Equation

then
(A5.3.9)numbered Display Equation

where

    VC: is the collision course closing velocity of the missile w.r.t. the target. Note that the collision course velocity is along the range vector RMT.
    Tgo: is time-to-go (to intercept).

A5.3.4 Computing the Collision Course Missile (Az. and El.) Heading: ;

Now the components of the relative position vector of the missile w.r.t. the target may be written as:
(A5.3.10)numbered Display Equation

(A5.3.11)numbered Display Equation

(A5.3.12)numbered Display Equation

where

    (ψM)cc: is a missile collision course azimuth heading, measured w.r.t. the fixed axis.
    (θM)cc: is a missile collision course elevation heading, measured w.r.t. the fixed axis.

Equations (A5.3.10) through (A5.3.12) give us:
(A5.3.13)numbered Display Equation

(A5.3.14)numbered Display Equation

(A5.3.15)numbered Display Equation

Equation (A5.3.15) gives us:
(A5.3.16)numbered Display Equation

Similarly equations (A2.13) and (A2.14) (after some straightforward algebraic manipulation) give us:
(A5.3.17)numbered Display Equation

A5.3.5 Example: Computing 2-DOF Collision Course Missile Heading Angles

Vertical Plane Engagement:

For this case (ψT = ψM = ψS = 0) and βTS = (θT − θS), βMS = (θM − θS); hence, utilizing equation (A5.3.16) we get:
(A5.3.18)numbered Display Equation

(A5.3.19)numbered Display Equation

Horizontal Plane Engagement:

For this case (θT = θM = θS = 0) and βTS = (ψT − ψS), βMS = (ψM − ψS); hence, utilizing (A5.3.16) we get:
(A5.3.20)numbered Display Equation

4: Three-Party Differential Game Theory Applied to Missile Guidance Problem
5: Four Degrees-of-Freedom (DOF) Simulation Model for Missile Guidance and Control Systems
Differential Game Theory with Applications to Missiles and Autonomous Systems Guidance
6: Three-Party Differential Game Missile Guidance Simulation Study


Skip to Content
Search 50,000+ courses, events, titles, and more
6
Three-Party Differential Game Missile Guidance Simulation Study
Nomenclature

    is the (3×1) position vector of vehicle i in fixed axis.

    is the (3×1) velocity vector of vehicle i in fixed axis.

    is the (3×1) acceleration vector of vehicle i in fixed axis.

    is the (3×1) relative position vector of vehicle i w.r.t. vehicle j in fixed axis.

    is the (3×1) relative position vector of vehicle i w.r.t. vehicle j in fixed axis.
I:

    is the (3×3) identity matrix.
S:

    is the final-state PI weightings matrix.
F:

    is the state coefficient matrix.
G:

    is the input coefficient matrix.

    is the combined relative state vector for vehicle i w.r.t. j.

    is the attacker 3 guidance input vector.

    is the defender 2 guidance input vector.

    is the target 1 guidance input vector.

    are input PI weightings matrices for target, defender, and attacker respectively.

Abbreviations

4-DOF:

    four degrees-of-freedom
6-DOF:

    six degrees-of-freedom
AI:

    artificial intelligence
PI:

    performance index
w.r.t.:

    with respect to

6.1 Introduction

Earlier reported research1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12 on the application of game theory to the missile guidance problem has concentrated on engagement scenarios that involve two parties. The scenarios are composed of an attacking missile (pursuer) aimed against another missile, or an aircraft referred to as the evader, whose objective is to execute maneuvers designed to evade the attacking missile. In this chapter, the above approach is extended to a three-party engagement, which includes the situation where one of the parties, such as an attacking missile, has a dual objective—that is, to evade the pursuer (e.g., a defending missile) and then continue on its mission to attack its designated target.

The particular scenario that we shall consider here consists of an aircraft target, which on becoming aware that it is being engaged by an attacking missile, fires a defending missile to engage and intercept this attacking missile and perform evasive maneuvers. The role of the defending missile is only to intercept the attacking missile; the attacking missile, on the other hand, must perform the dual role that includes evading the defending missile and intercepting its primary target—that is, the aircraft. Since the participants in this type of engagement consist of three players (an aircraft target, an attacking missile, and a defending missile), we shall refer to this type of engagement scenario as a three-party game.

In the references,1 the author used a linear quadratic performance index (LQPI) approach to formulate the game theoretic guidance problem and showed that in a 2-D engagement case, explicit analytical solution may be obtained for guidance feedback gains (the guidance law). The feedback gains involve parameters of the LQPI weightings and the time-to-go: T = (tf − t). The author also considered the case of engagements that involve a single pursuer against multiple stationary targets.

Application of the differential game theory to a three-party scenario (involving a target, a missile, and a defender) was considered in the references.11, 13, 14 A linear state feedback guidance law was derived for guidance commands (lateral accelerations) of the parties using the LQPI approach. This current chapter considers the case where the attacking missile may be required to perform both evasion and intercept maneuvers during the engagement. Kinematics models are developed and a solution to the problem is obtained in terms of the Riccati differential equations, which admit a wide choice of performance index (PI) weightings. Preliminary simulation results are included in order to demonstrate the characteristics of intercept and evasion strategies of the parties. Simple (rule-based) artificial intelligence-based avoidance strategies are also implemented for enhancing evasion by the aircraft target and for intercept by the attacking missile.
6.2 Engagement Kinematics Model

In this section we consider the engagement kinematics model for the three parties under consideration, in a fixed-axis coordinate system, depicted in Figure 6.2.1. Differential equations for position, velocity, and acceleration for a vehicle i (in our case: i = 1, 2, 3) may be written as:
(6.2.1)numbered Display Equation

(6.2.2)numbered Display Equation

where

    is the (3×1) position vector of vehicle i in fixed axis.
    is the (3×1) velocity vector of vehicle i in fixed axis.
    is the (3×1) acceleration vector of vehicle i in fixed axis.

Graph shows collision course engagement geometrics for target, attacker, and defender on X, Y, and Z axes, which have points P31, P23, u1, u2, u3, x3, y3, z3, et cetera.

Figure 6.2.1 Collision course engagement geometries for target (1), attacker (3), and defender (2). Pij –intercept point.

Equations (6.2.1) through (6.2.2) may be written in state space form as follows:
(6.2.3)numbered Display Equation

It follows from equation (6.2.3) that relative kinematics for vehicle i w.r.t. vehicle j may be written as:
(6.2.4)numbered Display Equation

where

    is the (3×1) relative position vector of vehicle i w.r.t. vehicle j in fixed axis.
    is the (3×1) relative velocity vector of vehicle i w.r.t. vehicle j in fixed axis.
    j ≠ i
    [I]: is a (3×3) identity matrix.

For the current problem we shall assume that the states of a high-value target (an aircraft, for example) are defined by: i = 1, and that it is being engaged by a ground-launched attacking missile defined by j = 3. It is further assumed that a defending missile is fired from the high-value target to defend itself against the attacking missile. In this scenario we are interested in the following relative states: that of the attacker 3 against the high-value target 1; states of the target relative to the attacker are with guidance inputs given by . In this case includes the evasion maneuver executed by the high-value target 1, and includes the intercept (pursuit) guidance command of the attacking missile 3. States of the engagement model for the defending interceptor 2 fired against the attacker missile 3 are taken to be , with intercept guidance input to 2 given by ; the evasion maneuver by party 3 in this case is included in and is given by . In order to accommodate this situation and to clearly distinguish between the guidance commands designed for intercept and those designed for evasion, we shall write:
(6.2.5)numbered Display Equation

As given in equation (6.2.5), we note that that the high-value target executes only an evasive maneuver and the defender executes only a pursuit maneuver; the attacker on the other hand executes an evasive maneuver to avoid the attacker, and a pursuit maneuver to engage the high-value target.

Using equation (6.2.5), the relative engagement kinematics model for target 1 and attacker 3 may be written as:
(6.2.6)numbered Display Equation

This equation is of the form:
(6.2.7)numbered Display Equation

Note that the inputs in equation (6.2.7) contain evasion inputs by vehicle 1 and pursuer inputs by vehicle 3. Similarly, relative engagement kinematics model for interceptor 2 and attacker 3 may be written as:
(6.2.8)numbered Display Equation

This equation is of the form:
(6.2.9)numbered Display Equation

where
numbered Display Equation

6.3 Game Theory Problem and the Solution

The three-party game theoretic problem may be stated as follows: Given the dynamical system (6.2.7) and (6.2.9), with initial states, and scalar quadratic performance indices (PIs) given by:
(6.3.1)numbered Display Equation

(6.3.2)numbered Display Equation

where

    [S]: is the (6×6) (at least) positive semi-definite matrix that defines the PI weightings (or soft constraints) on the final relative states.
    (Re1, R2p, Re3, R3p): are (3×3) positive-definite matrices that define the PI weightings on inputs.

The object here is to derive the guidance commands: , , such that optimum values J*(⋅⋅⋅) of the PIs are achieved in the sense that:
(6.3.3a)numbered Display Equation

(6.3.3b)numbered Display Equation

The engagement time (i.e., the flight time for a minimum separation or the “miss-distance”) for parties 2 and 3, given by: , will generally be different to the engagement time for parties 3 and 1, given by: . This certainly was the case for the simulation problem considered in this chapter.

Remarks

    In this chapter we consider the case where S = diagonal(s s s 0 0 0), with s a scalar; so that the first terms in the PI indices are simply weighted final miss distances: and,
    The PI index for the problem under consideration may be viewed as that of minimizing the final miss w.r.t. the pursuer inputs and maximizing this quantity w.r.t. to the evader input, subject to “soft constraints” on the inputs of the vehicles involved. Further, we assume that R = (Re1 = r1eI,  Rp2 = r2pI,  Re3 = r3eI,  Rp3 = r1pI). The choice of S and R affects the Riccati solution.
    It will be assumed that all parties have access to full information regarding all of the system states, that is , are known to all parties. It is suggested in the references1 that in order to cater for imperfect information, full state information may have to be constructed, and a time delay may have to be introduced in applying the guidance commands. Implementation of a state estimator would be an ideal approach, as it would provide an assessment of the effects of delays and state estimation errors on the guidance performance.
    The guidance commands define the actions of pursuers and are such as to minimize the PI Ji(⋅⋅⋅) while the guidance commands define the actions of the evaders and are such as to maximize Ji(⋅⋅⋅). These conflicting requirements are achieved by putting minus signs with the terms representing the evasive maneuvers.

In order to obtain a solution to the problem posed above we shall follow closely the LQPI approach such as the one suggested in Chapters 3 and 4. The Hamiltonians H1(⋅⋅⋅), H2(⋅⋅⋅) for this problem may be written as:
(6.3.4)numbered Display Equation

(6.3.5)numbered Display Equation

Remark

    In the simulation study presented in this chapter, the final miss distance has been computed for a single (run) initial condition w.r.t. the heading error value and the engagement geometry. For a multiple run study for assessing the effects of a large number of different heading errors and engagement geometries, the Monte Carlo technique could be used.

Necessary conditions for optimality for the above equations are given by:
(6.3.6)numbered Display Equation

(6.3.7)numbered Display Equation

(6.3.8)numbered Display Equation

(6.3.9)numbered Display Equation

and
(6.3.10)numbered Display Equation

(6.3.11)numbered Display Equation

The boundary conditions are given by: and .

Let us assume: and then equations (6.3.6)–(6.3.9) give us:
(6.3.12)numbered Display Equation

(6.3.13)numbered Display Equation

(6.3.14)numbered Display Equation

(6.3.15)numbered Display Equation

where

    [Pi]: are (6×6) Riccati matrices.

Using equations (6.3.10) through (6.3.15) along with equations (6.2.7) and (6.2.9), it can be shown (requires some matrix algebra, see Chapters 3, 4) that the following Riccati differential equations are obtained for [Pi], i = 1, 2:
(6.3.16)numbered Display Equation

(6.3.17)numbered Display Equation

with the boundary condition: [Pi(tf)] = [S];  i = 1, 2.

Remarks

    Equations (6.3.12) through (6.3.15) define the state feedback guidance commands (guidance law), which are used to generate the evasion and pursuit strategies.
    The Riccati equations (6.3.16) and (6.3.17) must be solved backward in time to obtain their solution. Analytical solution is also possible using the procedure similar to the one used in Chapters 3 and 4.
    In the theoretical development presented in this chapter, the guidance commands (for both the pursuer and the evader) are derived in fixed-axis coordinate system; however, these are applied in the vehicle body axis. Also, most missiles are capable of achieving high lateral accelerations that can be controlled, but the longitudinal acceleration is not easily varied; a zero longitudinal acceleration is generally assumed for missiles and even aircraft. The above consideration implies that the guidance commands, although derived using optimization theory, are in fact “sub-optimal” when we consider the guidance commands applied in body axis. Inclusion of the transformation matrix, either in the kinematics model or incorporated in the PI, would allow us to directly solve the optimum guidance problem with guidance accelerations applied in vehicle body axis. The difficulty with both these methods is that the resulting Riccati equation becomes a function of states, and may pose problems in its solution.
    Autopilot lags were not included in the derivation of the optimum guidance. However, these have been accommodated in the simulation model. Inclusion of autopilot dynamics in the guidance law derivation increases the order of the system dynamics model, and can be considered within the methodology presented in this book. An engagement kinematics model that includes the autopilot time constants and guidance commands applied in body axis was used in the simulation program developed in Chapter 5.

6.4 Discussion of the Simulation Results
6.4.1 Game Theory Guidance Demonstrator Simulation

In this section we discuss the results of the differential game-based guidance simulation obtained via the MATLAB-based simulation program (faruqi_dgt_DEMO). A disk containing the *.m files of this program is included with this book. The program was developed and tested using the MATLAB versions 2011a and 2014a. It is the author's understanding that in later versions of MATLAB, certain modifications have been made to the software that may cause the graphics of the simulation to be affected. The author cannot give warranties that the output graphics will work as originally intended by the author. Also, while the author has taken every care to verify the code no warranty is given as to correctness of the code.

Missile guidance simulation parameters used for the simulation are shown in the listing in the addendum. For convenience, these parameters are also given in Table 6.4.1 below.

Table 6.4.1 Key parameter values used in the DEMO simulation.
Parameters 	Values
Target, defender, and attacker velocities in body axis. 	640 m/s; 960 m/s; 960 m/s.
Target, defender, and attacker starting x, y, z positions w.r.t. the origin in fixed axis. 	(5000 m, 5000 m, −8000 m);(5000 m, 5000 m, −8000 m);(15000 m, 5000 m, 0.0 m).
El., Az. heading errors for the attacker and the defender. 	5 degrees in both El. and Az. for both.
Game theory guidance PI parameters: 	s1 = 1; s2 = 1; s3 = 1; s4 = 0; s5 = 0; s6 = 0; r1_bar = 0.00011; r2 = .0001; r3_bar = 0.00011; r3 = .0001.
Lateral (y, z) acceleration g-limits:Longitudinal acceleration = 0 g. 	Target: ± 8g; Defender: ± 40g;Attacker: ± 40g
Lateral autopilot bandwidth: 	3 sec−1
Other simulation parameters: 	as shown in the program listing.

The simulation run output plots are shown in Figures 6.4.1 through (d), where

    Plot (a): shows the elevation versus down-range (Z versus X) trajectories.
    Plot (b): shows the elevation versus cross-range (Z versus Y) trajectories.
    Plot (c): shows the cross-range versus down-range (Y versus X) trajectories.

In these plots the trajectory for the target is shown as a “continuous line,” for the attacker is shown as a “dashed line,” and for the defender is shown as a “dotted line.”

    Plot (d): shows the projected miss-distance (MD) values as a function of time for attacker 3 w.r.t. target 1 (dashed line) and defender 2 w.r.t. attacker 3 (dotted line). The minimum value is the miss-distance achieved; this value is also given on this plot. Vertical lines shown mark the times for minimum separation (miss-distance) of the vehicles.
    Symbols: (circle, asterisk) mark the closest approach of the attacker and the target, and (box, asterisk) mark the closest approach of the attacker and the defender.

The reader can observe the characteristic behaviors of the three parties (target, defender, and attacker) involved the target (continuous-line trajectory), the attacker (dashed-line trajectory) and the defender (dotted-line trajectory), given in Figures 6.4.1, (b), and (c). Weave-like trajectories characterize pursuit and evasion tactics employed by the parties. Projected miss-distance plots are given in Figure 6.4.1(d). Here, Miss31 is the miss between the attacker and the target (dashed line) and Miss23 (dotted line) is the miss between the defender and the attacker. This plot shows that Miss23 of 161.04 m occurs at 7.77 s, suggesting that the attacker has managed to evade the defender in their first encounter. First miss between the attacker and the target Miss31 of 513 m occurs at 10.49 s. This would suggest that the target has safely evaded the attacker in the first encounter; perhaps because the attacker, in order to evade the defender, had its pursuit trajectory diverted to a degree where it was unable to intercept the target successfully. It is further seen from plot (d) that the attacker closes in on the target during the first and subsequent encounters; however, the closest approach (145 m at 16.56 s) is large enough to class it as a miss.
6.4.2 Game Theory Guidance Simulation Including Disturbance Inputs

Further simulation studies were undertaken to study the characteristics of the optimum game theory guidance developed in this chapter, including disturbance inputs derived on rule-based AI-based guidance schemes. The results are shown in Figures 6.4.2(a, b, and c); plots (a) show the separation range whose minimum value is the miss distance achieved (MD). In the plots MD31 is the miss distance between attacker 3 and aircraft target 1, and MD23 is the miss distance between defender 2 and attacker 3; plots (b) show the (Z-X plane) elevation engagement trajectories, and plots (c) show the (Z-Y plane) engagement trajectories. The PI weightings were obtained through preliminary simulations, such as to yield “unbiased engagements” (i.e., the weightings were selected so as not to give any one party an advantage over the others) and to display salient features of the guidance performance. Of course, fine tuning of these parameters is possible depending on particular requirements. Sub-Figure 6.4.1(a, b, c) show the case of engagements when there is no evasion and the parties are expending all their energies for interception. In this case, the defender successfully intercepts the attacker (MD23 = 0.604, at 6.18s). However, as shown in the plots, if we continue the simulation, then the attacker also intercepts the target, first time at (MD31 = 0.166, at 7.56s) and a second time at about 26s.

For the cases discussed above, it appears that attacker 3 is unable to get through to target 1; clearly, the defender has managed to get in between the aircraft target and the attacker and has managed to achieve intercept (low miss-distances) with the attacker. We therefore considered implementation of additional maneuvers initiated (through rule-based logic) in order to enhance the ability of the attacker to evade the defender and to enhance the ability of the aircraft target to get away from the attacker. This is shown in sub-Figure 6.4.2(a, b, c). In this case, the attacker is allowed to disengage the evasion after the first minimum separation from the defender and apply only the intercept guidance against the target. It is shown that the attacker is able to achieve intercept with the target in this case (miss MD31=0.13m, at 17.24 s). Sub-Figure 6.4.3(a, b, c) shows the case where the aircraft target applies additional maneuvers (constant-8g in both pitch and yaw planes at 10s into the engagement). In this case the miss MD31=21.4m at 15s is achieved, and the aircraft is able to evade the attacker. The maneuver times were obtained through multiple simulation sensitivity studies; further work is required in this area in order to obtain optimum time and the g-level for evasion maneuvers. It is left to the reader to try other combinations of PI parameters to see if it is possible for the attacker to evade the defender and achieve intercept with the target without the need to implement additional (rule-based) maneuvers.

A listing of the MATLAB code used for the 4-DOF simulation model is included in the addendum of this chapter and a CD containing the MATLAB *.m files used in generating the plots in Figures 6.4.1 and Figure 6.4.2 is included in this book. The program allows the user to change the engagement geometries and the PI parameters in order to simulate different engagement scenarios.
Graph shows altitude versus down-range for plotting target, attacker and defender indicated with solid, dashed, and dotted lines, where curve of target passes through curve of attacker.

Figure 6.4.1(a) Plot of Altitude vs. Down-Range for Target, Attacker and Defender.
Graph shows altitude (m) versus cross-range (m) for target, attacker, and defender, where curve of target begins near 4,000 on cross-range and ends at 5,000, which continues as defender.

Figure 6.4.1(b) Plot of Altitude vs. Cross-Range for Target, Attacker and Defender.
Graph shows cross range versus down-range for target, attacker, and defender, where curves of target and defender begin at 5,000 on cross range and all three curves intersect with each other.

Figure 6.4.1(c) Plot of Cross-Range vs. Down Range for Target, Attacker and Defender.
Graph shows range-to-go (m) versus time (s) for miss31: attacker vs. target and miss23: defender vs. attacker, where both curves intersect each other after 8 seconds on time.

Figure 6.4.1(d) Plot of Miss-Distances for Attacker-to-Target and Defender-to-Attacker.
Graphs show simulation result with disturbance inputs, where plotting is on range-to-go (m*1,000) versus time, altitude versus down-range, and altitude versus cross-range.

Figure 6.4.2 Simulation Results with Disturbance Inputs. Source: Faruqi 2012.10 Reproduced with permission of DSTO.
6.5 Conclusions

In this chapter, three-party evasion and intercept guidance are derived using differential game theory for 3-D engagements using the 4-DOF simulation model developed in Chapter 5. Analytical solutions are derived for Riccati differential equations and for the guidance feedback gains that are required for implementing the optimum game theory missile guidance. Simulation results are given and discussed for a set of engagements between an aircraft target, an attacking ground-based missile, and a defending missile fired from the aircraft. Use of rule-based AI for initiating additional maneuvers (e.g., a step-acceleration) is also considered in the simulations. This is used primarily to enhance the (evasion) performance of the attacking missile and also that of the aircraft target. For engagement scenarios considered it has been shown that the attacking missile can be countered by the defending missile utilizing a differential game-based guidance. The simulation program allows the attacker to utilize additional maneuvers applied using rule-based AI logic. The simulations suggest that if an engagement is continued after missing the first time, the attacker is successfully able to intercept the target subsequently. Simulation results also indicate that the evasion and intercept trajectories are reactive (coupled), that is, the behavior of the evasion trajectory affects the intercept trajectory and vice versa. Further work is required to test game theory guidance for (a) different PI weightings, (b) different aircraft, attacker, and defender characteristics (e.g., velocities, acceleration capabilities, and autopilot bandwidths). Finally, it would be useful to study the application of the differential game-based guidance using a full 6-DOF simulation platform that allows for high order and non-linear aircraft and missile system models.
6.5.1 Useful Future Studies

There are a number of options available for the target, the attacker and/or the defender to implement additional maneuvers to gain advantage toward meeting their objectives. The author proposes that this can be achieved by applying additional maneuvers (disturbance inputs) or switching the performance index weightings as a function of time to go. That is, “rules” can be implemented within the guidance structures that enable the parties to trigger these changes based on time to go. The current chapter, along with Chapters 3 and 4, considered the implementation of additional maneuvers, where the attacker, once it achieves a minimum range w.r.t. the defender, triggers such a maneuver to get away from the defender. Time-to-go value at which this occurs can be determined through multiple runs of the simulation. Research is ongoing to study alternative methods of switching the PI weights or applying additional maneuvers as well as formal structures for implementing AI rules.
References

    Ben-Asher, J. Z., Isaac, Y., Advances in Missile Guidance Theory, Vol. 180 of Progress in Astronautics and Aeronautics, AIAA, 1st ed., 1998.
    Isaacs, R., Differential Games, Dover Publications, 1965.
    Robb, M. C., Tsourdos, A., and White, B. A., “Earliest Intercept Line Guidance Using a Game Theory Approach,” AIAA Guidance, Navigation, and Control Conference, No. AIAA-2006-6216, 2006.
    Sage, A. P., Optimum Systems Control, Prentice Hall, 1968.
    Shinar, J., Siegel, A., and Gold, Y., “On the analysis of a complex differential game using artificial intelligence,” Proceedings of the 27th IEEE Conference on Decision and Control, 1988, pp. 1436–1441.
    Shinar, J., Guelman, M., Silberman, G., and Green, A., “On optimal missile avoidance – a comparison between optimal control and differential game solutions,” IEEE International Conference on Control and Applications, 1989, pp. 453–459.
    Shinar, J. and Shima, T., “A game theoretical interceptor guidance law for ballistic missile defence,” Proceedings of the35th IEEE Conference on Decision and Control, 1996, pp. 2780–2785.
    Shinar, J., “On the feasibility of ‘hit to kill’ in the interception of a manoeuvring target,” American Control Conference, 2001, pp. 3358–3363.
    Zarchan, P., Tactical and Strategic Missile Guidance, Vol. 199 of Progress in Astronautics and Aeronautics, AIAA, 2nd ed., 2002.
    Faruqi, F. A., “Intelligent 3-Party Game Theoretic Approach to Missile Guidance”, Proc. AAIA (Conference GNC/AFM/MST/ASC), paper 152-GNC-69 on Guidance, Navigation & Control, Aug. 2012.
    Faruqi, F. A., “Integrated Navigation, Guidance and Control of Missile Systems: 3-D Dynamic Model”, DSTO Report TR-2805, March 2013.
    Rusnak, I., “Game based Guidance in Anti-Missile Defence for High Order Participants”, IEEE Conf. MELECON 2010, p812.
    Basar, T., Olsder, G.J., Dynamic Non-cooperative Game Theory, Academic Press 1982.
    Rusnak, I., “The target, the Missile and the Defender – A Two Team Dynamic Game”, The 16th IFAC World Congress, Prague, July 2005.

Appendix
A6.1 Analytical Solution for Riccati Equations

A detailed discussion of the game theory-based feedback guidance laws along with various different expressions for the guidance gains was given in Chapters 3 and 4. It was shown that the solution for the Riccati equations may be written as:
(A6.1.1)numbered Display Equation

For the case: [S] = diag[s s s 0 0 0]; [Rpi] = rip[I];  i = 2, 3; [Rei] = rie[I]; j = 1, 3.
(A6.1.2)numbered Display Equation

(A6.1.3)numbered Display Equation

(A6.1.4)numbered Display Equation

where
(A6.1.5)numbered Display Equation

Table A6.1 Selection of the PI weightings for Figure 6.4.2.
Run No. 	s1, s2, s3 	re1, r2p, re3, r3p
1 (a, b, c) 	1, 1, 1 	103, 10− 3, 103, 10− 3
2 (a, b, c) 	1, 1, 1 	
3 (a, b, c) 	1, 1, 1 	
Addendum

1. Listing for fauqi_dgt_DEMO.m

This program was developed and run on MATLAB 2011a, 2014at; the author of this book cannot guarantee its compatibility with other versions of MATLAB.


%%*************************faruqi_dgt_DEMO*********************************
% ************AIR-AIR MULTI PARTY GAME SIMULTION **************************
% Creator: F.Faruqi
% Single Run Version
% Includes Autopilot:
% Version-1: October 2012; Updated: July 2015; Data for Wiley DEMO
% While the Author has verified the accuracy of the program; no
% guarantee/warranty is expressed or implied. The user should verify the
% correctness of this simulation for his particular application.
% *************************************************************************
% *************************************************************************
%%=========================================================================
% 10.10.10: Simulation Parameters Values ==============================+===
% =========================================================================
t0=0; % Simulation start time
tf=30; % Simulation final time.Test 1-7.
del_t=.0005; % Simulation integration step (Trapeziodal Rule Implemented).
t=t0:del_t:tf; % Simulation time.
T_index=length(t);
%==========================================================================
%%=========================================================================
% 10.10.20: Number of Vehicles Values =====================================
% +++++++++++==============================================================
i_num=3; % Number of vehicles involved in the engagement.
j_num=3; % Number of vehicles involved in the engagement.
% For this simulation (3-party Game Simuulation), the following definition
% is used:
% VEHICLE INDEX 1: High Value (Aircraft) Target;
% VEHICLE INDEX 2: Defender (Missile) or Pursuer; with the purpose of
% intercepting the attcker-2.
% VEHICLE INDEX 3: Attacker (Missile) evader against the defender-2, while
% attacking the high value target-1, while evading the defender.
%==========================================================================
%%=========================================================================
% 10.10.30: Set Up Vehicle Body-Axis States ===============================
%==========================================================================
%10.10.30.10: Position Vector:
x_b=zeros(i_num,T_index);
y_b=zeros(i_num,T_index);
z_b=zeros(i_num,T_index);
 
% 10.10.30.20: Velocity Vector:
u_b=zeros(i_num,T_index);
v_b=zeros(i_num,T_index);
w_b=zeros(i_num,T_index);
 
% 10.10.30.30: Acceleration Vector:
ax_b=zeros(i_num,T_index);
ay_b=zeros(i_num,T_index);
az_b=zeros(i_num,T_index);
 
% 10.10.30.40: Acceleration Deritivr Vector:
ax_b_dot=zeros(i_num,T_index);
ay_b_dot=zeros(i_num,T_index);
az_b_dot=zeros(i_num,T_index);
 
% 10.10.30.50: Demanded Acceleration Vector(Autopilot Input):
ax_b_dem=zeros(i_num,T_index);
ay_b_dem=zeros(i_num,T_index);
az_b_dem=zeros(i_num,T_index);
 
% Body-Axis Rotation Rate Vector:
p_b=zeros(i_num,T_index);
q_b=zeros(i_num,T_index);
r_b=zeros(i_num,T_index);
 
% Total-Body Axis Velocity and Acceleration:
V_b=zeros(i_num,T_index);
V_b_sq=zeros(i_num,T_index);
 
A_b_sq=zeros(i_num,T_index);
A_b=zeros(i_num,T_index);
 
%% INPUT VALUES===========================================================
% Body-Axis Velocity Vector Values:
 u_b(1,1) = 660.0000; %Baseline
 u_b(2,1) = 990.0000; %Baseline
 u_b(3,1) = 990.0000; %Baseline
 
v_b(1,1) = 0.0;
v_b(2,1) = 0.0;
v_b(3,1) = 0.0;
 
w_b(1,1) = 0.0;
w_b(2,1) = 0.0;
w_b(3,1) = 0.0;
 
% Body-Axis Acceleration Vector Values:
ax_b(1,1)=0.0;
ax_b(2,1)=0.0;
ax_b(3,1)=0.0;
 
ay_b(1,1)=0.0;
ay_b(2,1)=0.0;
ay_b(3,1)=0.0;
 
az_b(1,1)=0.0;
az_b(2,1)=0.0;
az_b(3,1)=0.0;
 
% Body-AxisRotation Vector Values:
p_b(1,1)=0.0;
q_b(2,1)=0.0;
r_b(3,1)=0.0;
%==========================================================================
% Compute Body Axis Total Velocity, Acceleration & Body Rates:
for i=1:i_num;
    V_b(i,1)=sqrt(u_b(i,1)*u_b(i,1)+v_b(i,1)*v_b(i,1)+w_b(i,1)*w_b(i,1));
    V_b_sq(i,1)=V_b(i,1)*V_b(i,1);
 
A_b_sq(i,1)=(ax_b(i,1)*ax_b(i,1)+ay_b(i,1)*ay_b(i,1)+az_b(i,1)*az_b(i,1));
    A_b(i,1)=sqrt(A_b_sq(i,1));
end
 
for i=1:i_num;
    p_b(i,1)=(v_b(i,1)*az_b(i,1)-w_b(i,1)*ay_b(i,1))/V_b_sq(i,1);
    q_b(i,1)=(w_b(i,1)*ax_b(i,1)-u_b(i,1)*az_b(i,1))/V_b_sq(i,1);
    r_b(i,1)=(u_b(i,1)*ay_b(i,1)-v_b(i,1)*ax_b(i,1))/V_b_sq(i,1);
end
 
%% 10.30. Vehicle Heading (Euler) Angles and Quaternions*******************
phi=zeros(i_num,T_index);
theta=zeros(i_num,T_index);
psi=zeros(i_num,T_index);
 
% INPUT VALUES============================================================+
phi(1,1)=0*pi/180;
phi(2,1)=0*pi/180;
phi(3,1)=0*pi/180;
 
psi(1,1)=0*pi/180;
theta(1,1)=0*pi/180;
 
psi(2,1)=0*pi/180;
theta (2,1)=0*pi/180;
 
psi(3,1)=0*pi/180;
theta(3,1)=0*pi/180;
 
%% 10.40. Vehicle Fixed_Axis States ***************************************
% Fixed-Axis Position Vector:
x_i=zeros(i_num,T_index);
y_i=zeros(i_num,T_index);
z_i=zeros(i_num,T_index);
 
% Fixed-Axis Velocity Vector:
u_i=zeros(i_num,T_index);
v_i=zeros(i_num,T_index);
w_i=zeros(i_num,T_index);
 
% Fixed-Axis Acceleration Vector:
ax_i=zeros(i_num,T_index);
ay_i=zeros(i_num,T_index);
az_i=zeros(i_num,T_index);
 
% Fixed Axis Demanded Acceleration (Guidance Demands)
ax_i_dem=zeros(i_num,T_index);
ay_i_dem=zeros(i_num,T_index);
az_i_dem=zeros(i_num,T_index);
 
% Fixed-Axis Rotation Rate Vector:
p_i=zeros(i_num,T_index);
q_i=zeros(i_num,T_index);
r_i=zeros(i_num,T_index);
 
% Fixed-Axis Total Range, Velocity and Acceleration:
R_i_sq=zeros(i_num,T_index);
R_i=zeros(i_num,T_index);
 
V_i_sq=zeros(i_num,T_index);
V_i=zeros(i_num,T_index);
 
A_i_sq=zeros(i_num,T_index);
A_i=zeros(i_num,T_index);
 
% INPUT VALUES=============================================================
x_i(1,1)=5000.0000; %target Baseline
x_i(2,1)=5000.0000; %defender Baseline
x_i(3,1)=15000.0000; % target Baseline
 
y_i(1,1)=5000.0000;
y_i(2,1)=5000.0000;
y_i(3,1)=5000.0000;
 
z_i(1,1)=-8000.0000;
z_i(2,1)=-8000.0000;
z_i(3,1)=-0000.0000;
 
%==========================================================================
%% 10.50. Vehicle Fixed-Axis Relative States ******************************
rel_x_i=zeros(i_num,j_num,T_index);
rel_y_i=zeros(i_num,j_num,T_index);
rel_z_i=zeros(i_num,j_num,T_index);
 
rel_u_i=zeros(i_num,j_num,T_index);
rel_v_i=zeros(i_num,j_num,T_index);
rel_w_i=zeros(i_num,j_num,T_index);
 
rel_ax_i=zeros(i_num,j_num,T_index);
rel_ay_i=zeros(i_num,j_num,T_index);
rel_az_i=zeros(i_num,j_num,T_index);
 
rel_R1_i_sq=zeros(i_num,j_num,T_index);
rel_R1_i=zeros(i_num,j_num,T_index);
 
rel_R_i_sq=zeros(i_num,j_num,T_index);
rel_R_i=zeros(i_num,j_num,T_index);
 
rel_V_i_sq=zeros(i_num,j_num,T_index);
rel_V_i=zeros(i_num,j_num,T_index);
 
rel_A_i_sq=zeros(i_num,j_num,T_index);
rel_A_i=zeros(i_num,j_num,T_index);
 
rel_R1_i_dot=zeros(i_num,j_num,T_index);
rel_R_i_dot=zeros(i_num,j_num,T_index);
% Relative Azimuth, Elevation LOS Angles & Closing Velocity:
rel_theta_los_i=zeros(i_num,j_num,T_index);
rel_psi_los_i=zeros(i_num,j_num,T_index);
 
rel_theta_los_i_dot=zeros(i_num,j_num,T_index);
rel_psi_los_i_dot=zeros(i_num,j_num,T_index);
 
clos_vel=zeros(i_num,j_num,T_index);
 
% Compute Relative Positons & LOS Angles:
for i = 1:i_num;
    for j =1:j_num;
        if(i~=j);
            rel_x_i(i,j,1) = x_i(i,1)-x_i(j,1);
            rel_y_i(i,j,1) = y_i(i,1)-y_i(j,1);
            rel_z_i(i,j,1) = z_i(i,1)-z_i(j,1);
 
            rel_R1_i_sq(i,j,1)=(rel_x_i(i,j,1)*rel_x_i(i,j,1)+…
                rel_y_i(i,j,1)*rel_y_i(i,j,1));
            rel_R1_i(i,j,1)=sqrt(rel_R1_i_sq(i,j,1));
 
rel_R_i_sq(i,j,1)=(rel_R1_i_sq(i,j,1)+rel_z_i(i,j,1)*rel_z_i(i,j,1));
            rel_R_i(i,j,1)=sqrt(rel_R_i_sq(i,j,1));
 
            rel_psi_los_i(i,j,1) = atan2(rel_y_i(i,j,1),rel_x_i(i,j,1));
            rel_theta_los_i(i,j,1) = atan2(-rel_z_i(i,j,1),rel_R1_i(i,j,1));
        end
    end
end
 
%% 10.60. Collision Course Headings ***************************************
beta = zeros(i_num,j_num,T_index);
beta_cc = zeros(i_num,j_num,T_index);
 
cos_cos_cc = zeros(i_num,j_num,T_index);
cos_sin_cc = zeros(i_num,j_num,T_index);
 
VC_cc = zeros(i_num,j_num,T_index);
 
theta_cc =  zeros(i_num,j_num,T_index);
psi_cc =  zeros(i_num,j_num,T_index);
 
theta_he=zeros(i_num,T_index);
psi_he=zeros(i_num,T_index);
 
% INPUT VALUES
% =========================================================================
defender_cc_override=0;
%==========================================================================
 
% Heading Error Values for Computing Collision Course:
 
 theta_he(3,1)=5*pi/180; %Baseline
 psi_he(3,1)=5*pi/180;   %Baseline
 theta_he(2,1)=5*pi/180;  %Baseline
 psi_he(2,1)=5*pi/180;   %Baseline
% Compute Collision Course Headings (Attacker):
for i_target= 1:2;
    if(i_target==1);
        j=1; % target
        i=3; % attacker
    end
    % Compute Collision Course Headings (Defender):
    if(i_target==2);
        j=3;
        i=2;
        %Compute Defender Heading Based on Attacker's HE
        psi(3,1) = psi_cc(3,1,1)+psi_he(3,1);
        theta(3,1) = theta_cc(3,1,1)+theta_he(3,1);
    end
    A=cos(theta(j,1))*cos(psi(j,1))*cos(rel_theta_los_i(j,i,1))*…
        cos(rel_psi_los_i(j,i,1));
    B=cos(theta(j,1))*sin(psi(j,1))*cos(rel_theta_los_i(j,i,1))*…
        sin(rel_psi_los_i(j,i,1));
    C=sin(theta(j,1))*sin(rel_theta_los_i(j,i,1));
    D=A+B+C;
    beta(j,i,1)=acos(D);
    beta_cc(i,j,1) = asin(u_b(j,1)*sin(beta(j,i,1))/u_b(i,1));
    VC_cc(i,j,1) = u_b(i,1)*cos(beta_cc(i,j,1))-u_b(j,1)*…
        cos(beta(j,i,1));
    theta_cc(i,j,1) = asin((VC_cc(i,j,1)/u_b(i,1))*…
        sin(rel_theta_los_i(j,i,1))+(u_b(j,1)/u_b(i,1))*…
        sin(theta(j,1)));
    cos_cos_cc(i,j,1) = (VC_cc(i,j,1)/u_b(i,1))*…
        cos(rel_theta_los_i(j,i,1))*cos(rel_psi_los_i(j,i,1))+…
        (u_b(j,1)/u_b(i,1))*cos(theta(j,1))*cos(psi(j,1));
    cos_sin_cc(i,j,1) = (VC_cc(i,j,1)/u_b(i,1))*…
        cos(rel_theta_los_i(j,i,1))*sin(rel_psi_los_i(j,i,1))+…
        (u_b(j,1)/u_b(i,1))*cos(theta(j,1))*sin(psi(j,1));
    psi_cc(i,j,1)=atan2(cos_sin_cc(i,j,1),cos_cos_cc(i,j,1));
    xxx=1;
end
 
% Heading Error Values for Defender Post-Collision Course Computation:
theta(2,1) = theta_cc(2,3,1)+theta_he(2,1);
psi(2,1) = psi_cc(2,3,1)+psi_he(2,1);
 
if(defender_cc_override==1);
    theta(2,1) = theta(1,1)+theta_he(2,1);
    psi(2,1) = psi(1,1)+psi_he(2,1);
end
 
%% 10.70. Compute Quaternions:*********************************************
% Compute Quaternion Definition and Transformation Matrix (DCM):
quat1=zeros(i_num,T_index);
quat2=zeros(i_num,T_index);
quat3=zeros(i_num,T_index);
quat4=zeros(i_num,T_index);
quat_sq=zeros(i_num,T_index);
quat=zeros(i_num,T_index);
 
t11_bi=zeros(i_num,T_index);
t12_bi=zeros(i_num,T_index);
t13_bi=zeros(i_num,T_index);
t21_bi=zeros(i_num,T_index);
t22_bi=zeros(i_num,T_index);
t23_bi=zeros(i_num,T_index);
t31_bi=zeros(i_num,T_index);
t32_bi=zeros(i_num,T_index);
t33_bi=zeros(i_num,T_index);
 
for i=1:i_num;
    quat1(i,1)=cos(phi(i,1)/2)*cos(theta(i,1)/2)*cos(psi(i,1)/2)…
        +sin(phi(i,1)/2)*sin(theta(i,1)/2)*sin(psi(i,1)/2);
    quat2(i,1)=sin(phi(i,1)/2)*cos(theta(i,1)/2)*cos(psi(i,1)/2)…
        -cos(phi(i,1)/2)*sin(theta(i,1)/2)*sin(psi(i,1)/2);
    quat3(i,1)=cos(phi(i,1)/2)*sin(theta(i,1)/2)*cos(psi(i,1)/2)…
        +sin(phi(i,1)/2)*cos(theta(i,1)/2)*sin(psi(i,1)/2);
    quat4(i,1)=cos(phi(i,1)/2)*cos(theta(i,1)/2)*sin(psi(i,1)/2)…
        -sin(phi(i,1)/2)*sin(theta(i,1)/2)*cos(psi(i,1)/2);
 
    quat_sq(i,1)=quat1(i,1)*quat1(i,1)+quat2(i,1)*quat2(i,1)+…
        quat3(i,1)*quat3(i,1)+quat4(i,1)*quat4(i,1);
    quat(i,1)=sqrt(quat_sq(i,1));
 
    quat1(i,1)=quat1(i,1)/quat(i,1);
    quat2(i,1)=quat2(i,1)/quat(i,1);
    quat3(i,1)=quat3(i,1)/quat(i,1);
    quat4(i,1)=quat4(i,1)/quat(i,1);
end
 
% Compute Transformation Matrix form Body to Fixed (DCM):
for i = 1:i_num
    t11_bi(i,1)=quat1(i,1)*quat1(i,1)+quat2(i,1)*quat2(i,1)…
        -quat3(i,1)*quat3(i,1)-quat4(i,1)*quat4(i,1);
    t12_bi(i,1)=2*(quat2(i,1)*quat3(i,1)-quat1(i,1)*quat4(i,1));
    t13_bi(i,1)=2*(quat2(i,1)*quat4(i,1)+quat1(i,1)*quat3(i,1));
    t21_bi(i,1)=2*(quat2(i,1)*quat3(i,1)+quat1(i,1)*quat4(i,1));
    t22_bi(i,1)=quat1(i,1)*quat1(i,1)-quat2(i,1)*quat2(i,1)…
        +quat3(i,1)*quat3(i,1)-quat4(i,1)*quat4(i,1);
    t23_bi(i,1)=2*(quat3(i,1)*quat4(i,1)-quat1(i,1)*quat2(i,1));
    t31_bi(i,1)=2*(quat2(i,1)*quat4(i,1)-quat1(i,1)*quat3(i,1));
    t32_bi(i,1)=2*(quat3(i,1)*quat4(i,1)+quat1(i,1)*quat2(i,1));
    t33_bi(i,1)=quat1(i,1)*quat1(i,1)-quat2(i,1)*quat2(i,1)…
        -quat3(i,1)*quat3(i,1)+quat4(i,1)*quat4(i,1);
end
 
%% 10.80. Compute Other Fixed Axis States**********************************
% Compute Fixed-Axis velocity & Acceleration:
for i=1:i_num;
 
u_i(i,1)=t11_bi(i,1)*u_b(i,1)+t12_bi(i,1)*v_b(i,1)+t13_bi(i,1)*w_b(i,1);
 
v_i(i,1)=t21_bi(i,1)*u_b(i,1)+t22_bi(i,1)*v_b(i,1)+t23_bi(i,1)*w_b(i,1);
 
w_i(i,1)=t31_bi(i,1)*u_b(i,1)+t32_bi(i,1)*v_b(i,1)+t33_bi(i,1)*w_b(i,1);
 
 
ax_i(i,1)=t11_bi(i,1)*ax_b(i,1)+t12_bi(i,1)*ay_b(i,1)+t13_bi(i,1)*az_b(i,1);
ay_i(i,1)=t21_bi(i,1)*ax_b(i,1)+t22_bi(i,1)*ay_b(i,1)+t23_bi(i,1)*az_b(i,1);
 
az_i(i,1)=t31_bi(i,1)*ax_b(i,1)+t32_bi(i,1)*ay_b(i,1)+t33_bi(i,1)*az_b(i,1);
 
    % Fixed_Axis Total Range,Velocity, Acceleration & Body Rates:
    R_i_sq(i,1)=(x_i(i,1)*x_i(i,1)+y_i(i,1)*y_i(i,1)+z_i(i,1)*z_i(i,1));
    R_i(i,1)=sqrt(R_i_sq(i,1));
 
    V_i_sq(i,1)=(u_i(i,1)*u_i(i,1)+v_i(i,1)*v_i(i,1)+w_i(i,1)*w_i(i,1));
    V_i(i,1)=sqrt(V_i_sq(i,1));
 
A_i_sq(i,1)=(ax_i(i,1)*ax_i(i,1)+ay_i(i,1)*ay_i(i,1)+az_i(i,1)*az_i(i,1));
    A_i=sqrt(A_i_sq(i,1));
 
    p_i(i,1)=(v_i(i,1)*az_i(i,1)-w_i(i,1)*ay_i(i,1))/V_i_sq(i,1);
    q_i(i,1)=(w_i(i,1)*ax_i(i,1)-u_i(i,1)*az_i(i,1))/V_i_sq(i,1);
    r_i(i,1)=(u_i(i,1)*ay_i(i,1)-v_i(i,1)*ax_i(i,1))/V_i_sq(i,1);
end
 
%% Compute Relative Positons, LOS Angles & Closing:
for i = 1:i_num;
    for j =1:j_num;
        if(i~=j);
 
            rel_u_i(i,j,1) = u_i(i,1)-u_i(j,1);
            rel_v_i(i,j,1) = v_i(i,1)-v_i(j,1);
            rel_w_i(i,j,1) = w_i(i,1)-w_i(j,1);
 
            rel_ax_i(i,j,1) = ax_i(i,1)-ax_i(j,1);
            rel_ay_i(i,j,1) = ay_i(i,1)-ay_i(j,1);
            rel_az_i(i,j,1) = az_i(i,1)-az_i(j,1);
 
            rel_R1_i_dot(i,j,1)=(rel_x_i(i,j,1)*rel_u_i(i,j,1)…
                +rel_y_i(i,j,1)*rel_v_i(i,j,1))/rel_R1_i(i,j,1);
            rel_R_i_dot(i,j,1)=(rel_x_i(i,j,1)*rel_u_i(i,j,1)…
                +rel_y_i(i,j,1)*rel_v_i(i,j,1)…
                +rel_z_i(i,j,1)*rel_w_i(i,j,1))/rel_R_i(i,j,1);
 
            rel_V_i_sq(i,j,1)=(rel_u_i(i,j,1)*rel_u_i(i,j,1)+…
                rel_v_i(i,j,1)*rel_v_i(i,j,1)+…
                rel_w_i(i,j,1)*rel_w_i(i,j,1));
            rel_V_i(i,j,1)=sqrt(rel_V_i_sq(i,j,1));
 
            rel_A_i_sq(i,j,1)=(rel_ax_i(i,j,1)*rel_ax_i(i,j,1)+…
                rel_ay_i(i,j,1)*rel_ay_i(i,j,1)+…
                rel_az_i(i,j,1)*rel_az_i(i,j,1));
            rel_A_i(i,j,1)=sqrt(rel_A_i_sq(i,j,1));
 
            rel_psi_los_i_dot(i,j,1)=(rel_x_i(i,j,1)*rel_v_i(i,j,1)…
                -rel_y_i(i,j,1)*rel_u_i(i,j,1))/rel_R1_i_sq(i,j,1);
            rel_theta_los_i_dot(i,j,1)=(rel_w_i(i,j,1)*rel_R1_i(i,j,1)…
                -rel_z_i(i,j,1)*rel_R1_i_dot(i,j,1))/rel_R_i_sq(i,j,1);
 
        end
    end
end
%% 10.90. Autopilot Parameters ********************************************
% Autopilot Bandwidth & Input Limit Values:
bw_ax=zeros(i_num);
bw_ay=zeros(i_num);
bw_az=zeros(i_num);
 
limit_ax=zeros(i_num);
limit_ay=zeros(i_num);
limit_az=zeros(i_num);
 
bw_ax(1)=.1; bw_ax(2)=.1; bw_ax(3)=.1;
bw_ay(1)=3; bw_ay(2)=3; bw_ay(3)=3;
bw_az(1)=3; bw_az(2)=3; bw_az(3)=3;
 
%Set values for g-limits
lim_max_x=zeros(i_num);
lim_min_x=zeros(i_num);
lim_max_y=zeros(i_num);
lim_min_y=zeros(i_num);
lim_max_z=zeros(i_num);
lim_min_z=zeros(i_num);
 
%INPUT VALUES==============================================================
lim_max_x(1)=0; lim_min_x(1)=0;
lim_max_x(2)=0; lim_min_x(2)=0;
lim_max_x(3)=0; lim_min_x(3)=0;
 
lim_max_y(1)=80; lim_min_y(1)=-80;
lim_max_y(2)=400; lim_min_y(2)=-400;
lim_max_y(3)=400; lim_min_y(3)=-400;
 
lim_max_z(1)=80; lim_min_z(1)=-80;
lim_max_z(2)=400; lim_min_z(2)=-400;
lim_max_z(3)=400; lim_min_z(3)=-400;
 
%==========================================================================
%% 10.100 PN. APN Guidance-Law Parameters *********************************
 
nav_const_los=zeros(i_num);
nav_const_ax=zeros(i_num);
nav_const_ay=zeros(i_num);
nav_const_az=zeros(i_num);
 
miss_dist=zeros(i_num,j_num);
miss_flag=zeros(i_num,j_num);
flight_time=zeros(i_num,j_num);
 
for i=1:i_num;
    for j=1:j_num;
        if(i~=j);
            miss_dist(i,j)=rel_R_i(i,j,1);
        end
    end
end
 
 
%% 10.110. Optimum Guidance Parameters*************************************
 
T_1=zeros(1,T_index);
T_2=zeros(1,T_index);
 
rand_x=zeros(i_num,T_index);
rand_y=zeros(i_num,T_index);
rand_z=zeros(i_num,T_index);
 
ax_b_bias=zeros(i_num,T_index);
ay_b_bias=zeros(i_num,T_index);
az_b_bias=zeros(i_num,T_index);
 
sigma_1=0;
sigma_2=0;
sigma_3=0;
mean_1=0;
mean_2=0;
mean_3=0;
 
 
%% 10.120. TRIAL PARAMETER VALUES *****************************************
factor1=1;
factor2=1;
factor3=1;
factor4=1;
 
T_1_factor=1;
T_2_factor=1;
 
del_T_1=0;
del_T_2=0;
 
% INPUT VALUES=============================================================
% TEST 2 values
% s1 =1; s2=1; s3=1; s4=0; s5=0; s6=0;
% r1_bar=0.1001; r3=0.1;r3_bar=0.1001; r2=0.1;
 
%**************************************************************************
% PN TEST Values
% s1 =10; s2=10; s3=10; s4=0; s5=0; s6=0;%  PN Test
% r1_bar=1000; r2=.0001; r3_bar=1000; r3=.0001; % PN Test
 
%**************************************************************************
%TEST 1 Values
% r1_bar=1.001; r3=1.0;r3_bar=1.001; r2=1.0; %exp. r values
% s1 =1; s2=1; s3=1; s4=0; s5=0; s6=0; %experiment 3.1
 
%**************************************************************************
%TEST BASELINE
 s1 =1; s2=1; s3=1; s4=0; s5=0; s6=0; %BASELINE
 r1_bar=0.00011; r2=.0001; r3_bar=0.00011; r3=.0001; %BASELINE
 
%==========================================================================
r_diff_1=(r1_bar*r3)/(r1_bar-r3);
r_diff_2=(r3_bar*r2)/(r3_bar-r2);
% Calculate Guidance Gains:
T_1(1,1)=T_1_factor*abs(rel_R_i(3,1,1)/rel_R_i_dot(3,1,1))+del_T_1;
T_2(1,1)=T_2_factor*abs(rel_R_i(2,3,1)/rel_R_i_dot(2,3,1))+del_T_2;
 
T_1_sq=T_1(1,1)*T_1(1,1);
T_1_cube=T_1_sq*T_1(1,1);
T_1_fourth=T_1_cube*T_1(1,1);
 
T_2_sq=T_2(1,1)*T_2(1,1);
T_2_cube=T_2_sq*T_2(1,1);
T_2_fourth=T_2_cube*T_2(1,1);
 
% Gains for vehicle 3 against 1:
den_1=(12.0*r_diff_1*r_diff_1+12.0*s4*r_diff_1*T_1(1,1)+…
    4.0*s1*r_diff_1*T_1_cube+s1*s4*T_1_fourth);
den_2=(12.0*r_diff_1*r_diff_1+12.0*s5*r_diff_1*T_1(1,1)+…
    4.0*s2*r_diff_1*T_1_cube+s2*s5*T_1_fourth);
den_3=(12.0*r_diff_1*r_diff_1+12.0*s6*r_diff_1*T_1(1,1)+…
    4.0*s3*r_diff_1*T_1_cube+s3*s6*T_1_fourth);
 
num_14=6.0*s1*r_diff_1*T_1(1,1)*(2.0*r_diff_1+s4*T_1(1,1));
num_25=6.0*s2*r_diff_1*T_1(1,1)*(2.0*r_diff_1+s5*T_1(1,1));
num_36=6.0*s3*r_diff_1*T_1(1,1)*(2.0*r_diff_1+s6*T_1(1,1));
num_44=4.0*r_diff_1*(3.0*s4*r_diff_1+3.0*s1*r_diff_1*T_1_sq+s1*s4*T_1_cube);
num_55=4.0*r_diff_1*(3.0*s5*r_diff_1+3.0*s2*r_diff_1*T_1_sq+s2*s5*T_1_cube);
num_66=4.0*r_diff_1*(3.0*s6*r_diff_1+3.0*s3*r_diff_1*T_1_sq+s3*s6*T_1_cube);
 
 
% Interceptor (3) intercept gains against Target (1)
g31_1=(num_14/den_1)/r3;
g31_2=(num_25/den_2)/r3;
g31_3=(num_36/den_3)/r3;
g31_4=(num_44/den_1)/r3;
g31_5=(num_55/den_2)/r3;
g31_6=(num_66/den_3)/r3;
 
% target (1) evasion gains against attacker (3)
g13_1=(num_14/den_1)/r1_bar;
g13_2=(num_25/den_2)/r1_bar;
g13_3=(num_36/den_3)/r1_bar;
g13_4=(num_44/den_1)/r1_bar;
g13_5=(num_55/den_2)/r1_bar;
g13_6=(num_66/den_3)/r1_bar;
 
% Gains for vehicles 2 against 3:
den_1=(12.0*r_diff_2*r_diff_2+12.0*s4*r_diff_2*T_2(1,1)+…
    4.0*s1*r_diff_2*T_2_cube+s1*s4*T_2_fourth);
den_2=(12.0*r_diff_2*r_diff_2+12.0*s5*r_diff_2*T_2(1,1)+…
    4.0*s2*r_diff_2*T_2_cube+s2*s5*T_2_fourth);
den_3=(12.0*r_diff_2*r_diff_2+12.0*s6*r_diff_2*T_2(1,1)+…
    4.0*s3*r_diff_2*T_2_cube+s3*s6*T_2_fourth);
 
num_14=6.0*s1*r_diff_2*T_2(1,1)*(2.0*r_diff_2+s4*T_2(1,1));
num_25=6.0*s2*r_diff_2*T_2(1,1)*(2.0*r_diff_2+s5*T_2(1,1));
num_36=6.0*s3*r_diff_2*T_2(1,1)*(2.0*r_diff_2+s6*T_2(1,1));
num_44=4.0*r_diff_2*(3.0*s4*r_diff_2+3.0*s1*r_diff_2*T_2_sq+s1*s4*T_2_cube);
num_55=4.0*r_diff_2*(3.0*s5*r_diff_2+3.0*s2*r_diff_2*T_2_sq+s2*s5*T_2_cube);
num_66=4.0*r_diff_2*(3.0*s6*r_diff_2+3.0*s3*r_diff_2*T_2_sq+s3*s6*T_2_cube);
 
% defender (2) intercept gains against attacker (3)
g23_1=(num_14/den_1)/r2;
g23_2=(num_25/den_2)/r2;
g23_3=(num_36/den_3)/r2;
g23_4=(num_44/den_1)/r2;
g23_5=(num_55/den_2)/r2;
g23_6=(num_66/den_3)/r2;
 
% attacker (3) evasion gains against defender (2)
g32_1=(num_14/den_1)/r3_bar;
g32_2=(num_25/den_2)/r3_bar;
g32_3=(num_36/den_3)/r3_bar;
g32_4=(num_44/den_1)/r3_bar;
g32_5=(num_55/den_2)/r3_bar;
g32_6=(num_66/den_3)/r3_bar;
 
%Guidance demands in Fixed Axis:
 
ax_i_dem(1,1)=factor1*(g13_1*rel_x_i(1,3,1)+g13_4*rel_u_i(1,3,1));
ax_i_dem(2,1)=factor2*(g23_1*rel_x_i(3,2,1)+g23_4*rel_u_i(3,2,1));
ax_i_dem(3,1)=factor3*(g31_1*rel_x_i(1,3,1)+g31_4*rel_u_i(1,3,1)…
    +factor4*(g32_1*rel_x_i(3,2,1)+g32_4*rel_u_i(3,2,1)));
 
ay_i_dem(1,1)=factor1*(g13_2*rel_y_i(1,3,1)+g13_5*rel_v_i(1,3,1));
ay_i_dem(2,1)=factor2*(g23_2*rel_y_i(3,2,1)+g23_5*rel_v_i(3,2,1));
ay_i_dem(3,1)=factor3*(g31_2*rel_y_i(1,3,1)+g31_5*rel_v_i(1,3,1)…
    +factor4*(g32_2*rel_y_i(3,2,1)+g32_5*rel_v_i(3,2,1)));
 
az_i_dem(1,1)=factor1*(g13_3*rel_z_i(1,3,1)+g13_6*rel_w_i(1,3,1));
az_i_dem(2,1)=factor2*(g23_3*rel_z_i(3,2,1)+g23_6*rel_w_i(3,2,1));
az_i_dem(3,1)=factor3*(g31_3*rel_z_i(1,3,1)+g31_6*rel_w_i(1,3,1)…
    +factor4*(g32_3*rel_z_i(3,2,1)+g32_6*rel_w_i(3,2,1)));
 
%Convert to Demands in Body Axis
for i=1:i_num;
    ax_b_dem(i,1)=t11_bi(i,1)*ax_i_dem(i,1)+t21_bi(i,1)*ay_i_dem(i,1)+…
        t31_bi(i,1)*az_i_dem(i,1);
    ay_b_dem(i,1)=t12_bi(i,1)*ax_i_dem(i,1)+t22_bi(i,1)*ay_i_dem(i,1)+…
        t32_bi(i,1)*az_i_dem(i,1);
    az_b_dem(i,1)=t13_bi(i,1)*ax_i_dem(i,1)+t23_bi(i,1)*ay_i_dem(i,1)+…
        t33_bi(i,1)*az_i_dem(i,1);
end
%% g-constraints
ax_b_dem(1,1)=0;
ax_b_dem(2,1)=0;
ax_b_dem(3,1)=0;
 
if ay_b_dem(1,1)<lim_min_y(1); ay_b_dem(1,1)=lim_min_y(1); end
if ay_b_dem(1,1)>lim_max_y(1); ay_b_dem(1,1)=lim_max_y(1); end
if ay_b_dem(2,1)<lim_min_y(2); ay_b_dem(2,1)=lim_min_y(2); end
if ay_b_dem(2,1)>lim_max_y(2); ay_b_dem(2,1)=lim_max_y(2); end
if ay_b_dem(3,1)<lim_min_y(3); ay_b_dem(3,1)=lim_min_y(3); end
if ay_b_dem(3,1)>lim_max_y(3); ay_b_dem(3,1)=lim_max_y(3); end
if az_b_dem(1,1)<lim_min_z(1); az_b_dem(1,1)=lim_min_z(1); end
if az_b_dem(1,1)>lim_max_z(1); az_b_dem(1,1)=lim_max_z(1); end
if az_b_dem(2,1)<lim_min_z(2); az_b_dem(2,1)=lim_min_z(2); end
if az_b_dem(2,1)>lim_max_z(2); az_b_dem(2,1)=lim_max_z(2); end
if az_b_dem(3,1)<lim_min_z(3); az_b_dem(3,1)=lim_min_z(3); end
if az_b_dem(3,1)>lim_max_z(3); az_b_dem(3,1)=lim_max_z(3); end
 
% Vehicles Additional Manoeuvres
ax_b_bias(1,1)=0;
ay_b_bias(1,1)=0;
az_b_bias(1,1)=0;
 
ax_b_bias(2,1)=0;
ay_b_bias(2,1)=0;
az_b_bias(2,1)=0;
 
ax_b_bias(3,1)=0;
ay_b_bias(3,1)=0;
az_b_bias(3,1)=0;
 
%% ************************ END INITIALISATION BLOCK **********************
 
%% ************************************************************************
%  20. START MAIN SIMULATION LOOP::
%  ************************************************************************
%% 20.10. Update Inertial_Axis Position, Velocity & Acceleration:
 
for T=1:T_index-1;
    for i=1:i_num;
        [x_i(i,T+1),y_i(i,T+1),z_i(i,T+1),u_i(i,T+1),v_i(i,T+1),…
            w_i(i,T+1),ax_i(i,T+1),ay_i(i,T+1),az_i(i,T+1),…
            quat1(i,T+1),quat2(i,T+1),quat3(i,T+1),quat4(i,T+1),…
            t11_bi(i,T+1),t12_bi(i,T+1),t13_bi(i,T+1),t21_bi(i,T+1),…
            t22_bi(i,T+1),t23_bi(i,T+1),t31_bi(i,T+1),t32_bi(i,T+1),…
            t33_bi(i,T+1)]=…
            kinematics3(x_i(i,T),y_i(i,T),z_i(i,T),u_i(i,T),v_i(i,T),…
            w_i(i,T),quat1(i,T),quat2(i,T),quat3(i,T),quat4(i,T),…
 
p_b(i,T),q_b(i,T),r_b(i,T),ax_b(i,T),ay_b(i,T),az_b(i,T),del_t);
 
        R_i_sq(i,T+1)=(x_i(i,T+1)*x_i(i,T+1)+y_i(i,T+1)*y_i(i,T+1)+…
            z_i(i,T+1)*z_i(i,T+1));
        R_i(i,T+1)=sqrt(R_i_sq(i,T+1));
 
        V_i_sq(i,T+1)=(u_i(i,T+1)*u_i(i,T+1)+v_i(i,T+1)*v_i(i,T+1)+…
            w_i(i,T+1)*w_i(i,T+1));
        V_i(i,T+1)=sqrt(V_i_sq(i,T+1));
        A_i_sq(i,T+1)=(ax_i(i,T+1)*ax_i(i,T+1)+ay_i(i,T+1)*ay_i(i,T+1)+…
            az_i(i,T+1)*az_i(i,T+1));
        A_i(i,T+1)=sqrt(A_i_sq(i,T+1));
 
        p_i(i,T+1)=(v_i(i,T+1)*az_i(i,T+1)-w_i(i,T+1)*ay_i(i,T+1))/V_i_sq(i,T+1);
        q_i(i,T+1)=(w_i(i,T+1)*ax_i(i,T+1)-u_i(i,T+1)*az_i(i,T+1))/V_i_sq(i,T+1);
        r_i(i,T+1)=(u_i(i,T+1)*ay_i(i,T+1)-v_i(i,T+1)*ax_i(i,T+1))/V_i_sq(i,T+1);
    end
 
    %%  20.20. Update Inertial_Axis Relative States************************
    for i = 1:i_num;
        for j =1:j_num;
            if(i~=j);
                rel_x_i(i,j,T+1) = x_i(i,T+1)-x_i(j,T+1);
                rel_y_i(i,j,T+1) = y_i(i,T+1)-y_i(j,T+1);
                rel_z_i(i,j,T+1) = z_i(i,T+1)-z_i(j,T+1);
 
                rel_u_i(i,j,T+1) = u_i(i,T+1)-u_i(j,T+1);
                rel_v_i(i,j,T+1) = v_i(i,T+1)-v_i(j,T+1);
                rel_w_i(i,j,T+1) = w_i(i,T+1)-w_i(j,T+1);
 
                rel_ax_i(i,j,T+1) = ax_i(i,T+1)-ax_i(j,T+1);
                rel_ay_i(i,j,T+1) = ay_i(i,T+1)-ay_i(j,T+1);
                rel_az_i(i,j,T+1) = az_i(i,T+1)-az_i(j,T+1);
 
                rel_R1_i_sq(i,j,T+1)=(rel_x_i(i,j,T+1)*rel_x_i(i,j,T+1)+…
                    rel_y_i(i,j,T+1)*rel_y_i(i,j,T+1));
                rel_R1_i(i,j,T+1)=sqrt(rel_R1_i_sq(i,j,T+1));
 
                rel_R_i_sq(i,j,T+1)=(rel_R1_i_sq(i,j,T+1)+…
                    rel_z_i(i,j,T+1)*rel_z_i(i,j,T+1));
                rel_R_i(i,j,T+1)=sqrt(rel_R_i_sq(i,j,T+1));
 
                rel_V_i_sq(i,j,T+1)=(rel_u_i(i,j,T+1)*rel_u_i(i,j,T+1)+…
                    rel_v_i(i,j,T+1)*rel_v_i(i,j,T+1)+…
                    rel_w_i(i,j,1)*rel_w_i(i,j,1));
                rel_V_i(i,j,T+1)=sqrt(rel_V_i_sq(i,j,T+1));
 
                rel_A_i_sq(i,T+1)=(rel_ax_i(i,j,T+1)*rel_ax_i(i,j,T+1)+…
                    rel_ay_i(i,j,T+1)*rel_ay_i(i,j,T+1)+…
                    rel_az_i(i,j,T+1)*rel_az_i(i,j,T+1));
                rel_A_i(i,j,T+1)=sqrt(rel_A_i_sq(i,j,T+1));
 
                % Update Range, LOS Angle and Rates:
                rel_R1_i_dot(i,j,T+1)=(rel_x_i(i,j,T+1)*rel_u_i(i,j,T+1)…
                    +rel_y_i(i,j,T+1)*rel_v_i(i,j,T+1))/rel_R1_i(i,j,T+1);
                rel_R_i_dot(i,j,T+1)=(rel_x_i(i,j,T+1)*rel_u_i(i,j,T+1)…
                    +rel_y_i(i,j,T+1)*rel_v_i(i,j,T+1)…
                    +rel_z_i(i,j,T+1)*rel_w_i(i,j,T+1))/rel_R_i(i,j,T+1);
 
                rel_psi_los_i_dot(i,j,T+1)=(rel_x_i(i,j,T+1)*…
                    rel_v_i(i,j,T+1)-rel_y_i(i,j,T+1)*rel_u_i(i,j,T+1))…
                    /rel_R1_i_sq(i,j,T+1);
                rel_theta_los_i_dot(i,j,T+1)=(rel_w_i(i,j,T+1)*…
                    rel_R1_i(i,j,T+1)-rel_z_i(i,j,T+1)*…
                    rel_R1_i_dot(i,j,T+1))/rel_R_i_sq(i,j,T+1);
 
                rel_psi_los_i(i,j,T+1) = atan2(rel_y_i(i,j,T+1),…
                    rel_x_i(i,j,T+1));
                rel_theta_los_i(i,j,T+1) = atan2(-rel_z_i(i,j,T+1),…
                    rel_R1_i(i,j,T+1));
            end
        end
    end
 
    %% 20.30. Autopilot Loop Dynamics**************************************
    % Update Body-Axis Velocities & Accelerations
    for i=1:i_num
        ax_b_dot(i,T+1)=-bw_ax(i)*ax_b(i,T)+bw_ax(i)*ax_b_dem(i,T);
        ay_b_dot(i,T+1)=-bw_ay(i)*ay_b(i,T)+bw_ay(i)*ay_b_dem(i,T);
        az_b_dot(i,T+1)=-bw_az(i)*az_b(i,T)+bw_az(i)*az_b_dem(i,T);
 
        ax_b(i,T+1)=ax_b(i,T)+ax_b_dot(i,T+1)*del_t;
        ay_b(i,T+1)=ay_b(i,T)+ay_b_dot(i,T+1)*del_t;
        az_b(i,T+1)=az_b(i,T)+az_b_dot(i,T+1)*del_t;
 
        u_b(i,T+1)=u_b(i,T);
        v_b(i,T+1)=v_b(i,T);
        w_b(i,T+1)=w_b(i,T);
 
    end
 
    % Update Body_Axis Velociy, Acceleration and Rates:
    for i=1:i_num;
        V_b(i,T+1)=sqrt(u_b(i,T+1)*u_b(i,T+1)+v_b(i,T+1)*v_b(i,T+1)+…
            w_b(i,T+1)*w_b(i,T+1));
        V_b_sq(i,T+1)=V_b(i,T+1)*V_b(i,T+1);
        A_b(i,T+1)=sqrt(ax_b(i,T+1)*ax_b(i,T+1)+ay_b(i,T+1)*ay_b(i,T+1)+…
            az_b(i,T+1)*az_b(i,T+1));
        p_b(i,T+1)=(v_b(i,T+1)*az_b(i,T+1)-w_b(i,T+1)*ay_b(i,T+1))/V_b_sq(i,T+1);
        q_b(i,T+1)=(w_b(i,T+1)*ax_b(i,T+1)-u_b(i,T+1)*az_b(i,T+1))/V_b_sq(i,T+1);
        r_b(i,T+1)=(u_b(i,T+1)*ay_b(i,T+1)-v_b(i,T+1)*ax_b(i,T+1))/V_b_sq(i,T+1);
    end
 
    %% 20.40. Guidance Law Implementation**********************************
 
T_1(1,T+1)=T_1_factor*abs(rel_R_i(3,1,T+1)/rel_R_i_dot(3,1,T+1))+del_T_1;
 
T_2(1,T+1)=T_2_factor*abs(rel_R_i(2,3,T+1)/rel_R_i_dot(2,3,T+1))+del_T_2;
 
    if(T_1(1,T+1)>T_1(1,T));T_1(1,T+1)=T_1(1,T);
    end
    if(T_2(1,T+1)>T_2(1,T));T_2(1,T+1)=T_2(1,T);
    end
 
    T_1_sq=T_1(1,T+1)*T_1(1,T+1);
    T_1_cube=T_1_sq*T_1(1,T+1);
    T_1_fourth=T_1_cube*T_1(1,T+1);
 
    T_2_sq=T_2(1,T+1)*T_2(1,T+1);
    T_2_cube=T_2_sq*T_2(1,T+1);
    T_2_fourth=T_2_cube*T_2(1,T+1);
 
    time=T*del_t;
    if(time>6);
        factor4=0;
    end
 
    % Guidance Gains - Target(1)/Attacker(3):
    den_1=(12.0*r_diff_1*r_diff_1+12.0*s4*r_diff_1*T_1(1,T+1)+…
        4.0*s1*r_diff_1*T_1_cube+s1*s4*T_1_fourth);
    den_2=(12.0*r_diff_1*r_diff_1+12.0*s5*r_diff_1*T_1(1,T+1)+…
        4.0*s2*r_diff_1*T_1_cube+s2*s5*T_1_fourth);
    den_3=(12.0*r_diff_1*r_diff_1+12.0*s6*r_diff_1*T_1(1,T+1)+…
        4.0*s3*r_diff_1*T_1_cube+s3*s6*T_1_fourth);
 
    num_14=6.0*s1*r_diff_1*T_1(1,T+1)*(2.0*r_diff_1+s4*T_1(1,T+1));
    num_25=6.0*s2*r_diff_1*T_1(1,T+1)*(2.0*r_diff_1+s5*T_1(1,T+1));
    num_36=6.0*s3*r_diff_1*T_1(1,T+1)*(2.0*r_diff_1+s6*T_1(1,T+1));
 
num_44=4.0*r_diff_1*(3.0*s4*r_diff_1+3.0*s1*r_diff_1*T_1_sq+s1*s4*T_1_cube);
 
num_55=4.0*r_diff_1*(3.0*s5*r_diff_1+3.0*s2*r_diff_1*T_1_sq+s2*s5*T_1_cube);
 
num_66=4.0*r_diff_1*(3.0*s6*r_diff_1+3.0*s3*r_diff_1*T_1_sq+s3*s6*T_1_cube);
 
 
    g31_1=num_14/den_1/r3;
    g31_2=num_25/den_2/r3;
    g31_3=num_36/den_3/r3;
    g31_4=num_44/den_1/r3;
    g31_5=num_55/den_2/r3;
    g31_6=num_66/den_3/r3;
 
    g13_1=num_14/den_1/r1_bar;
    g13_2=num_25/den_2/r1_bar;
    g13_3=num_36/den_3/r1_bar;
    g13_4=num_44/den_1/r1_bar;
    g13_5=num_55/den_2/r1_bar;
    g13_6=num_66/den_3/r1_bar;
 
    % Guidance Gains - Target(3)/Defender(2):
    den_1=(12.0*r_diff_2*r_diff_2+12.0*s4*r_diff_2*T_2(1,T+1)+…
        4.0*s1*r_diff_2*T_2_cube+s1*s4*T_2_fourth);
    den_2=(12.0*r_diff_2*r_diff_2+12.0*s5*r_diff_2*T_2(1,T+1)+…
        4.0*s2*r_diff_2*T_2_cube+s2*s5*T_2_fourth);
    den_3=(12.0*r_diff_2*r_diff_2+12.0*s6*r_diff_2*T_2(1,T+1)+…
        4.0*s3*r_diff_2*T_2_cube+s3*s6*T_2_fourth);
 
    num_14=6.0*s1*r_diff_2*T_2(1,T+1)*(2.0*r_diff_2+s4*T_2(1,T+1));
    num_25=6.0*s2*r_diff_2*T_2(1,T+1)*(2.0*r_diff_2+s5*T_2(1,T+1));
    num_36=6.0*s3*r_diff_2*T_2(1,T+1)*(2.0*r_diff_2+s6*T_2(1,T+1));
 
num_44=4.0*r_diff_2*(3.0*s4*r_diff_2+3.0*s1*r_diff_2*T_2_sq+s1*s4*T_2_cube);
 
num_55=4.0*r_diff_2*(3.0*s5*r_diff_2+3.0*s2*r_diff_2*T_2_sq+s2*s5*T_2_cube);
 
num_66=4.0*r_diff_2*(3.0*s6*r_diff_2+3.0*s3*r_diff_2*T_2_sq+s3*s6*T_2_cube);
 
 
    % Attacker Gains
    g23_1=num_14/den_1/r2;
    g23_2=num_25/den_2/r2;
    g23_3=num_36/den_3/r2;
    g23_4=num_44/den_1/r2;
    g23_5=num_55/den_2/r2;
    g23_6=num_66/den_3/r2;
    % Evader gains
    g32_1=num_14/den_1/r3_bar;
    g32_2=num_25/den_2/r3_bar;
    g32_3=num_36/den_3/r3_bar;
    g32_4=num_44/den_1/r3_bar;
    g32_5=num_55/den_2/r3_bar;
    g32_6=num_66/den_3/r3_bar;
    % Guidance Acceleration Demands in Fixed_Axis:
 
 
ax_i_dem(1,T+1)=factor1*(g13_1*rel_x_i(1,3,T+1)+g13_4*rel_u_i(1,3,T+1));
 
ax_i_dem(2,T+1)=factor2*(g23_1*rel_x_i(3,2,T+1)+g23_4*rel_u_i(3,2,T+1));
 
ax_i_dem(3,T+1)=factor3*(g31_1*rel_x_i(1,3,T+1)+g31_4*rel_u_i(1,3,T+1))…
        +factor4*(g32_1*rel_x_i(3,2,T+1)+g32_4*rel_u_i(3,2,T+1));
 
 
ay_i_dem(1,T+1)=factor1*(g13_2*rel_y_i(1,3,T+1)+g13_5*rel_v_i(1,3,T+1));
 
ay_i_dem(2,T+1)=factor2*(g23_2*rel_y_i(3,2,T+1)+g23_5*rel_v_i(3,2,T+1));
 
ay_i_dem(3,T+1)=factor3*(g31_2*rel_y_i(1,3,T+1)+g31_5*rel_v_i(1,3,T+1))…
        +factor4*(g32_2*rel_y_i(3,2,T+1)+g32_5*rel_v_i(3,2,T+1));
 
 
az_i_dem(1,T+1)=factor1*(g13_3*rel_z_i(1,3,T+1)+g13_6*rel_w_i(1,3,T+1));
 
az_i_dem(2,T+1)=factor2*(g23_3*rel_z_i(3,2,T+1)+g23_6*rel_w_i(3,2,T+1));
 
az_i_dem(3,T+1)=factor3*(g31_3*rel_z_i(1,3,T+1)+g31_6*rel_w_i(1,3,T+1))…
        +factor4*(g32_3*rel_z_i(3,2,T+1)+g32_6*rel_w_i(3,2,T+1));
 
    %Convert Demands to Body_Axis
    for i=1:i_num;
        ax_b_dem(i,T+1)=t11_bi(i,T+1)*ax_i_dem(i,T+1)+t21_bi(i,T+1)*…
            ay_i_dem(i,T+1)+t31_bi(i,T+1)*az_i_dem(i,T+1);
        ay_b_dem(i,T+1)=t12_bi(i,T+1)*ax_i_dem(i,T+1)+t22_bi(i,T+1)*…
            ay_i_dem(i,T+1)+t32_bi(i,T+1)*az_i_dem(i,T+1);
        az_b_dem(i,T+1)=t13_bi(i,T+1)*ax_i_dem(i,T+1)+t23_bi(i,T+1)*…
            ay_i_dem(i,T+1)+t33_bi(i,T+1)*az_i_dem(i,T+1);
    end
 
    %Additional Vehicle Manoeuvres:
    for i = 1:i_num;
        ax_b_dem(i,T+1)=ax_b_dem(i,T+1)+ax_b_bias(i,T+1);
        ay_b_dem(i,T+1)=ay_b_dem(i,T+1)+ay_b_bias(i,T+1);
        az_b_dem(i,T+1)=az_b_dem(i,T+1)+az_b_bias(i,T+1);
    end
 
    %% g-constraints
    ax_b_dem(1,T+1)=0;
    ax_b_dem(2,T+1)=0;
    ax_b_dem(3,T+1)=0;
    if ay_b_dem(1,T+1)<lim_min_y(1); ay_b_dem(1,T+1)=lim_min_y(1); end
    if ay_b_dem(1,T+1)>lim_max_y(1); ay_b_dem(1,T+1)=lim_max_y(1); end
    if ay_b_dem(2,T+1)<lim_min_y(2); ay_b_dem(2,T+1)=lim_min_y(2); end
    if ay_b_dem(2,T+1)>lim_max_y(2); ay_b_dem(2,T+1)=lim_max_y(2); end
    if ay_b_dem(3,T+1)<lim_min_y(3); ay_b_dem(3,T+1)=lim_min_y(3); end
    if ay_b_dem(3,T+1)>lim_max_y(3); ay_b_dem(3,T+1)=lim_max_y(3); end
    if az_b_dem(1,T+1)<lim_min_z(1); az_b_dem(1,T+1)=lim_min_z(1); end
    if az_b_dem(1,T+1)>lim_max_z(1); az_b_dem(1,T+1)=lim_max_z(1); end
    if az_b_dem(2,T+1)<lim_min_z(2); az_b_dem(2,T+1)=lim_min_z(2); end
    if az_b_dem(2,T+1)>lim_max_z(2); az_b_dem(2,T+1)=lim_max_z(2); end
    if az_b_dem(3,T+1)<lim_min_z(3); az_b_dem(3,T+1)=lim_min_z(3); end
    if az_b_dem(3,T+1)>lim_max_z(3); az_b_dem(3,T+1)=lim_max_z(3); end
 
    % Check for Miss Distance *********************************************
    if(rel_R_i(2,3,T+1)<miss_dist(2,3));
        miss_dist(2,3)=rel_R_i(2,3,T+1);
        miss_flag(2,3)=0;
    else
        if(miss_flag(2,3)==0);
            miss_flag(2,3)=1;
            Miss23=miss_dist(2,3)
            flight_time(2,3)=(T+1)*del_t;
            Flight_time23=flight_time(2,3)
        end
    end
 
    if(rel_R_i(3,1,T+1)<miss_dist(3,1));
        miss_dist(3,1)=rel_R_i(3,1,T+1);
        miss_flag (3,1)=0;
    else
        if(miss_flag(3,1)==0);
            miss_flag(3,1)=1;
            Miss31=miss_dist(3,1)
            flight_time(3,1)=(T+1)*del_t;
            Flight_time31=flight_time(3,1)
        end
    end
    %     if(miss_flag(2,3)==1 && miss_flag(3,1)==1);
    %         break
    %     end
 
    if T==1     % Only for the first simulation step
        %% Miss distances
        decreasing_3_1 = true;
        decreasing_2_3 = true;
 
        misses23 = [];
        misses31 = [];
 
        %% Incremental plotting during run
        res = 500;      %Plot every "res" simulation steps
        rescount = 1;
 
        % Calculate locations for 3 figures in top half of screen
        ss = get(0,'ScreenSize');
        windw = ss(3)/3;
        windh = (ss(4)-28)/2;
 
        % Format figures and plot first point
        f25 = figure(25); hold on
        set(f25, 'OuterPosition', [1 29+windh  windw windh], 'MenuBar', ' none',
        'Toolbar', 'figure');
        f25p1 = plot(x_i(1,1),-z_i(1,1),'k');
        f25p2 = plot(x_i(2,1),-z_i(2,1),':k');
        f25p3 = plot(x_i(3,1),-z_i(3,1),'- -k');
        a25 = gca;
        title('Z vs. X; 1=blk, 2=…, 3=- - -');
        xlabel('Down-Range (m)');
        ylabel('Altitude (m)');
 
        f26 = figure(26); hold on
        set(f26, 'OuterPosition', [1+windw 29+windh  windw windh], 'MenuBar',
        ' none', 'Toolbar', 'figure');
        f26p1 = plot(y_i(1,1),-z_i(1,1),'k');
        f26p2 = plot(y_i(2,1),-z_i(2,1),':k');
        f26p3 = plot(y_i(3,1),-z_i(3,1),'- -k');
        a26 = gca;
        title('Z vs. Y; 1=blk, 2=…, 3=- - -');
        xlabel('Cross-Range (m)');
        ylabel('Altitude (m)');
 
        f27 = figure(27); hold on
        set(f27, 'OuterPosition', [1+2*windw 29+windh  windw windh], 'MenuBar',
        ' none', 'Toolbar', 'figure');
        f27p1 = plot(x_i(1,1),y_i(1,1),'k');
        f27p2 = plot(x_i(2,1),y_i(2,1),':k');
        f27p3 = plot(x_i(3,1),y_i(3,1),'- -k');
        a27 = gca;
        title('Y vs. X; 1=blk, 2=…, 3=- - -');
        xlabel('Down-Range (m)');
        ylabel('Cross Range (m)');
 
        f36 = figure(36); hold on
        set(f36, 'OuterPosition', [1+2*windw 29 windw windh], 'MenuBar', ' none',
        'Toolbar', 'figure');
        set(gca, 'xlim', [0,tf]);
        rel_R_i_3_1 = zeros(length(rel_R_i),1);
        rel_R_i_3_1(1) = rel_R_i(3,1,1);
        rel_R_i_3_1(2) = rel_R_i(3,1,2);
        f36p1 = plot(t(1),rel_R_i_3_1(1),'- -k');
        rel_R_i_2_3 = zeros(length(rel_R_i),1);
        rel_R_i_2_3(1) = rel_R_i(2,3,1);
        rel_R_i_2_3(2) = rel_R_i(2,3,2);
        f36p2 = plot(t(1),rel_R_i_2_3(1),':k');
        a36 = gca;
        y_lim = get(gca, 'ylim');
        set(gca, 'ylim', [0 y_lim(2)]);
        y_lim = get(gca, 'ylim');
        title('Range-to-go vs. Time');
        xlabel('Time (s)');
        ylabel('Range-to-go (m)');
 
        %% Pause and quit buttons
        choice=0;
        hd = dialog('WindowStyle', 'normal', 'Name', '', 'OuterPosition',
        [1 29+windh-100  270 90]);
 
but1=uicontrol(hd,'Style','pushbutton','String','Pause','Callback','choice=1;');
 
but2=uicontrol(hd,'Style','pushbutton','String','Continue','Position',
[100 20 60 20],'Callback','choice=2;');
        but3=uicontrol(hd,'Style','pushbutton','String','Quit','Position',
[180 20 60 20],'Callback','choice=3;');
    else        % For every simulation step except the first
        %% Miss distances
        if (rel_R_i(2,3,T+1) <= rel_R_i_2_3(T))     % Decreasing range
            if(~decreasing_2_3)
                decreasing_2_3 = true;              % Change to decreasing
            end
        else                                        % Increasing range
            if(decreasing_2_3)
                decreasing_2_3 = false;             % Change to increasing
                misses23 = [misses23; t(T) rel_R_i_2_3(T)];
                plot(a25, x_i(3,T+1),-z_i(3,T+1),'*b');
                plot(a25, x_i(2,T+1),-z_i(2,T+1),'sb');
                plot(a26, y_i(3,T+1),-z_i(3,T+1),'*b');
                plot(a26, y_i(2,T+1),-z_i(2,T+1),'sb');
                plot(a27, x_i(3,T+1),y_i(3,T+1),'*b');
                plot(a27, x_i(2,T+1),y_i(2,T+1),'sb');
                plot(a36, [t(T), t(T)], y_lim, '-b');
            end
        end
        if (rel_R_i(3,1,T+1) <= rel_R_i_3_1(T))     % Decreasing range
            if(~decreasing_3_1)
                decreasing_3_1 = true;              % Change to decreasing
            end
        else                                        % Increasing range
            if(decreasing_3_1)
                decreasing_3_1 = false;             % Change to increasing
                misses31 = [misses31; t(T) rel_R_i_3_1(T)];
                plot(a25, x_i(1,T+1),-z_i(1,T+1),'or');
                plot(a25, x_i(3,T+1),-z_i(3,T+1),'*r');
                plot(a26, y_i(1,T+1),-z_i(1,T+1),'or');
                plot(a26, y_i(3,T+1),-z_i(3,T+1),'*r');
                plot(a27, x_i(1,T+1),y_i(1,T+1),'or');
                plot(a27, x_i(3,T+1),y_i(3,T+1),'*r');
                plot(a36, [t(T), t(T)], y_lim, '-r');
            end
        end
        rel_R_i_3_1(T+1) = rel_R_i(3,1,T+1);
        rel_R_i_2_3(T+1) = rel_R_i(2,3,T+1);
 
        %% Incremental plotting during run
        rescount = rescount+1;
        if rescount>=res
            rescount = 0;
            set(f25p1,'xdata',x_i(1,1:T),'ydata',-z_i(1,1:T));
            set(f25p2,'xdata',x_i(2,1:T),'ydata',-z_i(2,1:T));
            set(f25p3,'xdata',x_i(3,1:T),'ydata',-z_i(3,1:T));
            set(f26p1,'xdata',y_i(1,1:T),'ydata',-z_i(1,1:T));
            set(f26p2,'xdata',y_i(2,1:T),'ydata',-z_i(2,1:T));
            set(f26p3,'xdata',y_i(3,1:T),'ydata',-z_i(3,1:T));
            set(f27p1,'xdata',x_i(1,1:T),'ydata',y_i(1,1:T));
            set(f27p2,'xdata',x_i(2,1:T),'ydata',y_i(2,1:T));
            set(f27p3,'xdata',x_i(3,1:T),'ydata',y_i(3,1:T));
            set(f36p1,'xdata',t(1:T),'ydata',rel_R_i_3_1(1:T));
            set(f36p2,'xdata',t(1:T),'ydata',rel_R_i_2_3(1:T));
            drawnow;
        end
    end
 
    %% Pause and quit buttons
    while choice==1
        set(but1,'String','Step');
        waitforbuttonpress;
        choice=2;
        if choice==2
            set(but1,'String','Pause');
        end
    end
    if choice==3
        delete(hd);
        clear('hd');
        break
    end
end
%% Pause and quit buttons. Delete buttons if they still exist
if exist('hd', 'var')
    delete(hd);
    clear('hd');
end
 
%% Incremental plotting
% Plot last point on graphs
set(f25p1,'xdata',x_i(1,1:T),'ydata',-z_i(1,1:T));
set(f25p2,'xdata',x_i(2,1:T),'ydata',-z_i(2,1:T));
set(f25p3,'xdata',x_i(3,1:T),'ydata',-z_i(3,1:T));
set(f26p3,'xdata',y_i(3,1:T),'ydata',-z_i(3,1:T));
set(f27p1,'xdata',x_i(1,1:T),'ydata',y_i(1,1:T));
set(f27p2,'xdata',x_i(2,1:T),'ydata',y_i(2,1:T));
set(f27p3,'xdata',x_i(3,1:T),'ydata',y_i(3,1:T));
set(f36p1,'xdata',t(1:T),'ydata',rel_R_i_3_1(1:T));
set(f36p2,'xdata',t(1:T),'ydata',rel_R_i_2_3(1:T));
 
% Show 2 minimum miss distances on graph 36
figure(36);
% Stretch series to fill X axis
set(gca, 'xlim', [0,ceil(t(T))]);
% Plot vertical near miss lines
% yl = get(gca, 'ylim');
 
empty = true;
str={};
str{ 1 } = ' Time Distance';
if ~isempty(misses31)
    empty = false;
    misses31 = sortrows(misses31,2);
    for i=1:size(misses31,1)
%         plot([misses31(i,1),misses31(i,1)], yl, '-r');
        str = [str; 'Miss31 :  ', num2str(misses31(i,:))];
        if (i==2)
            break
        end
    end
end
if ~isempty(misses23)
    empty = false;
    misses23 = sortrows(misses23,2);
    for i=1:size(misses23,1)
%         plot([misses23(i,1),misses23(i,1)], yl, '-b');
        str = [str; 'Miss23 :  ', num2str(misses23(1,:))];
        if (i==2)
            break
        end
    end
end
if ~empty
text(.55,.95,str,'EdgeColor','black','VerticalAlignment','top','units',
'normalized');
    drawnow;
end
 

2. Listing for kinematics3.m


%% ************************************************************************
%% This subroutine updates the direction cosine matrix using quaternions
%% Transform the vehicle acceleration from body to fixed axis
%% Updates the fixed axis vehicle position and velocities
%% ************************************************************************
 
function[x_i,y_i,z_i,u_i,v_i,w_i,ax_i,ay_i,az_i,quat1,quat2,quat3,quat4,…
    t11_bi,t12_bi,t13_bi,t21_bi,t22_bi,t23_bi,t31_bi,t32_bi,t33_bi]=…
    kinematics3(x_i,y_i,z_i,u_i,v_i,w_i,quat1,quat2,quat3,quat4,p,q,r,…
    ax_b,ay_b,az_b,del_t)
 
%% 1. Position,Velocity & Acceleration Vectors Update:
%% 1.1. Update Quaternions:
quat1_dot= -0.5*(quat2*p+quat3*q+quat4*r);
quat2_dot= 0.5*(quat1*p-quat4*q+quat3*r);
quat3_dot= 0.5*(quat4*p+quat1*q-quat2*r);
quat4_dot= -0.5*(quat3*p-quat2*q-quat1*r);
 
quat1=quat1+quat1_dot*del_t;
quat2=quat2+quat2_dot*del_t;
quat3=quat3+quat3_dot*del_t;
quat4=quat4+quat4_dot*del_t;
 
quat_sq=quat1*quat1+quat2*quat2+quat3*quat3+quat4*quat4;
quat=sqrt(quat_sq);
 
quat1=quat1/quat;
quat2=quat2/quat;
quat3=quat3/quat;
quat4=quat4/quat;
 
%% 1.2. Construct DCM;
t11_bi=quat1*quat1+quat2*quat2-quat3*quat3-quat4*quat4;
t12_bi=2*(quat2*quat3-quat1*quat4);
t13_bi=2*(quat2*quat4+quat1*quat3);
t21_bi=2*(quat2*quat3+quat1*quat4);
t22_bi=quat1*quat1-quat2*quat2+quat3*quat3-quat4*quat4;
t23_bi=2*(quat3*quat4-quat1*quat2);
t31_bi=2*(quat2*quat4-quat1*quat3);
t32_bi=2*(quat3*quat4+quat1*quat2);
t33_bi=quat1*quat1-quat2*quat2-quat3*quat3+quat4*quat4;
 
%% 1.3. Construct:ax_i,ay_i,az_i, from ax_b,ay_b,az_b:
ax_i=t11_bi*ax_b+t12_bi*ay_b+t13_bi*az_b;
ay_i=t21_bi*ax_b+t22_bi*ay_b+t23_bi*az_b;
az_i=t31_bi*ax_b+t32_bi*ay_b+t33_bi*az_b;
 
%% 1.4. Update Position & Velocity;
 
u_i=u_i+ax_i*del_t;
v_i=v_i+ay_i*del_t;
w_i=w_i+az_i*del_t;
 
x_i =x_i+u_i*del_t;
y_i =y_i+v_i*del_t;
z_i =z_i+w_i*del_t;

5: Four Degrees-of-Freedom (DOF) Simulation Model for Missile Guidance and Control Systems
6: Three-Party Differential Game Missile Guidance Simulation Study
Differential Game Theory with Applications to Missiles and Autonomous Systems Guidance
Index



Skip to Content
Search 50,000+ courses, events, titles, and more
Index
a

    Aerodynamic forces
        calculation
        and equations of motion
    APN. See Augmented proportional navigation
    Augmented proportional navigation (APN)
        guidance
        PN and

b

    Bilinear functions w.r.t. vector, partial differentiation of
    Body incidence

c

    Calculus of optima (minimum/maximum) for function
        equality constraints utilizing Lagrange multipliers, steady state with
        linear system with quadratic cost function, steady state for
        necessary and sufficient conditions for
    CF. See Cost function
    Characteristics eigenvalues
    Characteristics equations
    Collision course missile heading angles
    Continuous-time differential game
    Continuous-time game
    Cost function (CF)

d

    Differential game theory
        application to missile guidance
        to multi-party engagement
        optimal control applications in
            three-party game theoretic guidance for linear dynamical systems
            two-party game theoretic guidance for linear dynamical systems
        optimum control and
        three-party, to missile guidance problem
        two-party, to missile guidance problem
    Discrete-time game
    Disturbance inputs
    Dynamic games
    Dynamic problem, optimum control for
        with boundary (transversality) conditions
        with fixed initial condition and unspecified final time
        Hamiltonian property and
        with inequality control constraints
        with initial and terminal conditions specified
        with sufficient conditions for optimality

e

    Eigenvalues, characteristics
    Engagement kinematics model, development of
        multi-vehicle engagement, translational kinematics for
        of n versus m vehicles
        rotational kinematics
            range and range rates
            sightline rates
        for three parties
        vector/matrix representation
    Equations
        characteristics
        of motion
            and aerodynamic forces
    Euler Lagrange (EL) multiplier

f

    Finite game
    Flight path angles
    Four degrees-of-freedom simulation model, for missile guidance
        aerodynamic considerations
        augmented proportional navigation guidance
        engagement kinematics model, development of
            multi-vehicle
            rotational kinematics
            vector/matrix representation
        flight path angles
        game theory-based guidance
        optimum guidance
        overall state space model
        proportional navigation guidance
        vehicle autopilot dynamics
        vehicle body angles
        vehicle navigation model
            quaternion, application of

g

    Game of Tic-tac-toe
    Games
        continuous-time
        discrete-time
        dynamic
        dynamics
        evolution of
        finite
        infinite
        players
        stochastic
        two-/three-party pursuit-evasion
    Game theoretic guidance (GTG)
        mechanization of
    Game theory
        concepts
        continuous-time differential game
        definitions
        differential, application of
        discrete-time game
        to missile guidance problem
        to optimum guidance, extension of
        problem examples
            game of Tic-tac-toe
            prisoner’s dilemma
    GTG. See Game theoretic guidance
    Guidance disturbance inputs
    Guided missiles

h

    Hamilton-Jacobi canonic equations
    Hessian matrices

i

    Infinite game
    Interceptor/target guidance for two-party game
        differential game guidance problem, solution of
        differential game performance index
        weighting matrices S, Rp, Re

l

    Lagrange multipliers
        equality constraints and
        optimum control problems
    Linear, bi-linear, and quadratic forms, differential of
    Linear dynamical systems
        optimum control for LQPI problem (fixed final time)
        three-party game theoretic guidance for
        two-party game theoretic guidance for
    Linear system dynamical models
    Linear system quadratic performance index (LQPI)
        problem
        for two-party game theoretic guidance problem
    Loss function. See Cost function (CF)
    LQPI. See Linear system quadratic performance index

m

    MATLAB-based simulation program
    Matrix algebra and calculus
    Matrix Riccati differential equations (MRDE)
        solution of
    Missile guidance
        differential game theory application to
        four degrees-of-freedom simulation model for
        need for
        problem
            game theory to
            three-party differential game theory to
            two-party differential game theory to
    MRDE. See Matrix Riccati differential equations
    Multi-vehicle engagement, translational kinematics for

n

    Nash equilibrium. See Non-cooperative equilibrium
    Non-cooperative equilibrium

o

    Objective function (OF)
        in infinite game
        of players
    OF. See Objective function
    OG. See Optimal guidance
    Optimal guidance (OG)
        game theory to
        for two-party game
    Optimum control theory
        calculus of optima (minimum or maximum) for function
            equality constraints utilizing Lagrange multipliers, steady state with
            linear system with quadratic cost function, steady state for
            necessary and sufficient conditions for
        differential game theory and
            three-party game theoretic guidance for linear dynamical systems
            two-party game theoretic guidance for linear dynamical systems
        for dynamic problem
            with boundary (transversality) conditions
            with fixed initial condition and unspecified final time
            Hamiltonian property and
            with inequality control constraints
            with initial and terminal conditions specified
            with sufficient conditions for optimality
        for linear dynamical system
            LQPI problem (fixed final time)

p

    Parties. See Players
    Performance index
    Pitch-plane kinematics equations
    Players
        in cooperative game
        objective function of
        pay-off for
    PMP. See Pontryagin’s minimum principle
    PN. See Proportional navigation
    Pontryagin’s minimum principle (PMP)
    Positive semi-definiteness of matrix [S]
    Prisoner’s dilemma, game theory problem example
    Proportional navigation (PN) guidance law
        APN and

q

    Quaternion, in navigation

r

    Riccati differential equation
        analytical solution for
        derivation of
        MRDE, solution of

s

    Scalar functions
        first and second variations of
        nature (min/max-values) of
        partial differentiation of
    Scalar quadratic w.r.t. vector, partial differentiation of
    Sightline angles
    Sightline rates
    State feedback guidance gains
    State space dynamics model
    Stochastic games

t

    Three-party game
        differential game missile guidance simulation study
            engagement kinematics model
            game theory problem and solution
            simulation results
        differential theory to missile guidance problem
            engagement kinematics model for
            game termination criteria
            MRDE, solution for
            performance index (PI) weightings for
            and solution
            VRDE, solution for
        theoretic guidance for linear dynamical systems
    Two-party game
        interceptor/target guidance for
            differential game guidance problem, solution of
            differential game performance index
            weighting matrices S, Rp, Re
        theoretic guidance for linear dynamical systems
    Two-party missile guidance problem, differential game theory to
        engagement kinematics model, development of
        feedback guidance gains
        game theory to optimum guidance, extension of
        mechanization of game theoretic guidance
        MRDE, solution of
        optimum interceptor/target guidance
        PN and APN guidance, relationship with
        VRDE
            analytical solution of
            solution of
    Two-/three-party pursuit-evasion games

u

    UF. See Utility function
    Utility function (UF)

v

    Vector Riccati differential equations (VRDE)
        analytical solution of
        solution of
    Vehicle autopilot dynamics
    Vehicle body angles
    VRDE. See Vector Riccati differential equations

w

    Weighting matrices S, Rp, Re

y

    Yaw plane equations

z

    Zero-sum game

6: Three-Party Differential Game Missile Guidance Simulation Study
Index
Differential Game Theory with Applications to Missiles and Autonomous Systems Guidance
EULA



