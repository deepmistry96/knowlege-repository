#highlevel 
#### **Models Released:**
- **GPT (Generative Pre-trained Transformer):** GPT-1, GPT-2, GPT-3
- **Codex:** A variant of GPT-3 fine-tuned for coding and software development tasks.

#### **Contributions:**
- **Transformer Architecture:** OpenAI's GPT models are based on the transformer architecture, which uses attention mechanisms to process and generate text, significantly improving NLP tasks.
- **Few-Shot and Zero-Shot Learning:** GPT-3 demonstrated remarkable few-shot and zero-shot learning capabilities, allowing the model to perform various tasks with minimal task-specific training.
- **Codex:** Specifically designed to understand and generate code, Codex powers GitHub Copilot, an AI-powered code completion tool.


| LLM Name | Developer | Release Date | Access | Parameters |
| -------- | --------- | ------------ | ------ | ---------- |
| GPT-4o   | OpenAI    | May 13, 2024 | API    | Unknown    |
|          |           |              |        |            |
| GPT-4    | OpenAI    |              | API    | Unknown    |
|          |           |              |        |            |
| GPT-3.5  | OpenAI    |              | API    | Unknown    |
|          |           |              |        |            |
| GPT-3    | OpenAI    |              | API    | Unknown    |
|          |           |              |        |            |
| GPT-2    | OpenAI    | May 13, 2024 | API    | Unknown    |
|          |           |              |        |            |
| GPT-1    | OpenAI    | May 13, 2024 | API    | Unknown    |
